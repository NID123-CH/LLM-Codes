{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NID123-CH/LLM-Codes/blob/main/03_BitsAndBytes_Quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHqLQmmoTLuX",
        "outputId": "7914634b-ec07-4e9d-9e00-acc3afd3bcca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.44.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.24.7)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install bitsandbytes accelerate peft"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jcyR0812t4Z"
      },
      "source": [
        "# BitsAndBytes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8DvcDviUyb2"
      },
      "source": [
        "Let's use BitsAndBytes to create a quantization config before we load our pretrained model. This way, it will be quantized during loading. We'll load it in 4 bits, and we'll use the `NF4` quantization type. It constructs a quantization data type where each bin has equal area under a standard normal distribution N(0, 1) that is normalized into the range [-1, 1]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Q_He0pJTJbF",
        "outputId": "2dca6e3b-2a9c-4981-983c-176084be4f23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "base_model_id = \"EleutherAI/pythia-160m\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.float32\n",
        ")\n",
        "\n",
        "# Loads base model without quantization\n",
        "model = AutoModelForCausalLM.from_pretrained(base_model_id)\n",
        "\n",
        "# Loads quantized model right away\n",
        "q_model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lqksbZ6MVyM"
      },
      "source": [
        "We can use `get_memory_footprint()` method to get an estimated size of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LurtuhYsarGx",
        "outputId": "161e54ae-64df-4850-889f-be877a88cc67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "702.769584 250.721688\n"
          ]
        }
      ],
      "source": [
        "print(model.get_memory_footprint()/1e6, q_model.get_memory_footprint()/1e6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzAVk3xs3Y92"
      },
      "source": [
        "We'll use the `model_size()` helper function to compare the models along the way in more detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "7MSuVYN4TgZO"
      },
      "outputs": [],
      "source": [
        "# https://discuss.pytorch.org/t/finding-model-size/130275/11\n",
        "\n",
        "def model_size(model, include_buffer=True):\n",
        "    param_size = 0\n",
        "    parm_list = []\n",
        "    for name, param in model.named_parameters():\n",
        "        subtotal = param.nelement() * param.element_size()\n",
        "        parm_list.append((name, subtotal, param.requires_grad))\n",
        "        param_size += subtotal\n",
        "    buffer_size = 0\n",
        "    if include_buffer:\n",
        "        for buffer in model.buffers():\n",
        "            buffer_size += buffer.nelement() * buffer.element_size()\n",
        "\n",
        "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
        "    return size_all_mb, parm_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6BbwQQf3guO"
      },
      "source": [
        "## Regular Model\n",
        "\n",
        "Let's look at the regular model first:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd-siuVXWpNA",
        "outputId": "e30d7729-2212-4447-b93b-b99c30d2f0f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTNeoXForCausalLM(\n",
              "  (gpt_neox): GPTNeoXModel(\n",
              "    (embed_in): Embedding(50304, 768)\n",
              "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
              "    (layers): ModuleList(\n",
              "      (0-11): 12 x GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXSdpaAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (embed_out): Linear(in_features=768, out_features=50304, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9FYkTDlWXNj",
        "outputId": "83674ae1-4d22-4fb8-9c81-2173c817b15e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "670.2133026123047"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "size1, parm_list1 = model_size(model)\n",
        "size1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZvH8S433vQc"
      },
      "source": [
        "It is roughly 670Mb in size (160M parameters times 4 bytes (32 bits) for each parameter).\n",
        "\n",
        "Let's take a look at the weights of a linear layer in the attention mechanism:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGomDA75Wu81",
        "outputId": "e12bd159-6b96-459f-c657-37427b02afb9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2304, 768]),\n",
              " Parameter containing:\n",
              " tensor([[ 0.0295,  0.0594,  0.0711,  ...,  0.0077, -0.0146,  0.0082],\n",
              "         [-0.0202, -0.0193, -0.0186,  ..., -0.0018,  0.0001, -0.0081],\n",
              "         [ 0.0210,  0.0049,  0.0044,  ..., -0.0050, -0.0068,  0.0227],\n",
              "         ...,\n",
              "         [-0.0251, -0.0046, -0.0168,  ...,  0.0253, -0.0157, -0.0254],\n",
              "         [ 0.0089, -0.0146, -0.0023,  ..., -0.0260,  0.0066, -0.0007],\n",
              "         [-0.0109,  0.0204,  0.0143,  ..., -0.0116,  0.0042,  0.0450]],\n",
              "        requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "lin = model.gpt_neox.layers[0].attention.query_key_value\n",
        "lin.weight.shape, lin.weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0M6YT3X39hr"
      },
      "source": [
        "## Quantized Model\n",
        "\n",
        "Now, let's take a look at its quantized version:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PO9jyttWrFL",
        "outputId": "2146d356-663e-47eb-ef04-2dad258b79a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTNeoXForCausalLM(\n",
              "  (gpt_neox): GPTNeoXModel(\n",
              "    (embed_in): Embedding(50304, 768)\n",
              "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
              "    (layers): ModuleList(\n",
              "      (0-11): 12 x GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXSdpaAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear4bit(in_features=768, out_features=2304, bias=True)\n",
              "          (dense): Linear4bit(in_features=768, out_features=768, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear4bit(in_features=768, out_features=3072, bias=True)\n",
              "          (dense_4h_to_h): Linear4bit(in_features=3072, out_features=768, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (embed_out): Linear(in_features=768, out_features=50304, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "q_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ06j19D4HE0"
      },
      "source": [
        "Did you notice the difference? Linear layers are `Linear4bit` layers now!\n",
        "\n",
        "How did it impact the size?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dM0Sj5KTWY5_",
        "outputId": "747c3ea7-9099-4f7a-da95-d4b008e5e1bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "239.1068344116211"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "size2, parm_list2 = model_size(q_model)\n",
        "size2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1U6wKhIm4OsG"
      },
      "source": [
        "Nice! The model is roughly 1/3 of its original size thanks to quantization!\n",
        "\n",
        "What if we peek at the same linear layer as before?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEsJ818SW8Ax",
        "outputId": "5fd32dbf-b753-47ad-d6f7-6e37d624b087"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([884736, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "qlin = q_model.gpt_neox.layers[0].attention.query_key_value\n",
        "qlin.weight.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hse-wcpQXctL",
        "outputId": "a63d19d7-2368-4ce7-9ae2-c48c7219de2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'absmax': tensor([255, 242, 230,  ...,  15,  30,  27], device='cuda:0',\n",
              "        dtype=torch.uint8),\n",
              " 'shape': torch.Size([2304, 768]),\n",
              " 'code': tensor([-1.0000, -0.6962, -0.5251, -0.3949, -0.2844, -0.1848, -0.0911,  0.0000,\n",
              "          0.0796,  0.1609,  0.2461,  0.3379,  0.4407,  0.5626,  0.7230,  1.0000],\n",
              "        device='cuda:0'),\n",
              " 'dtype': torch.float16,\n",
              " 'blocksize': 64,\n",
              " 'quant_type': 'nf4',\n",
              " 'offset': tensor(0.0793, device='cuda:0'),\n",
              " 'state2': <bitsandbytes.functional.QuantState at 0x7ee5ec957940>,\n",
              " 'nested': True}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "qlin.weight.quant_state.__dict__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epFNPk854gSE"
      },
      "source": [
        "Wow! That's quite something else!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlCpHRpD6lMG"
      },
      "source": [
        "### Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "FnDO0Q0hhbMw",
        "outputId": "4b83f708-ff3c-434f-cc4d-44a65805adc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  name    n_parms  grad  \\\n",
              "0                             gpt_neox.embed_in.weight  154533888  True   \n",
              "1             gpt_neox.layers.0.input_layernorm.weight       3072  True   \n",
              "2               gpt_neox.layers.0.input_layernorm.bias       3072  True   \n",
              "3    gpt_neox.layers.0.post_attention_layernorm.weight       3072  True   \n",
              "4      gpt_neox.layers.0.post_attention_layernorm.bias       3072  True   \n",
              "..                                                 ...        ...   ...   \n",
              "143        gpt_neox.layers.11.mlp.dense_4h_to_h.weight    9437184  True   \n",
              "144          gpt_neox.layers.11.mlp.dense_4h_to_h.bias       3072  True   \n",
              "145                   gpt_neox.final_layer_norm.weight       3072  True   \n",
              "146                     gpt_neox.final_layer_norm.bias       3072  True   \n",
              "147                                   embed_out.weight  154533888  True   \n",
              "\n",
              "     q_n_parms  q_grad  \n",
              "0     77266944    True  \n",
              "1         1536    True  \n",
              "2         1536    True  \n",
              "3         1536    True  \n",
              "4         1536    True  \n",
              "..         ...     ...  \n",
              "143    1179648   False  \n",
              "144       1536   False  \n",
              "145       1536    True  \n",
              "146       1536    True  \n",
              "147   77266944    True  \n",
              "\n",
              "[148 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-19cb83be-a91b-422b-8c6b-293315a7c6a1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>n_parms</th>\n",
              "      <th>grad</th>\n",
              "      <th>q_n_parms</th>\n",
              "      <th>q_grad</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gpt_neox.embed_in.weight</td>\n",
              "      <td>154533888</td>\n",
              "      <td>True</td>\n",
              "      <td>77266944</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gpt_neox.layers.0.input_layernorm.weight</td>\n",
              "      <td>3072</td>\n",
              "      <td>True</td>\n",
              "      <td>1536</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gpt_neox.layers.0.input_layernorm.bias</td>\n",
              "      <td>3072</td>\n",
              "      <td>True</td>\n",
              "      <td>1536</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gpt_neox.layers.0.post_attention_layernorm.weight</td>\n",
              "      <td>3072</td>\n",
              "      <td>True</td>\n",
              "      <td>1536</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gpt_neox.layers.0.post_attention_layernorm.bias</td>\n",
              "      <td>3072</td>\n",
              "      <td>True</td>\n",
              "      <td>1536</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>gpt_neox.layers.11.mlp.dense_4h_to_h.weight</td>\n",
              "      <td>9437184</td>\n",
              "      <td>True</td>\n",
              "      <td>1179648</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>gpt_neox.layers.11.mlp.dense_4h_to_h.bias</td>\n",
              "      <td>3072</td>\n",
              "      <td>True</td>\n",
              "      <td>1536</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>gpt_neox.final_layer_norm.weight</td>\n",
              "      <td>3072</td>\n",
              "      <td>True</td>\n",
              "      <td>1536</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>gpt_neox.final_layer_norm.bias</td>\n",
              "      <td>3072</td>\n",
              "      <td>True</td>\n",
              "      <td>1536</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>embed_out.weight</td>\n",
              "      <td>154533888</td>\n",
              "      <td>True</td>\n",
              "      <td>77266944</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>148 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19cb83be-a91b-422b-8c6b-293315a7c6a1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-19cb83be-a91b-422b-8c6b-293315a7c6a1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-19cb83be-a91b-422b-8c6b-293315a7c6a1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-32275601-9d45-4da9-8034-5885bf466f1f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-32275601-9d45-4da9-8034-5885bf466f1f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-32275601-9d45-4da9-8034-5885bf466f1f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_10ab70da-afe1-4b98-9453-1e5e64862f2d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('comparison_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_10ab70da-afe1-4b98-9453-1e5e64862f2d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('comparison_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "comparison_df",
              "summary": "{\n  \"name\": \"comparison_df\",\n  \"rows\": 148,\n  \"fields\": [\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 148,\n        \"samples\": [\n          \"gpt_neox.layers.10.attention.query_key_value.weight\",\n          \"gpt_neox.layers.4.post_attention_layernorm.weight\",\n          \"gpt_neox.layers.11.attention.dense.weight\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_parms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18017063,\n        \"min\": 3072,\n        \"max\": 154533888,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          154533888,\n          3072,\n          9437184\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"grad\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"q_n_parms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8929551,\n        \"min\": 1536,\n        \"max\": 77266944,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          77266944\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"q_grad\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "import pandas as pd\n",
        "comparison_df = pd.DataFrame(parm_list1, columns=['name', 'n_parms', 'grad']).merge(pd.DataFrame(parm_list2, columns=['name', 'q_n_parms', 'q_grad']))\n",
        "comparison_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "vqilP1LS6dWU",
        "outputId": "e38b1bf6-bd5b-404b-8e77-220d04e503ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  name  n_parms  grad  \\\n",
              "5    gpt_neox.layers.0.attention.query_key_value.we...  7077888  True   \n",
              "6     gpt_neox.layers.0.attention.query_key_value.bias     9216  True   \n",
              "7             gpt_neox.layers.0.attention.dense.weight  2359296  True   \n",
              "8               gpt_neox.layers.0.attention.dense.bias     3072  True   \n",
              "9           gpt_neox.layers.0.mlp.dense_h_to_4h.weight  9437184  True   \n",
              "..                                                 ...      ...   ...   \n",
              "140            gpt_neox.layers.11.attention.dense.bias     3072  True   \n",
              "141        gpt_neox.layers.11.mlp.dense_h_to_4h.weight  9437184  True   \n",
              "142          gpt_neox.layers.11.mlp.dense_h_to_4h.bias    12288  True   \n",
              "143        gpt_neox.layers.11.mlp.dense_4h_to_h.weight  9437184  True   \n",
              "144          gpt_neox.layers.11.mlp.dense_4h_to_h.bias     3072  True   \n",
              "\n",
              "     q_n_parms  q_grad  \n",
              "5       884736   False  \n",
              "6         4608   False  \n",
              "7       294912   False  \n",
              "8         1536   False  \n",
              "9      1179648   False  \n",
              "..         ...     ...  \n",
              "140       1536   False  \n",
              "141    1179648   False  \n",
              "142       6144   False  \n",
              "143    1179648   False  \n",
              "144       1536   False  \n",
              "\n",
              "[96 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a1dce46-154e-4fc5-a4cd-d2cdd1ace085\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>n_parms</th>\n",
              "      <th>grad</th>\n",
              "      <th>q_n_parms</th>\n",
              "      <th>q_grad</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>gpt_neox.layers.0.attention.query_key_value.we...</td>\n",
              "      <td>7077888</td>\n",
              "      <td>True</td>\n",
              "      <td>884736</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>gpt_neox.layers.0.attention.query_key_value.bias</td>\n",
              "      <td>9216</td>\n",
              "      <td>True</td>\n",
              "      <td>4608</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>gpt_neox.layers.0.attention.dense.weight</td>\n",
              "      <td>2359296</td>\n",
              "      <td>True</td>\n",
              "      <td>294912</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>gpt_neox.layers.0.attention.dense.bias</td>\n",
              "      <td>3072</td>\n",
              "      <td>True</td>\n",
              "      <td>1536</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>gpt_neox.layers.0.mlp.dense_h_to_4h.weight</td>\n",
              "      <td>9437184</td>\n",
              "      <td>True</td>\n",
              "      <td>1179648</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>gpt_neox.layers.11.attention.dense.bias</td>\n",
              "      <td>3072</td>\n",
              "      <td>True</td>\n",
              "      <td>1536</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>gpt_neox.layers.11.mlp.dense_h_to_4h.weight</td>\n",
              "      <td>9437184</td>\n",
              "      <td>True</td>\n",
              "      <td>1179648</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>gpt_neox.layers.11.mlp.dense_h_to_4h.bias</td>\n",
              "      <td>12288</td>\n",
              "      <td>True</td>\n",
              "      <td>6144</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>gpt_neox.layers.11.mlp.dense_4h_to_h.weight</td>\n",
              "      <td>9437184</td>\n",
              "      <td>True</td>\n",
              "      <td>1179648</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>gpt_neox.layers.11.mlp.dense_4h_to_h.bias</td>\n",
              "      <td>3072</td>\n",
              "      <td>True</td>\n",
              "      <td>1536</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>96 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a1dce46-154e-4fc5-a4cd-d2cdd1ace085')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3a1dce46-154e-4fc5-a4cd-d2cdd1ace085 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3a1dce46-154e-4fc5-a4cd-d2cdd1ace085');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8679dca2-fe69-417e-9c9a-f59416e55925\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8679dca2-fe69-417e-9c9a-f59416e55925')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8679dca2-fe69-417e-9c9a-f59416e55925 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"comparison_df\",\n  \"rows\": 96,\n  \"fields\": [\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 96,\n        \"samples\": [\n          \"gpt_neox.layers.10.attention.query_key_value.weight\",\n          \"gpt_neox.layers.9.mlp.dense_h_to_4h.bias\",\n          \"gpt_neox.layers.9.attention.query_key_value.bias\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_parms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4104864,\n        \"min\": 3072,\n        \"max\": 9437184,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          7077888,\n          9216,\n          12288\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"grad\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"q_n_parms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 511982,\n        \"min\": 1536,\n        \"max\": 1179648,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          884736\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"q_grad\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "comparison_df.query('not q_grad')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wslJmZs56wSA"
      },
      "source": [
        "Quantization turned off gradient computation for quantized attention layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zspD1Hm42uw"
      },
      "source": [
        "## Keeping Original Dtypes\n",
        "\n",
        "It is said that increasing precision of some internal layers may help stabilize and improve training.\n",
        "\n",
        "### Head\n",
        "\n",
        "Let's start with the head (`mlp`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7F8oKL3bfmp",
        "outputId": "4b773509-5c6a-496c-f917-35f2235071b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(GPTNeoXMLP(\n",
              "   (dense_h_to_4h): Linear(in_features=768, out_features=3072, bias=True)\n",
              "   (dense_4h_to_h): Linear(in_features=3072, out_features=768, bias=True)\n",
              "   (act): GELUActivation()\n",
              " ),\n",
              " GPTNeoXMLP(\n",
              "   (dense_h_to_4h): Linear4bit(in_features=768, out_features=3072, bias=True)\n",
              "   (dense_4h_to_h): Linear4bit(in_features=3072, out_features=768, bias=True)\n",
              "   (act): GELUActivation()\n",
              " ))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "head = model.gpt_neox.layers[-1].mlp\n",
        "q_head = q_model.gpt_neox.layers[-1].mlp\n",
        "head, q_head"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy9_I2x5MVyb"
      },
      "source": [
        "These weights have been quantized as well, but \"messing with the model's head\" may not be such a good idea."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwWuFc1Kdh8G",
        "outputId": "9997a248-20f3-44cd-b984-33ffc98f6646"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32, torch.uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "head.dense_4h_to_h.weight.dtype, q_head.dense_4h_to_h.weight.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqL_SILSMVyb"
      },
      "source": [
        "Let's use the `llm_int8_skip_modules` argument to keep the `mlp` layer from being quantized. Don't be fooled by the argument's name, it *will* skip the listed modules even if we're quantizing it to 4 bits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JguGnmdwezke",
        "outputId": "a2b9bb99-f2d0-4a19-d1ad-8d46d8e55a4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        }
      ],
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    llm_int8_skip_modules=[\"mlp\"]\n",
        ")\n",
        "\n",
        "# Loads quantized model right away\n",
        "q_model2 = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGYDhNQ-MVyc"
      },
      "source": [
        "Now, let's take a look at the model and its head:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRREhI74hK5S",
        "outputId": "6c4a9f22-8733-47bb-a2c7-0e8532797749"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTNeoXForCausalLM(\n",
              "  (gpt_neox): GPTNeoXModel(\n",
              "    (embed_in): Embedding(50304, 768)\n",
              "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
              "    (layers): ModuleList(\n",
              "      (0-11): 12 x GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXSdpaAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear4bit(in_features=768, out_features=2304, bias=True)\n",
              "          (dense): Linear4bit(in_features=768, out_features=768, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (embed_out): Linear4bit(in_features=768, out_features=50304, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "q_model2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v82Ph-pe6X6",
        "outputId": "17ced285-2d8b-40c7-cd99-72f950d5bc06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTNeoXMLP(\n",
              "  (dense_h_to_4h): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (dense_4h_to_h): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (act): GELUActivation()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "q_model2.gpt_neox.layers[-1].mlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swmc96tFMVyd"
      },
      "source": [
        "How big is it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nBdVbo1e9gn",
        "outputId": "90e30128-c133-4514-bb0b-28744fa4290d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "277.706136\n"
          ]
        }
      ],
      "source": [
        "print(q_model2.get_memory_footprint()/1e6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yptxFLyeMVyd"
      },
      "source": [
        "### Layer Norm\n",
        "\n",
        "Layer norm layers were converted to float16 to save space. However, this may negatively affect performance and stability. Ideally, we'd like to have them as bfloat16 but, should the hardware not support this type, it's probably better to keep them as float32."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpDWWwE0fKLa",
        "outputId": "71a7ebf4-ccf6-40c4-a4f4-8331b999e77d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "q_model2.gpt_neox.final_layer_norm.weight.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEUALU2sMVye"
      },
      "source": [
        "To accomplish this, we can use the `torch_dtype` argument of the `from_pretrained()` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd1zyNSnfGmL",
        "outputId": "2da7701e-9600-4f1e-dc94-7dd98c014d0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        }
      ],
      "source": [
        "# Loads quantized model right away\n",
        "q_model3 = AutoModelForCausalLM.from_pretrained(base_model_id,\n",
        "                                                quantization_config=bnb_config,\n",
        "                                                torch_dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8NSLQZ_hNq7",
        "outputId": "adfe840c-64f3-44a0-a56b-fc61e402f8ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTNeoXForCausalLM(\n",
              "  (gpt_neox): GPTNeoXModel(\n",
              "    (embed_in): Embedding(50304, 768)\n",
              "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
              "    (layers): ModuleList(\n",
              "      (0-11): 12 x GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXSdpaAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear4bit(in_features=768, out_features=2304, bias=True)\n",
              "          (dense): Linear4bit(in_features=768, out_features=768, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (embed_out): Linear4bit(in_features=768, out_features=50304, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "q_model3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nf1cs4XfOcB",
        "outputId": "63941591-caac-4277-bfb7-addb32567727"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "q_model3.gpt_neox.final_layer_norm.weight.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdSUHsioMVyf"
      },
      "source": [
        "The side-effect is that the model is much bigger now (although still smaller than the original):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hHrc9NzfSDR",
        "outputId": "1ac4b2b9-f8a8-448b-96e8-fa164908e7d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "468.462\n"
          ]
        }
      ],
      "source": [
        "print(q_model3.get_memory_footprint()/1e6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1b25ko6MVyg"
      },
      "source": [
        "### Embeddings\n",
        "\n",
        "The embeddings returned as output have also been quantized:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypuCFv_EMVyg",
        "outputId": "1e5db4c2-f466-4b05-db72-5b727753297f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.uint8"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "q_model3.embed_out.weight.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsQZhP4IMVyg",
        "outputId": "56bb1fcb-b2d6-48e3-9768-4a95b405b106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        }
      ],
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    llm_int8_skip_modules=[\"mlp\", \"embed_out\"]\n",
        ")\n",
        "\n",
        "# Loads quantized model right away\n",
        "q_model4 = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, torch_dtype=torch.float16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFff1rYBMVyg",
        "outputId": "8fb724ec-0212-4950-ef7a-77e20d5b63ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "q_model4.embed_out.weight.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFUVIu_vMVyh",
        "outputId": "ca326d99-cd4d-4b07-ab30-b6a5c2f687d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "335.656344\n"
          ]
        }
      ],
      "source": [
        "print(q_model4.get_memory_footprint()/1e6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EKi2SKMMVyh"
      },
      "source": [
        "### Manual Intervention\n",
        "\n",
        "Although convenient, skipping modules and converting layer norm layers to float32 wholesale may offset most of the gains we had with the initial quantization.\n",
        "\n",
        "It's possible to *manually* intervene and cast some types in order to try improving performance and stability without incurring such a high cost in memory space.\n",
        "\n",
        "Beware that these manual interventions may cause your model to break, so be careful and double-check everything."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrgRDEC35eWm"
      },
      "source": [
        "#### Head\n",
        "\n",
        "Now we're casting *only* the output of the last MLP head to float32:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "267RRwcLtZ3p"
      },
      "outputs": [],
      "source": [
        "class CastOutputToFloat(torch.nn.Sequential):\n",
        "    def forward(self, x): return super().forward(x).to(torch.float32)\n",
        "\n",
        "q_model.gpt_neox.layers[-1].mlp = CastOutputToFloat(q_model.gpt_neox.layers[-1].mlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI_1mwBVtn9u",
        "outputId": "f62b9405-791a-4130-c616-d1c817c79642"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CastOutputToFloat(\n",
              "  (0): GPTNeoXMLP(\n",
              "    (dense_h_to_4h): Linear4bit(in_features=768, out_features=3072, bias=True)\n",
              "    (dense_4h_to_h): Linear4bit(in_features=3072, out_features=768, bias=True)\n",
              "    (act): GELUActivation()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "q_model.gpt_neox.layers[-1].mlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ht7I7P_y56_Z"
      },
      "source": [
        "#### Layer Norm\n",
        "\n",
        "The weights and biases of the **final layer norm only** are cast to float32 as well:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcyhApYDef0B",
        "outputId": "bc0155ae-2e24-46bb-e709-021bbfde0d51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "q_model.gpt_neox.final_layer_norm.weight.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "PCy3TXlJMVyj"
      },
      "outputs": [],
      "source": [
        "q_model.gpt_neox.final_layer_norm.weight.data = q_model.gpt_neox.final_layer_norm.weight.data.to(torch.float32)\n",
        "q_model.gpt_neox.final_layer_norm.bias.data = q_model.gpt_neox.final_layer_norm.bias.data.to(torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiBG8O-zMVyj"
      },
      "source": [
        "#### Embeddings\n",
        "\n",
        "In this case, noth manual intervention and skipping modules produce the same result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "0A8nMOJMxel0"
      },
      "outputs": [],
      "source": [
        "q_model.embed_out.weight.data = q_model.embed_out.weight.data.to(torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D10HD2VQuVBz",
        "outputId": "203b71dc-cae7-45cb-9ed6-7dacd83aba8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "q_model.gpt_neox.final_layer_norm.weight.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3-wLlv3MVyk"
      },
      "source": [
        "#### Size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtTtZ8Hj6F8o"
      },
      "source": [
        "These changes increase the model size once again, although it's less than half of its original size:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "revafisNzX6O",
        "outputId": "e24fb915-88f4-4d11-9b1a-1f25f0770719"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "327.991704\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(312.7972640991211, None)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "model_size(q_model)[0], print(q_model.get_memory_footprint()/1e6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGwtUPt79DUz"
      },
      "source": [
        "**IMPORTANT**: if you make this kind of changes - casting and modifying dtypes - **make sure** your model is still capable of producing outputs without breaking:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a46901efeb5a4774856e8e8dcf64834b",
            "205d7c1ed50448658a115f35d5c4846d",
            "424f24aaf797450db4726d23efa82dfd",
            "157367a343de4d508a6f6c2d3cf2f924",
            "8dd90572097d4f47b1cf2b2c974db279",
            "5388eb8007d9439285d0aa06910a9ca9",
            "9d866e441f3a445faa98b13403e14abb",
            "0844f3ab460047be9ebf385c7887757c",
            "8d3c3eb3ab8a400e9bd0c73320009ac5",
            "af7948b99cad40fe9423c1ffc01994b1",
            "bb5b588c39d8402ba1c462c88fcb46b7",
            "401bfd6b8de94d9ba8746862e05cfe16",
            "35149e6be34848da8344563275f991ac",
            "09665b5761a1414db126fc3074b2e8ad",
            "e82daf0e099c4d59bfc994bba5e3e105",
            "400d6f098b85479698a95d92143fab2c",
            "dce07f8e405f4d1f9b256a1d97f9e106",
            "b6bb277130eb4472906fa5424621b4f5",
            "f512ce7b1905423c889577420ba0a9db",
            "5e6854b5235f48d8a73ede7e5017bb01",
            "7a1ce4bb87bd436f8dd8ac3bd7f416ab",
            "b7a056295f464e34a0d8e99832a71181",
            "d9cff4bff2c24a518117ce5e01d9a805",
            "308f8fa1f7ee4f1c9f4e99f1eb6806f4",
            "8dc2721b61c34eabaffd74224db4d638",
            "65f6bb6a0fd74832ba3f7a7cdc7426f2",
            "c0949eacf6684db9b77a88f467f8f2ae",
            "9262e4ad868d49da8f4822a98e1ec7db",
            "e6ca34efbd0d4a2d9caed79299e99402",
            "35c2d5274be64c0da9c0fbf9c0374eca",
            "f2ee9ddbc7dc4345a95781c610bb4368",
            "a2596cd591e548f98bb4fa9530e533a9",
            "567a36b547de4a9ea025ad9248be7cb6"
          ]
        },
        "id": "VI4G-bct811M",
        "outputId": "9d42941a-63fb-4446-cc68-169f7137643d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a46901efeb5a4774856e8e8dcf64834b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "401bfd6b8de94d9ba8746862e05cfe16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9cff4bff2c24a518117ce5e01d9a805"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py:452: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CausalLMOutputWithPast(loss={'logits': tensor([[[823.2774,  13.8725, 823.7270,  ...,  13.9288,  13.8787,  13.9429],\n",
              "         [831.8468,  14.1120, 831.5814,  ...,  14.1692,  14.1238,  14.1848],\n",
              "         [832.4774,  13.7687, 834.7003,  ...,  13.8197,  13.7655,  13.8283]]],\n",
              "       grad_fn=<ToCopyBackward0>), 'past_key_values': ((tensor([[[[-2.8594,  3.1855, -2.2148,  ...,  1.9160, -1.3281, -1.2969],\n",
              "          [-3.7478,  5.8221, -1.3330,  ...,  0.9546, -0.3628,  0.1792],\n",
              "          [ 0.9579,  4.1571, -2.6934,  ...,  1.2578, -1.9883, -0.0756]],\n",
              "\n",
              "         [[ 0.3335,  0.2463, -0.2556,  ..., -1.1885, -0.2783, -2.9297],\n",
              "          [ 0.6544, -3.1055, -3.6083,  ...,  0.0500,  0.0132, -2.7090],\n",
              "          [ 0.3434,  0.3906, -0.9336,  ..., -1.1025,  1.3184, -2.0527]],\n",
              "\n",
              "         [[ 2.8984, -2.2090,  2.9844,  ...,  1.4609,  0.4304,  2.0273],\n",
              "          [ 0.1505, -1.2421,  3.7420,  ...,  0.7734, -0.0315,  2.4121],\n",
              "          [-1.8125, -3.1717,  3.0269,  ...,  0.8047, -1.2207,  3.5117]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 0.1145, -0.0718, -0.6763,  ...,  0.7266,  0.9971, -0.0252],\n",
              "          [-0.4046,  0.5434, -0.7801,  ...,  0.8218,  0.0182,  1.4053],\n",
              "          [ 0.2898,  0.6859, -0.4646,  ...,  1.4473,  0.0674,  1.8779]],\n",
              "\n",
              "         [[ 0.2009,  0.7061, -2.1250,  ..., -0.1711,  1.9443, -1.7031],\n",
              "          [-0.2466, -1.2119, -0.9929,  ..., -0.0346,  0.8574, -0.5288],\n",
              "          [-1.0070, -0.3774, -1.5104,  ...,  0.5322,  0.2284, -1.1836]],\n",
              "\n",
              "         [[ 0.1959,  0.6270,  0.3440,  ..., -1.2676,  0.6021, -2.1445],\n",
              "          [-0.1628, -1.2893, -1.6949,  ..., -0.2421,  0.5518, -1.0205],\n",
              "          [ 0.2641, -0.1469,  0.0287,  ..., -0.9194,  0.3333, -2.8125]]]],\n",
              "       device='cuda:0', grad_fn=<CatBackward0>), tensor([[[[-0.0912,  0.0903, -0.6816,  ..., -0.3005,  0.3496, -0.1708],\n",
              "          [-0.1050,  0.5034, -0.1067,  ...,  0.6094, -0.2761, -0.1379],\n",
              "          [ 0.4695,  0.9175,  0.2487,  ..., -0.2861, -0.6543, -1.3281]],\n",
              "\n",
              "         [[-0.3123, -0.4668,  0.7354,  ...,  0.2142,  0.6616,  0.7627],\n",
              "          [-0.3162,  0.1183,  0.1991,  ...,  0.2898,  0.0493, -0.3811],\n",
              "          [ 0.0953,  0.2236, -0.1953,  ..., -0.0102, -0.1501,  0.8105]],\n",
              "\n",
              "         [[-0.4058, -0.0680,  0.2827,  ...,  0.3647,  0.3557, -0.5981],\n",
              "          [-0.1019,  0.3093, -0.2173,  ..., -0.1223, -0.0133,  0.0482],\n",
              "          [ 0.4539,  0.4829,  0.4683,  ...,  0.6763,  0.0525, -0.7539]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 0.1406, -0.0985, -0.4351,  ...,  0.1582,  0.6562,  0.1671],\n",
              "          [ 0.1870, -0.2859,  0.3752,  ...,  0.3711,  0.2211, -0.0468],\n",
              "          [ 0.1882,  0.8320, -0.4885,  ...,  0.0389, -0.1925, -0.3401]],\n",
              "\n",
              "         [[-0.1013, -0.5859,  0.6904,  ...,  0.0019, -0.2598,  0.5083],\n",
              "          [ 0.4648, -0.3516,  0.8857,  ..., -0.1562, -0.0470,  0.2544],\n",
              "          [-0.4185,  0.0551, -0.2065,  ..., -0.3452, -0.2749, -0.0254]],\n",
              "\n",
              "         [[-0.0555, -0.5366, -0.1924,  ..., -0.1897, -0.3406, -0.0630],\n",
              "          [ 0.1432,  0.0601,  0.0571,  ...,  0.1462, -0.0404, -0.2837],\n",
              "          [ 0.3020,  0.1111, -0.1631,  ..., -0.1793, -0.1611, -0.3091]]]],\n",
              "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[ 2.3086,  2.3027,  2.0391,  ..., -0.1648,  3.0410, -1.1035],\n",
              "          [-0.1358,  0.9994,  0.9690,  ..., -0.5215,  2.3867, -2.4414],\n",
              "          [-0.7037,  3.1894,  2.2266,  ..., -0.4648,  1.4521, -0.9453]],\n",
              "\n",
              "         [[ 4.5039, -2.7402, -0.3857,  ..., -3.3438, -0.1497, -1.4873],\n",
              "          [ 0.1386, -0.1583,  0.0680,  ..., -2.4785, -0.7173, -1.1309],\n",
              "          [-0.3045, -1.9435, -1.5822,  ..., -3.3398, -0.6992, -2.0859]],\n",
              "\n",
              "         [[-2.6641,  3.9688, -4.4453,  ...,  0.9058, -0.0932,  0.5903],\n",
              "          [-3.1620,  3.8472, -4.3430,  ...,  1.2344, -0.5073, -0.1953],\n",
              "          [-2.3964,  4.8910, -4.9610,  ...,  1.2666, -0.4060, -1.2246]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-0.1113, -1.0889, -0.3137,  ...,  0.8354,  0.4307,  0.8403],\n",
              "          [ 0.0840, -0.0964,  0.1320,  ...,  1.3643, -0.8706,  0.3208],\n",
              "          [ 0.0765, -0.6695, -0.2371,  ...,  0.6162, -1.7402,  0.8159]],\n",
              "\n",
              "         [[-0.9312,  1.5977, -0.1072,  ..., -1.0625,  9.9531,  4.6328],\n",
              "          [-0.3221, -0.1964,  1.1807,  ..., -1.1309, 11.0312,  4.1953],\n",
              "          [-1.5343,  1.2656, -0.4718,  ..., -0.0501,  9.8750,  5.1719]],\n",
              "\n",
              "         [[-0.6250,  0.4194,  3.1758,  ...,  1.2246, -1.6719, -0.3193],\n",
              "          [-0.2238,  0.1226,  0.5561,  ...,  0.2837, -0.7334,  0.7295],\n",
              "          [-0.8723, -1.3995,  3.2606,  ...,  1.9092, -0.2085,  0.3828]]]],\n",
              "       device='cuda:0', grad_fn=<CatBackward0>), tensor([[[[ 0.0479,  0.0085,  0.3196,  ...,  0.0123,  0.8359,  0.2537],\n",
              "          [-0.1326, -0.0091,  0.1927,  ..., -0.0580,  0.0206, -0.0167],\n",
              "          [ 0.1569,  0.2856,  0.0124,  ..., -0.5239, -0.3472,  0.1757]],\n",
              "\n",
              "         [[ 0.3350,  0.1722, -0.6719,  ...,  0.3875,  0.1444, -0.5303],\n",
              "          [ 0.0493,  0.0409,  0.1259,  ..., -0.0859,  0.0907,  0.0841],\n",
              "          [ 0.3337, -0.8979, -0.3357,  ...,  0.5962,  0.6602, -0.2710]],\n",
              "\n",
              "         [[-0.3010, -0.0076, -0.2544,  ..., -0.9487, -0.4321, -0.7759],\n",
              "          [-0.2559, -0.6299,  0.1606,  ...,  0.5298, -0.2106, -0.1781],\n",
              "          [ 0.7666, -0.3145,  0.1974,  ..., -0.0078,  0.1251,  0.1360]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 0.5322,  0.5981, -0.2322,  ...,  0.3416, -0.4661,  0.5601],\n",
              "          [-0.0224,  0.0925,  0.0917,  ...,  0.2744, -0.1389,  0.1740],\n",
              "          [-0.6333, -0.8027, -0.5259,  ...,  0.0537, -0.0483, -0.8740]],\n",
              "\n",
              "         [[-0.9810,  0.6396, -0.3877,  ...,  0.2269,  0.2446, -0.2939],\n",
              "          [ 0.0163,  0.4414, -0.2021,  ...,  0.0250,  0.1030, -0.0550],\n",
              "          [-0.1251,  0.8848, -0.2098,  ...,  0.3054, -0.2284,  0.5815]],\n",
              "\n",
              "         [[ 0.3035, -0.3516,  0.9048,  ...,  0.4983,  0.3279,  0.8057],\n",
              "          [-0.1653, -0.0812,  0.5186,  ...,  0.2097,  0.2817,  0.0257],\n",
              "          [ 0.2646,  0.3474,  0.5469,  ...,  0.4417,  0.4395,  0.1360]]]],\n",
              "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.5195e+00, -1.3076e+00,  1.7957e-01,  ...,  1.9062e+00,\n",
              "            1.1680e+00,  2.0000e+00],\n",
              "          [ 9.1177e-02, -6.8679e-01, -2.1264e-01,  ...,  1.3994e+00,\n",
              "            9.7754e-01,  1.1162e+00],\n",
              "          [-1.9547e+00,  5.8611e-01, -8.2095e-01,  ...,  3.4521e-01,\n",
              "            3.8843e-01,  1.9482e+00]],\n",
              "\n",
              "         [[-1.2061e+00, -7.1533e-01, -2.6562e+00,  ..., -1.3652e+00,\n",
              "            2.4453e+00, -1.3145e+00],\n",
              "          [-5.9699e-01, -1.3471e+00, -2.5014e+00,  ..., -2.4199e+00,\n",
              "            2.3027e+00, -8.5938e-01],\n",
              "          [-2.3444e-01, -1.9063e+00, -3.5175e+00,  ..., -1.9590e+00,\n",
              "            3.7129e+00, -7.6807e-01]],\n",
              "\n",
              "         [[ 1.1973e+00,  2.0449e+00, -1.4209e+00,  ...,  5.3516e-01,\n",
              "            1.2830e-01, -2.5415e-01],\n",
              "          [-8.3491e-03,  6.3537e-01, -7.8907e-01,  ...,  9.1455e-01,\n",
              "            5.4443e-01,  1.2463e-01],\n",
              "          [-6.2413e-01,  1.2827e+00, -9.7538e-01,  ...,  3.8257e-01,\n",
              "            1.7451e+00, -2.4500e-01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-2.4863e+00,  2.7285e+00,  1.6260e+00,  ..., -2.3281e+00,\n",
              "           -9.0576e-01,  4.7578e+00],\n",
              "          [ 2.2831e-01,  1.0597e-01,  2.5268e-01,  ..., -2.6099e-01,\n",
              "           -8.4131e-01,  4.1484e+00],\n",
              "          [ 1.2686e+00,  1.6013e+00,  9.4960e-01,  ..., -1.9736e+00,\n",
              "           -1.0376e-01,  4.5312e+00]],\n",
              "\n",
              "         [[-6.2109e-01, -3.7231e-01,  7.0435e-02,  ...,  8.0566e-01,\n",
              "           -4.6753e-02, -4.6484e-01],\n",
              "          [ 2.1734e-01,  4.3149e-01, -2.8174e-01,  ..., -2.9956e-01,\n",
              "            3.1567e-01, -1.0889e+00],\n",
              "          [ 4.7054e-01,  4.2670e-01,  1.0360e+00,  ..., -8.8135e-01,\n",
              "           -9.9121e-01,  6.7261e-02]],\n",
              "\n",
              "         [[ 2.8418e+00, -2.3652e+00, -1.2812e+00,  ...,  6.4355e-01,\n",
              "           -2.7129e+00, -1.4856e-01],\n",
              "          [-2.6498e-01, -5.0950e-01, -3.7970e-03,  ...,  6.1572e-01,\n",
              "           -1.0811e+00, -1.0225e+00],\n",
              "          [-5.7311e-01, -2.9240e+00, -2.2515e+00,  ...,  1.5996e+00,\n",
              "           -7.3096e-01, -2.0293e+00]]]], device='cuda:0',\n",
              "       grad_fn=<CatBackward0>), tensor([[[[ 6.0840e-01, -2.7515e-01,  3.3887e-01,  ..., -2.8857e-01,\n",
              "           -7.9053e-01, -2.8706e-04],\n",
              "          [-1.3696e-01,  5.9662e-02,  1.9104e-01,  ...,  6.8588e-03,\n",
              "           -3.0859e-01, -5.3680e-02],\n",
              "          [-4.5996e-01,  1.1689e+00, -1.5173e-01,  ..., -4.2480e-01,\n",
              "           -7.0898e-01,  2.4353e-01]],\n",
              "\n",
              "         [[-2.8394e-01, -2.4780e-01,  6.5137e-01,  ...,  3.7500e-01,\n",
              "            6.2207e-01, -2.2607e-01],\n",
              "          [ 1.4758e-01,  2.7298e-02, -4.6234e-02,  ...,  1.4636e-01,\n",
              "            5.5847e-02, -5.2155e-02],\n",
              "          [-9.6533e-01,  3.0322e-01, -9.2773e-02,  ...,  1.2474e-02,\n",
              "            2.5757e-01, -3.2007e-01]],\n",
              "\n",
              "         [[-8.0859e-01, -1.2018e-01, -1.3281e-01,  ..., -3.2910e-01,\n",
              "           -4.1577e-01, -3.5913e-01],\n",
              "          [-3.5645e-02, -6.1798e-02,  1.9214e-01,  ...,  1.0361e-02,\n",
              "            4.6997e-02, -2.2534e-01],\n",
              "          [ 3.1104e-01, -1.1660e+00, -3.8916e-01,  ..., -6.1279e-01,\n",
              "           -4.0723e-01,  4.6558e-01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-3.6255e-01, -2.9160e-02,  3.2080e-01,  ...,  4.1260e-01,\n",
              "           -3.4521e-01, -7.0605e-01],\n",
              "          [ 5.8838e-02,  1.8921e-01,  2.4487e-01,  ..., -1.3330e-01,\n",
              "           -3.0502e-02, -1.0645e-01],\n",
              "          [-2.8979e-01, -6.3330e-01, -7.2461e-01,  ...,  5.5176e-01,\n",
              "            5.0781e-01,  5.4297e-01]],\n",
              "\n",
              "         [[-1.5515e-01,  4.1351e-02,  2.4939e-01,  ...,  8.6914e-02,\n",
              "           -5.3027e-01, -2.1655e-01],\n",
              "          [-2.2388e-01,  1.7651e-01, -2.9077e-01,  ...,  7.3280e-03,\n",
              "           -1.0400e-01,  1.5479e-01],\n",
              "          [ 2.0801e-01, -3.8135e-01,  2.0520e-01,  ..., -1.1420e-01,\n",
              "           -5.3613e-01,  3.8666e-02]],\n",
              "\n",
              "         [[-5.4199e-01,  9.4055e-02, -6.4404e-01,  ...,  6.3184e-01,\n",
              "            1.0376e-01,  4.5752e-01],\n",
              "          [ 2.2308e-02, -1.8433e-02,  9.2139e-01,  ...,  4.2065e-01,\n",
              "           -2.6953e-01, -1.4001e-01],\n",
              "          [ 1.2146e-01,  8.9453e-01, -3.9795e-01,  ..., -2.7051e-01,\n",
              "            8.1689e-01,  9.8438e-01]]]], device='cuda:0', dtype=torch.float16,\n",
              "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.3535e+00, -2.4377e-01, -1.2148e+00,  ..., -2.6562e-01,\n",
              "           -9.0186e-01,  2.3984e+00],\n",
              "          [ 1.0631e+00, -4.5209e+00, -4.0060e+00,  ..., -1.3105e+00,\n",
              "           -1.2119e+00,  2.2402e+00],\n",
              "          [-4.7133e+00, -5.4789e+00, -4.6130e+00,  ...,  3.7061e-01,\n",
              "           -8.2910e-01,  2.8223e+00]],\n",
              "\n",
              "         [[-8.5156e-01,  9.2188e-01,  8.4424e-01,  ...,  1.2500e-01,\n",
              "           -1.0137e+00, -2.0176e+00],\n",
              "          [-3.0308e+00,  4.2468e+00,  4.3211e+00,  ..., -1.8250e-01,\n",
              "           -1.5957e+00, -2.0469e+00],\n",
              "          [-2.4765e+00,  4.7136e+00,  5.9474e+00,  ..., -1.8958e-01,\n",
              "           -8.4766e-01, -1.9814e+00]],\n",
              "\n",
              "         [[ 5.4688e-01,  4.8711e+00,  5.1484e+00,  ...,  2.0957e+00,\n",
              "            2.2656e+00, -2.0098e+00],\n",
              "          [ 7.4648e+00,  4.8491e+00,  6.2792e+00,  ...,  1.9453e+00,\n",
              "            2.3203e+00, -2.4414e+00],\n",
              "          [ 3.1274e+00,  3.9703e+00,  6.0811e+00,  ...,  9.5508e-01,\n",
              "            2.2012e+00, -1.1543e+00]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 6.1768e-01,  7.0410e-01, -2.9980e-01,  ..., -1.2578e+00,\n",
              "            4.8535e-01, -3.7383e+00],\n",
              "          [-8.4600e-01,  1.2608e+00, -7.5499e-01,  ..., -1.2842e+00,\n",
              "            3.7695e-01, -4.4219e+00],\n",
              "          [-5.5360e-01,  2.1947e+00, -2.6189e+00,  ..., -1.7412e+00,\n",
              "            1.1143e+00, -3.3438e+00]],\n",
              "\n",
              "         [[-3.8867e-01,  4.9683e-01,  2.6660e-01,  ...,  7.3789e+00,\n",
              "           -7.2975e-03,  6.3438e+00],\n",
              "          [ 3.2623e-01,  5.7602e-01,  1.1721e+00,  ...,  7.7734e+00,\n",
              "           -2.3486e-01,  6.1484e+00],\n",
              "          [ 1.3936e+00, -8.5778e-02, -2.2019e-01,  ...,  7.1836e+00,\n",
              "            5.3760e-01,  5.1445e+00]],\n",
              "\n",
              "         [[-3.3276e-01,  7.0215e-01, -1.5215e+00,  ...,  4.6992e+00,\n",
              "            1.4258e+00, -8.3789e-01],\n",
              "          [ 3.6396e-01,  2.7064e-01, -2.4233e-01,  ...,  3.2031e+00,\n",
              "            1.0273e+00, -4.6216e-01],\n",
              "          [ 1.3421e+00,  1.1581e+00, -1.1163e+00,  ...,  4.8594e+00,\n",
              "            2.4199e+00, -5.9717e-01]]]], device='cuda:0',\n",
              "       grad_fn=<CatBackward0>), tensor([[[[-1.7761e-01,  3.9429e-01,  8.4591e-04,  ...,  2.8467e-01,\n",
              "           -5.6104e-01,  3.0420e-01],\n",
              "          [ 2.3169e-01, -1.2927e-01,  6.2866e-02,  ...,  2.5830e-01,\n",
              "            4.8584e-01,  4.2871e-01],\n",
              "          [-3.7915e-01,  1.7566e-01, -8.1348e-01,  ...,  7.8662e-01,\n",
              "           -6.7688e-02,  4.5776e-01]],\n",
              "\n",
              "         [[-8.4900e-02, -2.1289e-01,  3.6316e-02,  ...,  8.8477e-01,\n",
              "            2.2491e-02,  3.2397e-01],\n",
              "          [-3.1030e-01, -6.3660e-02,  1.2115e-01,  ..., -1.4551e+00,\n",
              "           -1.2177e-01,  3.8525e-01],\n",
              "          [-9.8584e-01,  9.4849e-02,  6.7810e-02,  ...,  4.2822e-01,\n",
              "            4.8291e-01, -1.2793e-01]],\n",
              "\n",
              "         [[ 3.9062e-01, -1.0830e+00, -2.5073e-01,  ...,  5.1562e-01,\n",
              "           -7.1582e-01, -6.4600e-01],\n",
              "          [-2.2473e-01, -1.1660e+00, -1.2396e-01,  ..., -7.5293e-01,\n",
              "            2.0898e-01, -1.0654e+00],\n",
              "          [-5.6543e-01,  1.9199e+00,  2.7783e-01,  ...,  6.1572e-01,\n",
              "           -6.6602e-01,  9.0918e-01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-1.2769e-01,  5.1416e-01, -5.9326e-01,  ..., -9.8816e-02,\n",
              "           -2.6733e-01, -3.0835e-01],\n",
              "          [-2.7051e-01, -1.9983e-01, -1.0199e-01,  ..., -1.4502e-01,\n",
              "            6.1377e-01,  2.4597e-01],\n",
              "          [ 3.2520e-01,  1.8127e-01, -4.0063e-01,  ...,  7.5732e-01,\n",
              "            4.1382e-02,  2.9861e-02]],\n",
              "\n",
              "         [[-2.7124e-01, -3.4454e-02,  4.6234e-02,  ..., -8.5907e-03,\n",
              "           -1.6211e-01,  1.6589e-01],\n",
              "          [-2.5635e-01,  1.2903e-01, -1.2561e-01,  ...,  3.6194e-02,\n",
              "           -1.1304e-01, -3.2349e-02],\n",
              "          [-6.2305e-01, -3.1235e-02,  2.6709e-01,  ...,  1.6528e-01,\n",
              "            2.0386e-01, -5.3027e-01]],\n",
              "\n",
              "         [[ 1.7932e-01, -2.9468e-01, -1.4004e+00,  ..., -3.5474e-01,\n",
              "            1.8079e-01, -1.6260e-01],\n",
              "          [-6.3904e-02, -1.5784e-01, -6.2842e-01,  ...,  4.8682e-01,\n",
              "           -7.1899e-02,  6.5613e-02],\n",
              "          [ 3.6182e-01, -3.1812e-01, -3.5498e-01,  ...,  2.6196e-01,\n",
              "           -2.0667e-01, -5.4054e-03]]]], device='cuda:0', dtype=torch.float16,\n",
              "       grad_fn=<PermuteBackward0>)), (tensor([[[[-1.9470e-01, -2.0337e-01,  2.6196e-01,  ..., -9.0625e+00,\n",
              "           -2.0469e+00,  2.4766e+00],\n",
              "          [ 1.1163e-01, -1.6454e+00,  3.3134e+00,  ..., -9.2656e+00,\n",
              "           -4.2422e+00,  2.1562e+00],\n",
              "          [ 1.1359e+00, -2.1406e+00,  3.0637e+00,  ..., -7.8203e+00,\n",
              "           -1.7705e+00,  3.4902e+00]],\n",
              "\n",
              "         [[-3.0975e-02, -9.8999e-02,  3.2379e-02,  ..., -2.2012e+00,\n",
              "           -2.6484e+00,  2.2168e-01],\n",
              "          [-3.5293e-01, -3.9941e-01,  2.4423e-01,  ..., -3.2754e+00,\n",
              "           -2.5684e+00,  2.8027e-01],\n",
              "          [-1.9135e-02, -2.8050e-01, -1.9924e-01,  ..., -5.0000e+00,\n",
              "           -3.5059e+00,  1.0645e+00]],\n",
              "\n",
              "         [[-2.4139e-02, -5.5908e-02, -4.6120e-03,  ..., -2.7656e+00,\n",
              "            7.2144e-02, -1.3789e+00],\n",
              "          [-8.9721e-01, -2.8765e+00,  2.2858e+00,  ..., -1.0459e+00,\n",
              "           -6.3538e-02, -1.4805e+00],\n",
              "          [ 1.3653e+00, -3.5494e+00,  2.6687e+00,  ..., -1.4023e+00,\n",
              "            3.4058e-01, -1.3789e+00]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 3.7079e-03,  4.0039e-02, -4.0924e-02,  ...,  8.1562e+00,\n",
              "           -6.0352e+00,  4.3320e+00],\n",
              "          [-3.5543e-01, -1.4389e+00,  1.0911e+00,  ...,  6.2344e+00,\n",
              "           -4.9258e+00,  4.7305e+00],\n",
              "          [-7.8165e-01, -2.4743e-01,  5.4793e-01,  ...,  6.7969e+00,\n",
              "           -5.3164e+00,  4.4688e+00]],\n",
              "\n",
              "         [[-6.8848e-02,  1.5491e-01,  8.5327e-02,  ...,  3.5812e+01,\n",
              "           -3.6312e+01, -3.4250e+01],\n",
              "          [-1.1713e-01, -2.9715e-01,  3.9916e-01,  ...,  3.3562e+01,\n",
              "           -3.6438e+01, -3.4062e+01],\n",
              "          [ 2.6837e-01, -2.7897e-01, -1.8501e-01,  ...,  3.3125e+01,\n",
              "           -3.6312e+01, -3.3875e+01]],\n",
              "\n",
              "         [[-8.5571e-02, -5.5466e-03, -1.2769e-01,  ...,  5.7617e+00,\n",
              "            1.1016e+01,  2.0254e+00],\n",
              "          [ 1.5194e-01,  3.0507e-01, -1.5180e+00,  ...,  5.1406e+00,\n",
              "            1.1820e+01,  2.0879e+00],\n",
              "          [-2.3478e-02,  3.0299e-01, -5.2872e-01,  ...,  7.5547e+00,\n",
              "            1.0656e+01,  2.0234e+00]]]], device='cuda:0',\n",
              "       grad_fn=<CatBackward0>), tensor([[[[ 0.0124, -0.0223,  0.0868,  ..., -0.2379,  0.0671,  0.0638],\n",
              "          [-0.3230,  0.0124,  0.6025,  ...,  0.1136,  0.2771,  0.7061],\n",
              "          [ 0.5762,  0.3181, -0.3105,  ..., -0.1138,  1.4834,  0.5825]],\n",
              "\n",
              "         [[-0.1431, -0.1500,  0.4741,  ...,  0.0958,  0.1506, -0.0748],\n",
              "          [-0.0731, -0.1550, -1.0312,  ...,  0.0359,  0.6235, -1.8018],\n",
              "          [-0.0144,  0.1210, -0.5962,  ...,  1.8301,  0.1162, -1.8848]],\n",
              "\n",
              "         [[-0.0981,  0.1576,  0.0247,  ...,  0.1686,  0.0559,  0.1131],\n",
              "          [ 0.1069, -1.2646, -0.4182,  ...,  0.4541, -0.7900,  0.9233],\n",
              "          [ 0.2810,  0.4280, -0.9385,  ...,  0.5918, -1.1445,  0.4075]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 0.5728, -0.5410, -0.1956,  ..., -0.1279,  0.0193,  0.0249],\n",
              "          [-0.2903,  1.4795, -0.6475,  ...,  0.8223,  0.0289,  0.2184],\n",
              "          [ 0.1923,  0.3381, -0.0454,  ...,  0.2517,  0.3730,  0.0380]],\n",
              "\n",
              "         [[-0.0028, -0.0111, -0.1385,  ..., -0.0804,  0.0166,  0.0773],\n",
              "          [-0.0768,  1.8389, -0.6641,  ..., -0.0138, -0.4041,  1.3809],\n",
              "          [-0.1508,  1.2969,  0.3162,  ..., -0.3420, -0.0101,  0.4470]],\n",
              "\n",
              "         [[-0.2722, -0.0242, -0.0208,  ...,  0.0094,  0.0414,  0.0350],\n",
              "          [-0.6377, -0.4290,  0.4314,  ...,  0.2810, -0.2542, -0.0593],\n",
              "          [-1.0332,  0.3259,  0.0639,  ..., -0.5649, -1.2949, -0.2214]]]],\n",
              "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[-3.3569e-03,  1.1353e-02,  1.4880e-01,  ...,  3.3926e+00,\n",
              "            1.4453e+01,  1.6078e+01],\n",
              "          [ 2.8283e-01, -3.8896e-02, -4.6110e-01,  ...,  1.6074e+00,\n",
              "            1.5734e+01,  1.5906e+01],\n",
              "          [-8.5995e-02, -1.2383e-01, -4.1223e-01,  ...,  2.9961e+00,\n",
              "            1.5289e+01,  1.5914e+01]],\n",
              "\n",
              "         [[-5.4443e-02, -3.9581e-02, -3.5187e-02,  ..., -2.1055e+00,\n",
              "           -4.2617e+00, -1.2172e+01],\n",
              "          [ 1.2227e-01, -6.1560e-01,  2.3195e+00,  ..., -2.1035e+00,\n",
              "           -4.1914e+00, -1.2523e+01],\n",
              "          [ 8.3974e-01,  1.7393e-01,  1.8424e+00,  ..., -1.8574e+00,\n",
              "           -4.2305e+00, -1.1023e+01]],\n",
              "\n",
              "         [[ 4.0649e-02,  8.2245e-03, -1.7310e-01,  ..., -2.6297e+01,\n",
              "           -1.9141e+01,  1.3852e+01],\n",
              "          [-8.1994e-01, -6.8560e-01, -1.1787e+00,  ..., -2.5609e+01,\n",
              "           -1.9812e+01,  1.3750e+01],\n",
              "          [-8.3198e-01, -2.2960e-01, -1.0998e+00,  ..., -2.5438e+01,\n",
              "           -1.9891e+01,  1.3555e+01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-1.5076e-01,  2.5345e-02, -1.3782e-01,  ..., -1.3164e+01,\n",
              "            6.1367e+00, -3.3145e+00],\n",
              "          [-4.7555e-01,  1.2342e-01, -1.3879e+00,  ..., -1.2812e+01,\n",
              "            4.7656e+00, -3.2637e+00],\n",
              "          [ 1.0824e-01,  4.2289e-01, -1.5217e+00,  ..., -1.1578e+01,\n",
              "            5.0547e+00, -3.8633e+00]],\n",
              "\n",
              "         [[ 4.3762e-02, -3.5004e-02, -1.7383e-01,  ...,  4.1562e+00,\n",
              "            7.8594e+00,  2.8789e+00],\n",
              "          [-4.1180e-01, -5.8583e-01, -1.6998e+00,  ...,  4.8906e+00,\n",
              "            9.0703e+00,  3.8242e+00],\n",
              "          [-2.7888e-01,  1.5917e-01, -2.9193e-01,  ...,  3.5273e+00,\n",
              "            9.4688e+00,  2.7207e+00]],\n",
              "\n",
              "         [[ 3.4241e-02, -1.5823e-02,  9.0576e-02,  ..., -5.8438e+00,\n",
              "           -6.4258e+00, -3.0328e+01],\n",
              "          [-2.5179e-01, -3.6507e-01,  2.2624e+00,  ..., -5.4102e+00,\n",
              "           -5.9062e+00, -2.8922e+01],\n",
              "          [-1.1087e+00, -1.2112e+00,  2.6533e+00,  ..., -6.2773e+00,\n",
              "           -6.9414e+00, -2.9281e+01]]]], device='cuda:0',\n",
              "       grad_fn=<CatBackward0>), tensor([[[[-8.4381e-03, -4.7150e-02, -9.4849e-02,  ..., -1.4824e-02,\n",
              "           -9.9609e-02, -2.0740e-01],\n",
              "          [ 1.0615e+00,  2.7539e-01, -1.3452e-01,  ..., -1.0083e-01,\n",
              "            8.8525e-01,  6.4209e-01],\n",
              "          [ 1.0264e+00,  5.6396e-01,  1.7764e+00,  ..., -1.2217e+00,\n",
              "           -9.7119e-01,  1.5552e-01]],\n",
              "\n",
              "         [[ 1.2732e-01,  1.7517e-01,  3.9001e-02,  ..., -8.3130e-02,\n",
              "            5.4749e-02,  1.0443e-01],\n",
              "          [-2.9053e-01,  1.5059e+00,  1.1328e+00,  ..., -1.0889e-01,\n",
              "            4.5386e-01,  1.1826e+00],\n",
              "          [-2.6807e-01,  7.1680e-01,  7.3633e-01,  ..., -1.0010e-01,\n",
              "           -1.1551e-02,  4.0283e-01]],\n",
              "\n",
              "         [[ 8.1238e-02, -6.9214e-02, -2.9495e-02,  ..., -4.6051e-02,\n",
              "            2.3834e-02,  8.4167e-02],\n",
              "          [ 7.6660e-01,  1.1786e-01, -5.7861e-01,  ..., -2.3413e-01,\n",
              "           -2.9224e-01,  9.1064e-01],\n",
              "          [ 2.2021e-01,  7.6050e-02, -3.7158e-01,  ...,  5.4077e-02,\n",
              "            6.3965e-01, -1.1493e-01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 6.2500e-02, -1.4001e-01, -1.7639e-01,  ...,  5.8075e-02,\n",
              "           -1.8188e-01, -6.8787e-02],\n",
              "          [-2.6392e-01, -4.5996e-01,  3.9087e-01,  ..., -4.0436e-03,\n",
              "           -6.0944e-02, -6.8945e-01],\n",
              "          [-5.4346e-01, -3.9697e-01, -2.0667e-01,  ..., -5.2002e-01,\n",
              "            5.7812e-01, -1.5361e+00]],\n",
              "\n",
              "         [[-2.8900e-02, -2.3425e-01, -3.2166e-02,  ..., -6.2866e-02,\n",
              "            5.1842e-03,  2.8000e-03],\n",
              "          [ 9.7119e-01, -1.0186e+00,  5.6190e-03,  ..., -5.7617e-02,\n",
              "           -5.3613e-01, -7.9883e-01],\n",
              "          [ 1.0410e+00, -1.7395e-01, -1.2002e+00,  ..., -4.2285e-01,\n",
              "           -8.6572e-01, -7.7588e-01]],\n",
              "\n",
              "         [[ 1.8970e-01,  1.0828e-01,  4.2236e-02,  ..., -9.2285e-02,\n",
              "            1.0956e-01, -1.1475e-01],\n",
              "          [-2.4646e-01,  1.4346e+00,  7.1631e-01,  ..., -4.0698e-01,\n",
              "            4.3311e-01,  6.4160e-01],\n",
              "          [-1.0195e+00,  2.9712e-01,  1.9177e-01,  ...,  4.2603e-01,\n",
              "            1.1896e-01, -1.6928e-03]]]], device='cuda:0', dtype=torch.float16,\n",
              "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 7.1106e-03, -1.4453e-01, -2.7039e-02,  ...,  9.5938e+00,\n",
              "           -1.2602e+01, -1.4688e+01],\n",
              "          [-8.6641e-01, -5.7154e-01,  9.9740e-03,  ...,  8.8047e+00,\n",
              "           -1.1844e+01, -1.3602e+01],\n",
              "          [ 5.3445e-02, -1.1097e-01, -1.2180e-01,  ...,  9.1172e+00,\n",
              "           -1.2398e+01, -1.4844e+01]],\n",
              "\n",
              "         [[-8.1421e-02,  6.6345e-02,  2.8061e-02,  ..., -3.1719e+00,\n",
              "           -2.4231e-01, -7.6836e+00],\n",
              "          [ 2.1990e-01,  8.6712e-02, -3.5788e-01,  ..., -4.1094e+00,\n",
              "            3.0542e-01, -7.2266e+00],\n",
              "          [ 7.8866e-01, -1.6024e-01, -1.0282e+00,  ..., -3.7324e+00,\n",
              "           -4.9927e-01, -7.0664e+00]],\n",
              "\n",
              "         [[ 9.8206e-02,  1.7651e-01,  3.0548e-02,  ...,  2.9219e+01,\n",
              "           -2.2484e+01, -8.2578e+00],\n",
              "          [ 6.4655e-01, -2.1766e-01, -3.1310e+00,  ...,  2.8531e+01,\n",
              "           -2.2531e+01, -7.8750e+00],\n",
              "          [ 1.8109e+00, -1.9519e+00, -2.9511e+00,  ...,  2.8984e+01,\n",
              "           -2.2141e+01, -7.8906e+00]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-8.6792e-02,  5.8136e-03,  8.7585e-02,  ...,  1.4250e+01,\n",
              "            1.4133e+01,  6.2695e+00],\n",
              "          [-4.4606e-01,  5.4342e-01,  1.1756e-01,  ...,  1.3914e+01,\n",
              "            1.4320e+01,  5.9531e+00],\n",
              "          [ 7.7255e-01,  1.6596e+00, -4.7069e-01,  ...,  1.4281e+01,\n",
              "            1.3531e+01,  5.9805e+00]],\n",
              "\n",
              "         [[-1.9012e-02,  3.0838e-02,  1.1346e-01,  ..., -5.2852e+00,\n",
              "           -1.4180e+00, -1.0719e+01],\n",
              "          [ 1.5935e-02, -5.4897e-02,  7.6129e-01,  ..., -4.7266e+00,\n",
              "           -2.0781e+00, -1.0133e+01],\n",
              "          [-2.0688e-01,  4.6308e-01,  3.6455e-01,  ..., -5.4961e+00,\n",
              "           -4.3555e+00, -9.7188e+00]],\n",
              "\n",
              "         [[-5.9875e-02, -1.3989e-01,  4.8462e-02,  ...,  8.7891e+00,\n",
              "            1.2430e+01,  6.6797e+00],\n",
              "          [ 4.3948e-02, -5.4037e-01,  3.5959e-01,  ...,  7.1680e+00,\n",
              "            1.1625e+01,  7.4727e+00],\n",
              "          [ 6.9173e-01, -8.1031e-01, -2.5944e-02,  ...,  8.7031e+00,\n",
              "            1.2820e+01,  7.0977e+00]]]], device='cuda:0',\n",
              "       grad_fn=<CatBackward0>), tensor([[[[ 0.0169, -0.0317,  0.0211,  ...,  0.1536,  0.0546,  0.1375],\n",
              "          [-0.2104,  0.7959, -0.2131,  ..., -0.0516, -0.2222, -0.4521],\n",
              "          [ 0.5186,  1.0537, -0.1718,  ..., -0.2554, -0.1826, -0.6226]],\n",
              "\n",
              "         [[ 0.0035,  0.0892, -0.1724,  ...,  0.1027,  0.2461,  0.1537],\n",
              "          [-0.3638,  0.0620, -1.3359,  ...,  1.0000,  1.0537, -0.0314],\n",
              "          [-0.9102,  0.4143, -0.4150,  ...,  1.9385,  0.5996,  1.1045]],\n",
              "\n",
              "         [[ 0.3164, -0.0329,  0.0747,  ..., -0.0934, -0.0192,  0.0267],\n",
              "          [ 0.0029, -0.0153, -0.2107,  ...,  0.1652, -0.6826,  0.5156],\n",
              "          [-0.9741,  0.2844, -0.5020,  ...,  0.7798, -0.3030,  0.4077]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-0.0222, -0.0295,  0.0649,  ...,  0.0093, -0.1075, -0.0724],\n",
              "          [ 0.9824,  0.6089,  0.6387,  ...,  0.1132, -0.5024, -0.0635],\n",
              "          [ 0.9194, -0.2235,  0.4429,  ...,  0.5967,  0.0698,  0.4075]],\n",
              "\n",
              "         [[-0.0029, -0.1527,  0.0636,  ...,  0.0127,  0.0518, -0.0033],\n",
              "          [-0.5767, -0.4019, -1.0889,  ...,  0.2078,  0.4363,  1.4502],\n",
              "          [ 0.0495, -1.3359, -0.2474,  ...,  0.7510,  0.1176,  0.9360]],\n",
              "\n",
              "         [[-0.0244,  0.0346, -0.0185,  ...,  0.0470, -0.0036,  0.0594],\n",
              "          [ 0.0549,  1.2705, -0.3381,  ..., -0.1680, -0.2354,  0.5566],\n",
              "          [ 0.8584,  0.3499, -0.7246,  ...,  0.2856,  0.0249, -0.5425]]]],\n",
              "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[-1.4941e-01, -8.1635e-03,  3.1033e-03,  ...,  1.3898e+01,\n",
              "           -9.6797e+00, -7.1016e+00],\n",
              "          [ 2.3730e-01, -4.7610e-01,  1.1009e+00,  ...,  1.4211e+01,\n",
              "           -9.9609e+00, -7.5586e+00],\n",
              "          [ 2.8418e-01, -6.0781e-01,  8.4216e-01,  ...,  1.3367e+01,\n",
              "           -1.0453e+01, -7.9375e+00]],\n",
              "\n",
              "         [[ 1.4392e-01, -1.0162e-01,  1.2512e-01,  ...,  1.4945e+01,\n",
              "            2.0250e+01,  2.0328e+01],\n",
              "          [ 1.9344e+00,  2.6728e-01,  4.5022e+00,  ...,  1.4883e+01,\n",
              "            1.9859e+01,  2.0656e+01],\n",
              "          [-1.0841e+00, -2.5963e+00,  4.6759e+00,  ...,  1.5094e+01,\n",
              "            1.9281e+01,  2.0938e+01]],\n",
              "\n",
              "         [[-1.6882e-01, -2.4429e-02, -2.3865e-02,  ..., -1.5734e+01,\n",
              "           -1.2391e+01, -1.6438e+01],\n",
              "          [-1.1191e+00, -3.1371e-02, -9.3288e-01,  ..., -1.6266e+01,\n",
              "           -1.2219e+01, -1.6547e+01],\n",
              "          [ 2.2710e+00,  3.5449e-01, -3.5900e+00,  ..., -1.5195e+01,\n",
              "           -1.3078e+01, -1.6328e+01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 1.0254e-01, -1.9800e-01, -2.7710e-01,  ...,  2.2281e+01,\n",
              "           -2.0828e+01,  1.6078e+01],\n",
              "          [ 1.4818e+00, -2.8781e-01,  1.5584e+00,  ...,  2.1625e+01,\n",
              "           -2.0719e+01,  1.6781e+01],\n",
              "          [-7.9683e-01, -8.3715e-01,  3.6014e-01,  ...,  2.2094e+01,\n",
              "           -2.0125e+01,  1.6750e+01]],\n",
              "\n",
              "         [[ 2.2715e+00,  1.4473e+00,  1.0713e+00,  ...,  3.3562e+01,\n",
              "            3.3469e+01, -3.3469e+01],\n",
              "          [ 1.3355e+01,  8.2235e+00,  8.5833e+00,  ...,  3.4281e+01,\n",
              "            3.4156e+01, -3.4375e+01],\n",
              "          [ 1.8556e+01,  4.4532e+00,  1.1690e+01,  ...,  3.4062e+01,\n",
              "            3.4219e+01, -3.3312e+01]],\n",
              "\n",
              "         [[ 7.6904e-02,  7.7332e-02,  2.5464e-01,  ..., -3.3750e+00,\n",
              "           -4.2930e+00, -7.5879e-01],\n",
              "          [ 1.6920e-01,  2.0815e-01,  5.2202e-01,  ..., -2.7676e+00,\n",
              "           -4.7539e+00, -6.1475e-01],\n",
              "          [ 5.2962e-01, -8.5269e-02,  1.1714e+00,  ..., -4.9878e-01,\n",
              "           -4.4414e+00, -2.1265e-01]]]], device='cuda:0',\n",
              "       grad_fn=<CatBackward0>), tensor([[[[-7.0435e-02,  5.4108e-02, -2.7002e-01,  ...,  3.1982e-02,\n",
              "            1.8896e-01,  1.2292e-01],\n",
              "          [ 3.0981e-01,  3.8208e-01, -6.9824e-01,  ..., -5.2539e-01,\n",
              "            4.7900e-01,  8.2458e-02],\n",
              "          [ 2.0825e-01,  1.4092e+00, -5.8545e-01,  ..., -9.3689e-02,\n",
              "            5.9180e-01, -3.1006e-01]],\n",
              "\n",
              "         [[ 4.1565e-02, -1.0309e-03,  4.3152e-02,  ..., -2.1851e-02,\n",
              "            1.5671e-02,  1.6797e-01],\n",
              "          [ 5.4297e-01, -6.3525e-01, -2.1887e-01,  ...,  7.3242e-01,\n",
              "            6.6895e-02,  3.1471e-03],\n",
              "          [ 3.4424e-01,  4.3750e-01, -5.7364e-04,  ...,  4.4482e-01,\n",
              "           -2.5586e-01, -1.2286e-01]],\n",
              "\n",
              "         [[-3.6285e-02,  3.9856e-02,  2.1790e-02,  ...,  2.7515e-01,\n",
              "            5.4565e-02,  1.7271e-03],\n",
              "          [-4.5581e-01,  3.9478e-01, -7.1167e-02,  ..., -5.4053e-01,\n",
              "           -1.1847e-01, -3.1494e-02],\n",
              "          [-3.3643e-01, -1.2122e-01,  6.7432e-01,  ..., -1.4834e+00,\n",
              "           -1.8042e-01, -3.6450e-01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 2.1103e-02, -4.9829e-04, -4.6143e-02,  ..., -2.2781e-02,\n",
              "            4.9011e-02,  9.6680e-02],\n",
              "          [-8.3679e-02,  1.7212e-01, -2.4048e-01,  ..., -4.5288e-01,\n",
              "           -2.1286e-02, -4.5898e-01],\n",
              "          [ 5.9784e-02, -6.5137e-01, -4.2786e-02,  ..., -9.6582e-01,\n",
              "           -6.3049e-02, -3.2642e-01]],\n",
              "\n",
              "         [[ 2.2385e-02, -1.6724e-02,  5.3787e-03,  ...,  2.2903e-02,\n",
              "            6.6956e-02,  8.0061e-04],\n",
              "          [ 1.3647e-01, -1.7053e-01,  2.1460e-01,  ..., -4.7876e-01,\n",
              "            1.9421e-01,  2.4060e-01],\n",
              "          [ 1.1548e-01, -5.5786e-02, -1.1444e-01,  ...,  1.6281e-02,\n",
              "            6.4746e-01,  1.0391e-02]],\n",
              "\n",
              "         [[-1.8188e-01,  1.5186e-01,  4.3335e-02,  ..., -1.2311e-01,\n",
              "           -3.0029e-01, -1.5955e-01],\n",
              "          [ 8.0994e-02,  1.8799e-01, -1.1289e+00,  ..., -2.5635e-01,\n",
              "           -5.1416e-01, -6.6528e-02],\n",
              "          [-3.3667e-01, -1.2178e+00, -5.7324e-01,  ...,  2.5708e-01,\n",
              "           -5.8398e-01, -1.5498e+00]]]], device='cuda:0', dtype=torch.float16,\n",
              "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 9.2087e-03, -3.1143e-02, -1.6113e-01,  ...,  3.6094e+01,\n",
              "            3.6562e+01, -3.5438e+01],\n",
              "          [ 1.2699e+00,  1.5856e+00, -3.0572e+00,  ...,  3.7094e+01,\n",
              "            3.6688e+01, -3.5969e+01],\n",
              "          [ 2.3921e+00, -1.0625e+00, -1.7823e+00,  ...,  3.6219e+01,\n",
              "            3.6469e+01, -3.5812e+01]],\n",
              "\n",
              "         [[ 2.1191e-01, -3.1641e-01, -3.9795e-01,  ...,  3.6719e+01,\n",
              "           -2.2703e+01,  3.4594e+01],\n",
              "          [ 2.1323e+00,  2.4994e-01, -3.8380e-01,  ...,  3.7000e+01,\n",
              "           -2.2188e+01,  3.4156e+01],\n",
              "          [ 1.0759e+00,  2.1143e+00,  2.7951e-01,  ...,  3.7500e+01,\n",
              "           -2.3031e+01,  3.4719e+01]],\n",
              "\n",
              "         [[ 1.1768e-01, -1.3745e-01, -1.5808e-01,  ..., -2.6828e+01,\n",
              "            3.1219e+01,  2.7812e+01],\n",
              "          [ 2.1017e-01, -3.4010e-01,  4.7792e-01,  ..., -2.6531e+01,\n",
              "            3.1344e+01,  2.8391e+01],\n",
              "          [-3.3030e-02, -1.5540e-01,  1.5497e+00,  ..., -2.6094e+01,\n",
              "            3.1312e+01,  2.7016e+01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-2.9659e-03,  6.2256e-02, -9.5825e-02,  ..., -2.0000e+01,\n",
              "            1.6422e+01,  2.1938e+01],\n",
              "          [-5.7265e-01,  2.9532e-01,  2.6854e-01,  ..., -1.9609e+01,\n",
              "            1.7516e+01,  2.1797e+01],\n",
              "          [-7.2938e-01,  1.0463e+00,  2.9088e+00,  ..., -1.9719e+01,\n",
              "            1.6516e+01,  2.1734e+01]],\n",
              "\n",
              "         [[ 6.7688e-02, -2.3022e-01,  1.6125e-01,  ...,  6.9062e+00,\n",
              "            1.8688e+01, -1.1703e+01],\n",
              "          [ 3.5246e-01, -8.5210e-01, -4.9979e-01,  ...,  7.4219e+00,\n",
              "            1.8766e+01, -1.2453e+01],\n",
              "          [-1.5539e-01, -1.4006e+00, -1.3663e+00,  ...,  6.9062e+00,\n",
              "            1.9375e+01, -1.2500e+01]],\n",
              "\n",
              "         [[-4.7333e-02, -4.1046e-02,  6.5820e-01,  ...,  2.2469e+01,\n",
              "            1.6984e+01,  2.0172e+01],\n",
              "          [ 4.1025e-01,  4.6595e-01,  2.6348e+00,  ...,  2.1969e+01,\n",
              "            1.6781e+01,  2.0234e+01],\n",
              "          [-2.8452e-01,  1.2939e-01,  2.1272e+00,  ...,  2.1719e+01,\n",
              "            1.7453e+01,  2.1078e+01]]]], device='cuda:0',\n",
              "       grad_fn=<CatBackward0>), tensor([[[[-0.0798,  0.0859, -0.1469,  ..., -0.1265, -0.1857, -0.0127],\n",
              "          [-0.5859,  0.2805, -0.0648,  ..., -0.4299, -0.5527,  0.9380],\n",
              "          [-0.6729, -0.0748, -0.3501,  ...,  0.2454,  0.3003,  1.3701]],\n",
              "\n",
              "         [[-0.0250,  0.2241, -0.1105,  ..., -0.0458,  0.0090, -0.0064],\n",
              "          [ 0.4092,  0.4390,  0.4443,  ..., -0.8354,  0.1268, -0.1787],\n",
              "          [ 0.3572,  0.3982,  0.8433,  ..., -0.4998, -0.1635, -0.0035]],\n",
              "\n",
              "         [[-0.1184,  0.0550,  0.0201,  ...,  0.2001, -0.1528,  0.0195],\n",
              "          [ 0.2080,  0.1243, -0.3904,  ...,  0.0591,  0.3018, -0.2263],\n",
              "          [ 0.2273, -0.2213, -0.5718,  ...,  0.4575, -0.6611,  0.3914]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-0.1479, -0.0853, -0.1573,  ...,  0.0092, -0.0247,  0.0105],\n",
              "          [ 0.8760,  0.2012,  0.0524,  ...,  0.2029, -0.1803,  0.0876],\n",
              "          [ 0.6294,  0.7344,  0.6655,  ...,  0.1214,  0.9995,  1.3486]],\n",
              "\n",
              "         [[-0.0087, -0.0705,  0.0342,  ...,  0.0384,  0.1458, -0.0648],\n",
              "          [ 0.4387, -0.1895,  0.3914,  ...,  0.1036, -0.3655,  0.3447],\n",
              "          [-0.0790,  0.4619,  0.4009,  ...,  0.7178, -0.4680,  1.3467]],\n",
              "\n",
              "         [[-0.0575, -0.0912,  0.0887,  ...,  0.0790,  0.1707,  0.2478],\n",
              "          [-0.1479, -1.0498, -0.0580,  ...,  0.0778,  0.6621, -0.9082],\n",
              "          [-0.1760, -0.4824,  1.3486,  ...,  1.1045,  1.1572, -0.4355]]]],\n",
              "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[ 6.8298e-02,  9.6863e-02, -6.7932e-02,  ..., -4.6211e+00,\n",
              "            1.9000e+01,  1.3617e+01],\n",
              "          [ 1.9294e-01,  6.6215e-01, -5.2146e-01,  ..., -5.2891e+00,\n",
              "            1.8359e+01,  1.3859e+01],\n",
              "          [ 1.1853e+00,  5.1532e-01, -2.1138e+00,  ..., -2.3945e+00,\n",
              "            1.8141e+01,  1.3148e+01]],\n",
              "\n",
              "         [[-6.5613e-02,  9.2712e-02,  2.1216e-01,  ..., -3.8531e+01,\n",
              "           -3.5469e+01, -3.4875e+01],\n",
              "          [ 4.0771e+00,  4.3657e-01,  4.9251e+00,  ..., -3.8281e+01,\n",
              "           -3.5500e+01, -3.6750e+01],\n",
              "          [ 3.9263e+00,  2.3020e-01,  3.8285e+00,  ..., -3.7781e+01,\n",
              "           -3.5000e+01, -3.6438e+01]],\n",
              "\n",
              "         [[ 7.4036e-02, -3.5620e-01,  7.2510e-01,  ..., -3.4812e+01,\n",
              "           -3.0016e+01, -2.7078e+01],\n",
              "          [-4.6206e-01, -1.0701e+00,  9.6159e-01,  ..., -3.5906e+01,\n",
              "           -2.9625e+01, -2.8156e+01],\n",
              "          [ 2.3841e-02,  1.3266e+00,  1.6264e+00,  ..., -3.6312e+01,\n",
              "           -3.0109e+01, -2.7609e+01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 5.5084e-02,  2.9785e-01, -4.0126e-04,  ...,  3.0734e+01,\n",
              "            4.4297e+00, -2.1969e+01],\n",
              "          [ 6.5086e-01,  1.3108e+00,  1.7117e+00,  ...,  3.1484e+01,\n",
              "            1.4404e+00, -2.1734e+01],\n",
              "          [-1.6960e-01,  1.4831e+00,  2.8676e+00,  ...,  3.2188e+01,\n",
              "            4.5093e-01, -2.1297e+01]],\n",
              "\n",
              "         [[-2.4139e-02,  9.3262e-02, -5.7587e-02,  ..., -1.6094e+01,\n",
              "            1.2688e+01, -1.9953e+01],\n",
              "          [-1.9646e+00,  3.2521e-01, -2.4304e+00,  ..., -1.6234e+01,\n",
              "            1.2445e+01, -1.9875e+01],\n",
              "          [-1.4476e+00, -7.5989e-01, -3.4542e+00,  ..., -1.7391e+01,\n",
              "            1.3438e+01, -1.9562e+01]],\n",
              "\n",
              "         [[ 1.4844e-01, -5.6519e-02, -4.3671e-02,  ...,  2.8156e+01,\n",
              "            2.4969e+01, -2.7500e+01],\n",
              "          [ 9.1808e-01, -1.6897e-01, -1.4622e+00,  ...,  2.8109e+01,\n",
              "            2.5484e+01, -2.7594e+01],\n",
              "          [-3.3883e-02, -6.4924e-01, -7.2861e-01,  ...,  2.8344e+01,\n",
              "            2.6500e+01, -2.7969e+01]]]], device='cuda:0',\n",
              "       grad_fn=<CatBackward0>), tensor([[[[-2.0325e-01, -7.2571e-02,  1.3159e-01,  ...,  2.9205e-02,\n",
              "            2.1683e-02,  1.2619e-02],\n",
              "          [-6.5234e-01, -5.9912e-01,  1.4380e-01,  ..., -3.0298e-01,\n",
              "            2.5732e-01,  3.2788e-01],\n",
              "          [ 4.1687e-02, -2.3901e-01,  8.0994e-02,  ..., -1.3770e-01,\n",
              "           -2.8267e-03, -3.9966e-01]],\n",
              "\n",
              "         [[ 1.6144e-02, -2.7557e-02, -2.2831e-03,  ..., -1.0577e-01,\n",
              "            1.1279e-01, -9.8877e-02],\n",
              "          [-2.2656e-01, -1.2189e-01,  7.1259e-03,  ..., -4.1382e-01,\n",
              "           -3.8574e-01, -4.2676e-01],\n",
              "          [-3.2837e-01,  3.6987e-02, -1.1530e-03,  ..., -3.7671e-01,\n",
              "           -6.1816e-01, -4.6484e-01]],\n",
              "\n",
              "         [[ 1.2415e-01,  6.2027e-03, -4.7058e-02,  ..., -7.8491e-02,\n",
              "           -1.0870e-01,  3.7048e-02],\n",
              "          [ 6.0156e-01,  4.0015e-01,  3.8086e-01,  ..., -8.8745e-02,\n",
              "           -4.7852e-01,  1.7883e-01],\n",
              "          [-1.2976e-01,  5.2734e-01,  3.1030e-01,  ...,  7.6721e-02,\n",
              "           -3.1274e-01,  3.0005e-01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-2.9892e-02,  9.7046e-02,  1.0498e-01,  ...,  4.3976e-02,\n",
              "            1.2915e-01,  1.1060e-01],\n",
              "          [-2.4878e-01, -1.9885e-01,  9.1858e-02,  ..., -5.0293e-01,\n",
              "            4.8999e-01,  2.3694e-01],\n",
              "          [-4.0698e-01,  7.8430e-02,  2.9614e-01,  ..., -4.3433e-01,\n",
              "            1.1115e-01, -1.5576e+00]],\n",
              "\n",
              "         [[ 3.3569e-02, -1.1176e-01, -8.2458e-02,  ..., -5.3009e-02,\n",
              "           -1.8835e-01,  5.2399e-02],\n",
              "          [-5.8203e-01, -6.8457e-01,  2.4390e-01,  ..., -9.8511e-02,\n",
              "           -9.1748e-01,  3.8208e-01],\n",
              "          [-1.4648e-01,  8.9722e-02, -4.5443e-04,  ..., -1.3843e-01,\n",
              "           -6.7200e-02, -2.5757e-01]],\n",
              "\n",
              "         [[ 2.9953e-02,  1.0992e-01, -9.2773e-02,  ..., -1.0666e-02,\n",
              "            9.9548e-02,  6.1401e-02],\n",
              "          [-7.4463e-01,  8.0469e-01, -8.1348e-01,  ...,  3.3936e-01,\n",
              "            5.0244e-01, -8.4290e-02],\n",
              "          [-7.1826e-01,  3.5278e-01, -4.8779e-01,  ...,  1.7505e-01,\n",
              "            3.8208e-02, -3.8257e-01]]]], device='cuda:0', dtype=torch.float16,\n",
              "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 2.9114e-02,  1.9910e-01,  7.7246e-01,  ..., -3.4625e+01,\n",
              "            3.4906e+01,  3.7281e+01],\n",
              "          [ 4.9966e-01, -3.0665e-01, -1.2154e+00,  ..., -3.3250e+01,\n",
              "            3.4625e+01,  3.7812e+01],\n",
              "          [ 1.3882e+00, -2.0577e+00,  1.8870e+00,  ..., -3.3094e+01,\n",
              "            3.3750e+01,  3.7562e+01]],\n",
              "\n",
              "         [[ 1.3203e+00,  1.2051e+00, -1.2930e+00,  ...,  3.7938e+01,\n",
              "           -3.6812e+01, -3.6781e+01],\n",
              "          [-1.8897e+00, -1.3111e+00, -2.4537e+00,  ...,  3.7750e+01,\n",
              "           -3.7219e+01, -3.7469e+01],\n",
              "          [-1.0560e+01,  2.2972e+00, -6.8253e+00,  ...,  3.7938e+01,\n",
              "           -3.6844e+01, -3.7781e+01]],\n",
              "\n",
              "         [[ 1.2680e-02,  1.1047e-01, -1.8042e-01,  ...,  4.1219e+01,\n",
              "            3.9375e+01,  4.0750e+01],\n",
              "          [-2.0351e+00,  2.4810e+00, -1.3634e+00,  ...,  4.0906e+01,\n",
              "            3.8688e+01,  4.0500e+01],\n",
              "          [-1.6785e+00,  6.6483e+00, -3.1171e+00,  ...,  4.0969e+01,\n",
              "            3.8906e+01,  4.0750e+01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 2.3633e-01,  4.0436e-02, -3.5327e-01,  ..., -3.2531e+01,\n",
              "           -3.3375e+01, -2.1891e+01],\n",
              "          [-1.8898e+00, -1.6708e+00, -3.9886e+00,  ..., -3.2281e+01,\n",
              "           -3.3594e+01, -2.2047e+01],\n",
              "          [-6.2288e+00, -5.2466e+00, -5.7415e+00,  ..., -3.1969e+01,\n",
              "           -3.3594e+01, -2.2125e+01]],\n",
              "\n",
              "         [[ 1.0364e-01,  5.8105e-01, -5.4541e-01,  ...,  3.3719e+01,\n",
              "           -3.1344e+01, -3.6125e+01],\n",
              "          [-5.9550e-01,  6.2316e-01, -8.8913e-01,  ...,  3.4594e+01,\n",
              "           -3.1125e+01, -3.6438e+01],\n",
              "          [-1.4353e+00, -9.7836e-01, -1.3167e+00,  ...,  3.3844e+01,\n",
              "           -3.1703e+01, -3.6281e+01]],\n",
              "\n",
              "         [[ 5.9448e-02,  1.4075e-01, -2.1448e-01,  ..., -3.2406e+01,\n",
              "            3.3594e+01,  3.5250e+01],\n",
              "          [-1.8187e+00,  2.6845e+00, -2.3209e+00,  ..., -3.1469e+01,\n",
              "            3.3562e+01,  3.5406e+01],\n",
              "          [ 9.3194e-01,  9.1698e-01,  1.7794e-01,  ..., -3.1438e+01,\n",
              "            3.2406e+01,  3.6344e+01]]]], device='cuda:0',\n",
              "       grad_fn=<CatBackward0>), tensor([[[[ 0.0898,  0.0355,  0.0019,  ...,  0.0264,  0.0807,  0.1274],\n",
              "          [-0.1481,  0.5190,  0.1521,  ...,  0.6763,  0.3708,  0.3313],\n",
              "          [-0.2094,  0.5942, -0.6768,  ..., -0.0341,  0.7095,  0.0603]],\n",
              "\n",
              "         [[-0.1132,  0.0476, -0.0826,  ..., -0.0110, -0.1267, -0.0196],\n",
              "          [-0.4995, -0.0676, -0.1495,  ...,  0.1934,  0.5420,  0.1152],\n",
              "          [-0.3450,  0.1556, -0.0792,  ...,  0.2981,  0.5854,  0.1000]],\n",
              "\n",
              "         [[ 0.0141, -0.1080, -0.0577,  ...,  0.0928, -0.0422, -0.0147],\n",
              "          [-0.0953, -0.1445,  0.2393,  ...,  0.1965,  0.0269, -0.0921],\n",
              "          [-0.1682,  0.5020,  0.2795,  ..., -0.6353,  0.3650,  0.1122]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 0.0726,  0.0828, -0.1123,  ..., -0.0177,  0.0911,  0.1092],\n",
              "          [ 0.1270, -0.3772, -0.4097,  ..., -0.0772, -0.0450,  0.4053],\n",
              "          [-0.5005,  0.2654, -1.3730,  ...,  0.0439, -0.4888,  0.2158]],\n",
              "\n",
              "         [[-0.0899,  0.0703, -0.1056,  ...,  0.0482, -0.1067, -0.0293],\n",
              "          [-0.0266,  0.7119, -0.4194,  ...,  0.6753,  0.0418, -0.2184],\n",
              "          [-0.2209,  0.7534, -0.6465,  ...,  0.3333,  0.4712, -0.8281]],\n",
              "\n",
              "         [[ 0.0861, -0.0723, -0.0474,  ..., -0.0349, -0.0994, -0.0175],\n",
              "          [ 0.7085,  0.0701, -0.3767,  ..., -0.2466, -0.0561,  0.4812],\n",
              "          [ 1.0742,  0.4802, -0.7861,  ..., -0.4314, -0.2419,  0.4648]]]],\n",
              "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[ 5.8496e-01,  5.2783e-01, -9.3460e-03,  ..., -3.9000e+01,\n",
              "            3.8750e+01,  3.7094e+01],\n",
              "          [-2.7582e+00, -2.1096e+00, -1.2514e+01,  ..., -3.8562e+01,\n",
              "            3.9156e+01,  3.7406e+01],\n",
              "          [-1.7022e+01, -8.3549e+00, -2.3240e+01,  ..., -3.8094e+01,\n",
              "            3.8844e+01,  3.7656e+01]],\n",
              "\n",
              "         [[-2.0554e-02,  9.3945e-01, -1.9702e-01,  ..., -3.6906e+01,\n",
              "           -3.6281e+01, -3.7281e+01],\n",
              "          [-7.8843e+00,  3.8061e+00,  1.5948e+00,  ..., -3.8031e+01,\n",
              "           -3.5844e+01, -3.5281e+01],\n",
              "          [-1.4353e+01,  4.7767e+00,  5.2274e+00,  ..., -3.8156e+01,\n",
              "           -3.7125e+01, -3.6219e+01]],\n",
              "\n",
              "         [[ 3.3281e+00,  2.6978e-01, -1.9580e+00,  ..., -3.7469e+01,\n",
              "            3.7594e+01, -3.5281e+01],\n",
              "          [ 1.6504e+01,  9.3995e+00, -1.2942e+01,  ..., -3.7562e+01,\n",
              "            3.8375e+01, -3.5156e+01],\n",
              "          [ 2.1464e+00,  1.9727e+01, -1.9439e+01,  ..., -3.7594e+01,\n",
              "            3.7719e+01, -3.6562e+01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-6.1377e-01,  1.8770e+00, -1.5596e+00,  ..., -3.6969e+01,\n",
              "            3.7188e+01,  3.6969e+01],\n",
              "          [-7.0680e+00,  9.3587e+00, -1.5057e+00,  ..., -3.6844e+01,\n",
              "            3.8188e+01,  3.7156e+01],\n",
              "          [-1.1815e+00,  1.0855e+01, -5.6100e+00,  ..., -3.6688e+01,\n",
              "            3.7000e+01,  3.8156e+01]],\n",
              "\n",
              "         [[-1.1445e+00, -2.8555e+00,  3.4980e+00,  ..., -3.2406e+01,\n",
              "            3.2375e+01, -3.5250e+01],\n",
              "          [ 7.3835e+00, -1.2554e+01,  6.5976e+00,  ..., -3.3125e+01,\n",
              "            2.9266e+01, -3.4938e+01],\n",
              "          [ 1.8788e+01, -1.3041e+01,  1.3906e+01,  ..., -3.3156e+01,\n",
              "            2.9594e+01, -3.5312e+01]],\n",
              "\n",
              "         [[-1.1143e+00,  2.0703e+00, -1.6172e+00,  ...,  3.3906e+01,\n",
              "            3.5656e+01, -2.9156e+01],\n",
              "          [-3.6210e-01,  8.6655e+00, -4.2762e+00,  ...,  3.3281e+01,\n",
              "            3.5438e+01, -2.8406e+01],\n",
              "          [ 2.6040e+00,  1.1524e+01, -3.9993e+00,  ...,  3.3125e+01,\n",
              "            3.5906e+01, -2.8609e+01]]]], device='cuda:0',\n",
              "       grad_fn=<CatBackward0>), tensor([[[[-6.1963e-01,  6.5857e-02, -7.4951e-01,  ..., -1.3257e-01,\n",
              "            2.5375e-02, -1.1304e-01],\n",
              "          [-9.4287e-01, -1.6833e-01, -7.2803e-01,  ..., -2.6514e-01,\n",
              "            6.0254e-01,  5.7037e-02],\n",
              "          [-1.0781e+00, -8.9539e-02, -1.3213e+00,  ..., -1.5552e-01,\n",
              "           -6.6895e-02,  4.3121e-02]],\n",
              "\n",
              "         [[-2.1225e-02,  1.3049e-01, -3.8477e-01,  ...,  1.0693e-01,\n",
              "           -5.7945e-03, -4.8859e-02],\n",
              "          [ 1.2927e-01,  7.3291e-01,  1.0271e-03,  ...,  2.3425e-01,\n",
              "            1.1792e-01,  1.4258e-01],\n",
              "          [ 4.5996e-01,  4.6436e-01, -6.2109e-01,  ...,  8.7280e-02,\n",
              "           -2.7490e-01,  8.6121e-02]],\n",
              "\n",
              "         [[-1.0049e+00,  2.5482e-02,  1.8286e-01,  ..., -1.7993e-01,\n",
              "            3.8940e-02,  5.9277e-01],\n",
              "          [-1.6436e+00,  6.5247e-02,  4.0503e-01,  ..., -2.9443e-01,\n",
              "            6.1768e-01,  1.1611e+00],\n",
              "          [-1.2725e+00, -6.6064e-01,  6.3916e-01,  ...,  1.3806e-01,\n",
              "            3.6035e-01,  5.1904e-01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 5.8716e-02,  4.7363e-02, -8.2458e-02,  ...,  8.7158e-01,\n",
              "            6.2378e-02, -7.5928e-02],\n",
              "          [-1.7236e-01,  6.2451e-01, -2.7344e-01,  ...,  1.1113e+00,\n",
              "           -3.1348e-01, -2.1851e-01],\n",
              "          [-6.8848e-02,  3.0273e-01, -4.7046e-01,  ...,  1.1621e+00,\n",
              "           -2.1814e-01, -1.4294e-01]],\n",
              "\n",
              "         [[ 2.3651e-02, -1.6711e-01, -1.1969e-01,  ..., -2.6535e-02,\n",
              "           -1.1147e-02, -7.6721e-02],\n",
              "          [-2.4011e-01, -5.8887e-01,  9.1095e-03,  ..., -4.1162e-01,\n",
              "            2.4341e-01,  1.4084e-02],\n",
              "          [-4.3018e-01, -3.8361e-02, -6.3232e-02,  ..., -4.5386e-01,\n",
              "            6.5625e-01, -1.8036e-02]],\n",
              "\n",
              "         [[ 4.0918e-01, -1.0681e-01,  1.5344e-01,  ..., -2.7563e-01,\n",
              "            3.3301e-01, -4.0192e-02],\n",
              "          [ 5.2881e-01, -1.3354e-01,  5.9509e-04,  ..., -5.7373e-01,\n",
              "            3.2910e-01,  3.5229e-01],\n",
              "          [ 1.2168e+00, -1.0040e-01, -1.2842e-01,  ..., -6.3623e-01,\n",
              "            6.3281e-01, -2.5317e-01]]]], device='cuda:0', dtype=torch.float16,\n",
              "       grad_fn=<PermuteBackward0>)))}, logits=tensor([[[823.2774,  13.8725, 823.7270,  ...,  13.9288,  13.8787,  13.9429],\n",
              "         [831.8468,  14.1120, 831.5814,  ...,  14.1692,  14.1238,  14.1848],\n",
              "         [832.4774,  13.7687, 834.7003,  ...,  13.8197,  13.7655,  13.8283]]],\n",
              "       grad_fn=<ToCopyBackward0>), past_key_values=((tensor([[[[-2.8594,  3.1855, -2.2148,  ...,  1.9160, -1.3281, -1.2969],\n",
              "          [-3.7478,  5.8221, -1.3330,  ...,  0.9546, -0.3628,  0.1792],\n",
              "          [ 0.9579,  4.1571, -2.6934,  ...,  1.2578, -1.9883, -0.0756]],\n",
              "\n",
              "         [[ 0.3335,  0.2463, -0.2556,  ..., -1.1885, -0.2783, -2.9297],\n",
              "          [ 0.6544, -3.1055, -3.6083,  ...,  0.0500,  0.0132, -2.7090],\n",
              "          [ 0.3434,  0.3906, -0.9336,  ..., -1.1025,  1.3184, -2.0527]],\n",
              "\n",
              "         [[ 2.8984, -2.2090,  2.9844,  ...,  1.4609,  0.4304,  2.0273],\n",
              "          [ 0.1505, -1.2421,  3.7420,  ...,  0.7734, -0.0315,  2.4121],\n",
              "          [-1.8125, -3.1717,  3.0269,  ...,  0.8047, -1.2207,  3.5117]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 0.1145, -0.0718, -0.6763,  ...,  0.7266,  0.9971, -0.0252],\n",
              "          [-0.4046,  0.5434, -0.7801,  ...,  0.8218,  0.0182,  1.4053],\n",
              "          [ 0.2898,  0.6859, -0.4646,  ...,  1.4473,  0.0674,  1.8779]],\n",
              "\n",
              "         [[ 0.2009,  0.7061, -2.1250,  ..., -0.1711,  1.9443, -1.7031],\n",
              "          [-0.2466, -1.2119, -0.9929,  ..., -0.0346,  0.8574, -0.5288],\n",
              "          [-1.0070, -0.3774, -1.5104,  ...,  0.5322,  0.2284, -1.1836]],\n",
              "\n",
              "         [[ 0.1959,  0.6270,  0.3440,  ..., -1.2676,  0.6021, -2.1445],\n",
              "          [-0.1628, -1.2893, -1.6949,  ..., -0.2421,  0.5518, -1.0205],\n",
              "          [ 0.2641, -0.1469,  0.0287,  ..., -0.9194,  0.3333, -2.8125]]]],\n",
              "       device='cuda:0', grad_fn=<CatBackward0>), tensor([[[[-0.0912,  0.0903, -0.6816,  ..., -0.3005,  0.3496, -0.1708],\n",
              "          [-0.1050,  0.5034, -0.1067,  ...,  0.6094, -0.2761, -0.1379],\n",
              "          [ 0.4695,  0.9175,  0.2487,  ..., -0.2861, -0.6543, -1.3281]],\n",
              "\n",
              "         [[-0.3123, -0.4668,  0.7354,  ...,  0.2142,  0.6616,  0.7627],\n",
              "          [-0.3162,  0.1183,  0.1991,  ...,  0.2898,  0.0493, -0.3811],\n",
              "          [ 0.0953,  0.2236, -0.1953,  ..., -0.0102, -0.1501,  0.8105]],\n",
              "\n",
              "         [[-0.4058, -0.0680,  0.2827,  ...,  0.3647,  0.3557, -0.5981],\n",
              "          [-0.1019,  0.3093, -0.2173,  ..., -0.1223, -0.0133,  0.0482],\n",
              "          [ 0.4539,  0.4829,  0.4683,  ...,  0.6763,  0.0525, -0.7539]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 0.1406, -0.0985, -0.4351,  ...,  0.1582,  0.6562,  0.1671],\n",
              "          [ 0.1870, -0.2859,  0.3752,  ...,  0.3711,  0.2211, -0.0468],\n",
              "          [ 0.1882,  0.8320, -0.4885,  ...,  0.0389, -0.1925, -0.3401]],\n",
              "\n",
              "         [[-0.1013, -0.5859,  0.6904,  ...,  0.0019, -0.2598,  0.5083],\n",
              "          [ 0.4648, -0.3516,  0.8857,  ..., -0.1562, -0.0470,  0.2544],\n",
              "          [-0.4185,  0.0551, -0.2065,  ..., -0.3452, -0.2749, -0.0254]],\n",
              "\n",
              "         [[-0.0555, -0.5366, -0.1924,  ..., -0.1897, -0.3406, -0.0630],\n",
              "          [ 0.1432,  0.0601,  0.0571,  ...,  0.1462, -0.0404, -0.2837],\n",
              "          [ 0.3020,  0.1111, -0.1631,  ..., -0.1793, -0.1611, -0.3091]]]],\n",
              "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[ 2.3086,  2.3027,  2.0391,  ..., -0.1648,  3.0410, -1.1035],\n",
              "          [-0.1358,  0.9994,  0.9690,  ..., -0.5215,  2.3867, -2.4414],\n",
              "          [-0.7037,  3.1894,  2.2266,  ..., -0.4648,  1.4521, -0.9453]],\n",
              "\n",
              "         [[ 4.5039, -2.7402, -0.3857,  ..., -3.3438, -0.1497, -1.4873],\n",
              "          [ 0.1386, -0.1583,  0.0680,  ..., -2.4785, -0.7173, -1.1309],\n",
              "          [-0.3045, -1.9435, -1.5822,  ..., -3.3398, -0.6992, -2.0859]],\n",
              "\n",
              "         [[-2.6641,  3.9688, -4.4453,  ...,  0.9058, -0.0932,  0.5903],\n",
              "          [-3.1620,  3.8472, -4.3430,  ...,  1.2344, -0.5073, -0.1953],\n",
              "          [-2.3964,  4.8910, -4.9610,  ...,  1.2666, -0.4060, -1.2246]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-0.1113, -1.0889, -0.3137,  ...,  0.8354,  0.4307,  0.8403],\n",
              "          [ 0.0840, -0.0964,  0.1320,  ...,  1.3643, -0.8706,  0.3208],\n",
              "          [ 0.0765, -0.6695, -0.2371,  ...,  0.6162, -1.7402,  0.8159]],\n",
              "\n",
              "         [[-0.9312,  1.5977, -0.1072,  ..., -1.0625,  9.9531,  4.6328],\n",
              "          [-0.3221, -0.1964,  1.1807,  ..., -1.1309, 11.0312,  4.1953],\n",
              "          [-1.5343,  1.2656, -0.4718,  ..., -0.0501,  9.8750,  5.1719]],\n",
              "\n",
              "         [[-0.6250,  0.4194,  3.1758,  ...,  1.2246, -1.6719, -0.3193],\n",
              "          [-0.2238,  0.1226,  0.5561,  ...,  0.2837, -0.7334,  0.7295],\n",
              "          [-0.8723, -1.3995,  3.2606,  ...,  1.9092, -0.2085,  0.3828]]]],\n",
              "       device='cuda:0', grad_fn=<CatBackward0>), tensor([[[[ 0.0479,  0.0085,  0.3196,  ...,  0.0123,  0.8359,  0.2537],\n",
              "          [-0.1326, -0.0091,  0.1927,  ..., -0.0580,  0.0206, -0.0167],\n",
              "          [ 0.1569,  0.2856,  0.0124,  ..., -0.5239, -0.3472,  0.1757]],\n",
              "\n",
              "         [[ 0.3350,  0.1722, -0.6719,  ...,  0.3875,  0.1444, -0.5303],\n",
              "          [ 0.0493,  0.0409,  0.1259,  ..., -0.0859,  0.0907,  0.0841],\n",
              "          [ 0.3337, -0.8979, -0.3357,  ...,  0.5962,  0.6602, -0.2710]],\n",
              "\n",
              "         [[-0.3010, -0.0076, -0.2544,  ..., -0.9487, -0.4321, -0.7759],\n",
              "          [-0.2559, -0.6299,  0.1606,  ...,  0.5298, -0.2106, -0.1781],\n",
              "          [ 0.7666, -0.3145,  0.1974,  ..., -0.0078,  0.1251,  0.1360]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 0.5322,  0.5981, -0.2322,  ...,  0.3416, -0.4661,  0.5601],\n",
              "          [-0.0224,  0.0925,  0.0917,  ...,  0.2744, -0.1389,  0.1740],\n",
              "          [-0.6333, -0.8027, -0.5259,  ...,  0.0537, -0.0483, -0.8740]],\n",
              "\n",
              "         [[-0.9810,  0.6396, -0.3877,  ...,  0.2269,  0.2446, -0.2939],\n",
              "          [ 0.0163,  0.4414, -0.2021,  ...,  0.0250,  0.1030, -0.0550],\n",
              "          [-0.1251,  0.8848, -0.2098,  ...,  0.3054, -0.2284,  0.5815]],\n",
              "\n",
              "         [[ 0.3035, -0.3516,  0.9048,  ...,  0.4983,  0.3279,  0.8057],\n",
              "          [-0.1653, -0.0812,  0.5186,  ...,  0.2097,  0.2817,  0.0257],\n",
              "          [ 0.2646,  0.3474,  0.5469,  ...,  0.4417,  0.4395,  0.1360]]]],\n",
              "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.5195e+00, -1.3076e+00,  1.7957e-01,  ...,  1.9062e+00,\n",
              "            1.1680e+00,  2.0000e+00],\n",
              "          [ 9.1177e-02, -6.8679e-01, -2.1264e-01,  ...,  1.3994e+00,\n",
              "            9.7754e-01,  1.1162e+00],\n",
              "          [-1.9547e+00,  5.8611e-01, -8.2095e-01,  ...,  3.4521e-01,\n",
              "            3.8843e-01,  1.9482e+00]],\n",
              "\n",
              "         [[-1.2061e+00, -7.1533e-01, -2.6562e+00,  ..., -1.3652e+00,\n",
              "            2.4453e+00, -1.3145e+00],\n",
              "          [-5.9699e-01, -1.3471e+00, -2.5014e+00,  ..., -2.4199e+00,\n",
              "            2.3027e+00, -8.5938e-01],\n",
              "          [-2.3444e-01, -1.9063e+00, -3.5175e+00,  ..., -1.9590e+00,\n",
              "            3.7129e+00, -7.6807e-01]],\n",
              "\n",
              "         [[ 1.1973e+00,  2.0449e+00, -1.4209e+00,  ...,  5.3516e-01,\n",
              "            1.2830e-01, -2.5415e-01],\n",
              "          [-8.3491e-03,  6.3537e-01, -7.8907e-01,  ...,  9.1455e-01,\n",
              "            5.4443e-01,  1.2463e-01],\n",
              "          [-6.2413e-01,  1.2827e+00, -9.7538e-01,  ...,  3.8257e-01,\n",
              "            1.7451e+00, -2.4500e-01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-2.4863e+00,  2.7285e+00,  1.6260e+00,  ..., -2.3281e+00,\n",
              "           -9.0576e-01,  4.7578e+00],\n",
              "          [ 2.2831e-01,  1.0597e-01,  2.5268e-01,  ..., -2.6099e-01,\n",
              "           -8.4131e-01,  4.1484e+00],\n",
              "          [ 1.2686e+00,  1.6013e+00,  9.4960e-01,  ..., -1.9736e+00,\n",
              "           -1.0376e-01,  4.5312e+00]],\n",
              "\n",
              "         [[-6.2109e-01, -3.7231e-01,  7.0435e-02,  ...,  8.0566e-01,\n",
              "           -4.6753e-02, -4.6484e-01],\n",
              "          [ 2.1734e-01,  4.3149e-01, -2.8174e-01,  ..., -2.9956e-01,\n",
              "            3.1567e-01, -1.0889e+00],\n",
              "          [ 4.7054e-01,  4.2670e-01,  1.0360e+00,  ..., -8.8135e-01,\n",
              "           -9.9121e-01,  6.7261e-02]],\n",
              "\n",
              "         [[ 2.8418e+00, -2.3652e+00, -1.2812e+00,  ...,  6.4355e-01,\n",
              "           -2.7129e+00, -1.4856e-01],\n",
              "          [-2.6498e-01, -5.0950e-01, -3.7970e-03,  ...,  6.1572e-01,\n",
              "           -1.0811e+00, -1.0225e+00],\n",
              "          [-5.7311e-01, -2.9240e+00, -2.2515e+00,  ...,  1.5996e+00,\n",
              "           -7.3096e-01, -2.0293e+00]]]], device='cuda:0',\n",
              "       grad_fn=<CatBackward0>), tensor([[[[ 6.0840e-01, -2.7515e-01,  3.3887e-01,  ..., -2.8857e-01,\n",
              "           -7.9053e-01, -2.8706e-04],\n",
              "          [-1.3696e-01,  5.9662e-02,  1.9104e-01,  ...,  6.8588e-03,\n",
              "           -3.0859e-01, -5.3680e-02],\n",
              "          [-4.5996e-01,  1.1689e+00, -1.5173e-01,  ..., -4.2480e-01,\n",
              "           -7.0898e-01,  2.4353e-01]],\n",
              "\n",
              "         [[-2.8394e-01, -2.4780e-01,  6.5137e-01,  ...,  3.7500e-01,\n",
              "            6.2207e-01, -2.2607e-01],\n",
              "          [ 1.4758e-01,  2.7298e-02, -4.6234e-02,  ...,  1.4636e-01,\n",
              "            5.5847e-02, -5.2155e-02],\n",
              "          [-9.6533e-01,  3.0322e-01, -9.2773e-02,  ...,  1.2474e-02,\n",
              "            2.5757e-01, -3.2007e-01]],\n",
              "\n",
              "         [[-8.0859e-01, -1.2018e-01, -1.3281e-01,  ..., -3.2910e-01,\n",
              "           -4.1577e-01, -3.5913e-01],\n",
              "          [-3.5645e-02, -6.1798e-02,  1.9214e-01,  ...,  1.0361e-02,\n",
              "            4.6997e-02, -2.2534e-01],\n",
              "          [ 3.1104e-01, -1.1660e+00, -3.8916e-01,  ..., -6.1279e-01,\n",
              "           -4.0723e-01,  4.6558e-01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-3.6255e-01, -2.9160e-02,  3.2080e-01,  ...,  4.1260e-01,\n",
              "           -3.4521e-01, -7.0605e-01],\n",
              "          [ 5.8838e-02,  1.8921e-01,  2.4487e-01,  ..., -1.3330e-01,\n",
              "           -3.0502e-02, -1.0645e-01],\n",
              "          [-2.8979e-01, -6.3330e-01, -7.2461e-01,  ...,  5.5176e-01,\n",
              "            5.0781e-01,  5.4297e-01]],\n",
              "\n",
              "         [[-1.5515e-01,  4.1351e-02,  2.4939e-01,  ...,  8.6914e-02,\n",
              "           -5.3027e-01, -2.1655e-01],\n",
              "          [-2.2388e-01,  1.7651e-01, -2.9077e-01,  ...,  7.3280e-03,\n",
              "           -1.0400e-01,  1.5479e-01],\n",
              "          [ 2.0801e-01, -3.8135e-01,  2.0520e-01,  ..., -1.1420e-01,\n",
              "           -5.3613e-01,  3.8666e-02]],\n",
              "\n",
              "         [[-5.4199e-01,  9.4055e-02, -6.4404e-01,  ...,  6.3184e-01,\n",
              "            1.0376e-01,  4.5752e-01],\n",
              "          [ 2.2308e-02, -1.8433e-02,  9.2139e-01,  ...,  4.2065e-01,\n",
              "           -2.6953e-01, -1.4001e-01],\n",
              "          [ 1.2146e-01,  8.9453e-01, -3.9795e-01,  ..., -2.7051e-01,\n",
              "            8.1689e-01,  9.8438e-01]]]], device='cuda:0', dtype=torch.float16,\n",
              "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.3535e+00, -2.4377e-01, -1.2148e+00,  ..., -2.6562e-01,\n",
              "           -9.0186e-01,  2.3984e+00],\n",
              "          [ 1.0631e+00, -4.5209e+00, -4.0060e+00,  ..., -1.3105e+00,\n",
              "           -1.2119e+00,  2.2402e+00],\n",
              "          [-4.7133e+00, -5.4789e+00, -4.6130e+00,  ...,  3.7061e-01,\n",
              "           -8.2910e-01,  2.8223e+00]],\n",
              "\n",
              "         [[-8.5156e-01,  9.2188e-01,  8.4424e-01,  ...,  1.2500e-01,\n",
              "           -1.0137e+00, -2.0176e+00],\n",
              "          [-3.0308e+00,  4.2468e+00,  4.3211e+00,  ..., -1.8250e-01,\n",
              "           -1.5957e+00, -2.0469e+00],\n",
              "          [-2.4765e+00,  4.7136e+00,  5.9474e+00,  ..., -1.8958e-01,\n",
              "           -8.4766e-01, -1.9814e+00]],\n",
              "\n",
              "         [[ 5.4688e-01,  4.8711e+00,  5.1484e+00,  ...,  2.0957e+00,\n",
              "            2.2656e+00, -2.0098e+00],\n",
              "          [ 7.4648e+00,  4.8491e+00,  6.2792e+00,  ...,  1.9453e+00,\n",
              "            2.3203e+00, -2.4414e+00],\n",
              "          [ 3.1274e+00,  3.9703e+00,  6.0811e+00,  ...,  9.5508e-01,\n",
              "            2.2012e+00, -1.1543e+00]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 6.1768e-01,  7.0410e-01, -2.9980e-01,  ..., -1.2578e+00,\n",
              "            4.8535e-01, -3.7383e+00],\n",
              "          [-8.4600e-01,  1.2608e+00, -7.5499e-01,  ..., -1.2842e+00,\n",
              "            3.7695e-01, -4.4219e+00],\n",
              "          [-5.5360e-01,  2.1947e+00, -2.6189e+00,  ..., -1.7412e+00,\n",
              "            1.1143e+00, -3.3438e+00]],\n",
              "\n",
              "         [[-3.8867e-01,  4.9683e-01,  2.6660e-01,  ...,  7.3789e+00,\n",
              "           -7.2975e-03,  6.3438e+00],\n",
              "          [ 3.2623e-01,  5.7602e-01,  1.1721e+00,  ...,  7.7734e+00,\n",
              "           -2.3486e-01,  6.1484e+00],\n",
              "          [ 1.3936e+00, -8.5778e-02, -2.2019e-01,  ...,  7.1836e+00,\n",
              "            5.3760e-01,  5.1445e+00]],\n",
              "\n",
              "         [[-3.3276e-01,  7.0215e-01, -1.5215e+00,  ...,  4.6992e+00,\n",
              "            1.4258e+00, -8.3789e-01],\n",
              "          [ 3.6396e-01,  2.7064e-01, -2.4233e-01,  ...,  3.2031e+00,\n",
              "            1.0273e+00, -4.6216e-01],\n",
              "          [ 1.3421e+00,  1.1581e+00, -1.1163e+00,  ...,  4.8594e+00,\n",
              "            2.4199e+00, -5.9717e-01]]]], device='cuda:0',\n",
              "       grad_fn=<CatBackward0>), tensor([[[[-1.7761e-01,  3.9429e-01,  8.4591e-04,  ...,  2.8467e-01,\n",
              "           -5.6104e-01,  3.0420e-01],\n",
              "          [ 2.3169e-01, -1.2927e-01,  6.2866e-02,  ...,  2.5830e-01,\n",
              "            4.8584e-01,  4.2871e-01],\n",
              "          [-3.7915e-01,  1.7566e-01, -8.1348e-01,  ...,  7.8662e-01,\n",
              "           -6.7688e-02,  4.5776e-01]],\n",
              "\n",
              "         [[-8.4900e-02, -2.1289e-01,  3.6316e-02,  ...,  8.8477e-01,\n",
              "            2.2491e-02,  3.2397e-01],\n",
              "          [-3.1030e-01, -6.3660e-02,  1.2115e-01,  ..., -1.4551e+00,\n",
              "           -1.2177e-01,  3.8525e-01],\n",
              "          [-9.8584e-01,  9.4849e-02,  6.7810e-02,  ...,  4.2822e-01,\n",
              "            4.8291e-01, -1.2793e-01]],\n",
              "\n",
              "         [[ 3.9062e-01, -1.0830e+00, -2.5073e-01,  ...,  5.1562e-01,\n",
              "           -7.1582e-01, -6.4600e-01],\n",
              "          [-2.2473e-01, -1.1660e+00, -1.2396e-01,  ..., -7.5293e-01,\n",
              "            2.0898e-01, -1.0654e+00],\n",
              "          [-5.6543e-01,  1.9199e+00,  2.7783e-01,  ...,  6.1572e-01,\n",
              "           -6.6602e-01,  9.0918e-01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-1.2769e-01,  5.1416e-01, -5.9326e-01,  ..., -9.8816e-02,\n",
              "           -2.6733e-01, -3.0835e-01],\n",
              "          [-2.7051e-01, -1.9983e-01, -1.0199e-01,  ..., -1.4502e-01,\n",
              "            6.1377e-01,  2.4597e-01],\n",
              "          [ 3.2520e-01,  1.8127e-01, -4.0063e-01,  ...,  7.5732e-01,\n",
              "            4.1382e-02,  2.9861e-02]],\n",
              "\n",
              "         [[-2.7124e-01, -3.4454e-02,  4.6234e-02,  ..., -8.5907e-03,\n",
              "           -1.6211e-01,  1.6589e-01],\n",
              "          [-2.5635e-01,  1.2903e-01, -1.2561e-01,  ...,  3.6194e-02,\n",
              "           -1.1304e-01, -3.2349e-02],\n",
              "          [-6.2305e-01, -3.1235e-02,  2.6709e-01,  ...,  1.6528e-01,\n",
              "            2.0386e-01, -5.3027e-01]],\n",
              "\n",
              "         [[ 1.7932e-01, -2.9468e-01, -1.4004e+00,  ..., -3.5474e-01,\n",
              "            1.8079e-01, -1.6260e-01],\n",
              "          [-6.3904e-02, -1.5784e-01, -6.2842e-01,  ...,  4.8682e-01,\n",
              "           -7.1899e-02,  6.5613e-02],\n",
              "          [ 3.6182e-01, -3.1812e-01, -3.5498e-01,  ...,  2.6196e-01,\n",
              "           -2.0667e-01, -5.4054e-03]]]], device='cuda:0', dtype=torch.float16,\n",
              "       grad_fn=<PermuteBackward0>)), (tensor([[[[-1.9470e-01, -2.0337e-01,  2.6196e-01,  ..., -9.0625e+00,\n",
              "           -2.0469e+00,  2.4766e+00],\n",
              "          [ 1.1163e-01, -1.6454e+00,  3.3134e+00,  ..., -9.2656e+00,\n",
              "           -4.2422e+00,  2.1562e+00],\n",
              "          [ 1.1359e+00, -2.1406e+00,  3.0637e+00,  ..., -7.8203e+00,\n",
              "           -1.7705e+00,  3.4902e+00]],\n",
              "\n",
              "         [[-3.0975e-02, -9.8999e-02,  3.2379e-02,  ..., -2.2012e+00,\n",
              "           -2.6484e+00,  2.2168e-01],\n",
              "          [-3.5293e-01, -3.9941e-01,  2.4423e-01,  ..., -3.2754e+00,\n",
              "           -2.5684e+00,  2.8027e-01],\n",
              "          [-1.9135e-02, -2.8050e-01, -1.9924e-01,  ..., -5.0000e+00,\n",
              "           -3.5059e+00,  1.0645e+00]],\n",
              "\n",
              "         [[-2.4139e-02, -5.5908e-02, -4.6120e-03,  ..., -2.7656e+00,\n",
              "            7.2144e-02, -1.3789e+00],\n",
              "          [-8.9721e-01, -2.8765e+00,  2.2858e+00,  ..., -1.0459e+00,\n",
              "           -6.3538e-02, -1.4805e+00],\n",
              "          [ 1.3653e+00, -3.5494e+00,  2.6687e+00,  ..., -1.4023e+00,\n",
              "            3.4058e-01, -1.3789e+00]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 3.7079e-03,  4.0039e-02, -4.0924e-02,  ...,  8.1562e+00,\n",
              "           -6.0352e+00,  4.3320e+00],\n",
              "          [-3.5543e-01, -1.4389e+00,  1.0911e+00,  ...,  6.2344e+00,\n",
              "           -4.9258e+00,  4.7305e+00],\n",
              "          [-7.8165e-01, -2.4743e-01,  5.4793e-01,  ...,  6.7969e+00,\n",
              "           -5.3164e+00,  4.4688e+00]],\n",
              "\n",
              "         [[-6.8848e-02,  1.5491e-01,  8.5327e-02,  ...,  3.5812e+01,\n",
              "           -3.6312e+01, -3.4250e+01],\n",
              "          [-1.1713e-01, -2.9715e-01,  3.9916e-01,  ...,  3.3562e+01,\n",
              "           -3.6438e+01, -3.4062e+01],\n",
              "          [ 2.6837e-01, -2.7897e-01, -1.8501e-01,  ...,  3.3125e+01,\n",
              "           -3.6312e+01, -3.3875e+01]],\n",
              "\n",
              "         [[-8.5571e-02, -5.5466e-03, -1.2769e-01,  ...,  5.7617e+00,\n",
              "            1.1016e+01,  2.0254e+00],\n",
              "          [ 1.5194e-01,  3.0507e-01, -1.5180e+00,  ...,  5.1406e+00,\n",
              "            1.1820e+01,  2.0879e+00],\n",
              "          [-2.3478e-02,  3.0299e-01, -5.2872e-01,  ...,  7.5547e+00,\n",
              "            1.0656e+01,  2.0234e+00]]]], device='cuda:0',\n",
              "       grad_fn=<CatBackward0>), tensor([[[[ 0.0124, -0.0223,  0.0868,  ..., -0.2379,  0.0671,  0.0638],\n",
              "          [-0.3230,  0.0124,  0.6025,  ...,  0.1136,  0.2771,  0.7061],\n",
              "          [ 0.5762,  0.3181, -0.3105,  ..., -0.1138,  1.4834,  0.5825]],\n",
              "\n",
              "         [[-0.1431, -0.1500,  0.4741,  ...,  0.0958,  0.1506, -0.0748],\n",
              "          [-0.0731, -0.1550, -1.0312,  ...,  0.0359,  0.6235, -1.8018],\n",
              "          [-0.0144,  0.1210, -0.5962,  ...,  1.8301,  0.1162, -1.8848]],\n",
              "\n",
              "         [[-0.0981,  0.1576,  0.0247,  ...,  0.1686,  0.0559,  0.1131],\n",
              "          [ 0.1069, -1.2646, -0.4182,  ...,  0.4541, -0.7900,  0.9233],\n",
              "          [ 0.2810,  0.4280, -0.9385,  ...,  0.5918, -1.1445,  0.4075]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 0.5728, -0.5410, -0.1956,  ..., -0.1279,  0.0193,  0.0249],\n",
              "          [-0.2903,  1.4795, -0.6475,  ...,  0.8223,  0.0289,  0.2184],\n",
              "          [ 0.1923,  0.3381, -0.0454,  ...,  0.2517,  0.3730,  0.0380]],\n",
              "\n",
              "         [[-0.0028, -0.0111, -0.1385,  ..., -0.0804,  0.0166,  0.0773],\n",
              "          [-0.0768,  1.8389, -0.6641,  ..., -0.0138, -0.4041,  1.3809],\n",
              "          [-0.1508,  1.2969,  0.3162,  ..., -0.3420, -0.0101,  0.4470]],\n",
              "\n",
              "         [[-0.2722, -0.0242, -0.0208,  ...,  0.0094,  0.0414,  0.0350],\n",
              "          [-0.6377, -0.4290,  0.4314,  ...,  0.2810, -0.2542, -0.0593],\n",
              "          [-1.0332,  0.3259,  0.0639,  ..., -0.5649, -1.2949, -0.2214]]]],\n",
              "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[-3.3569e-03,  1.1353e-02,  1.4880e-01,  ...,  3.3926e+00,\n",
              "            1.4453e+01,  1.6078e+01],\n",
              "          [ 2.8283e-01, -3.8896e-02, -4.6110e-01,  ...,  1.6074e+00,\n",
              "            1.5734e+01,  1.5906e+01],\n",
              "          [-8.5995e-02, -1.2383e-01, -4.1223e-01,  ...,  2.9961e+00,\n",
              "            1.5289e+01,  1.5914e+01]],\n",
              "\n",
              "         [[-5.4443e-02, -3.9581e-02, -3.5187e-02,  ..., -2.1055e+00,\n",
              "           -4.2617e+00, -1.2172e+01],\n",
              "          [ 1.2227e-01, -6.1560e-01,  2.3195e+00,  ..., -2.1035e+00,\n",
              "           -4.1914e+00, -1.2523e+01],\n",
              "          [ 8.3974e-01,  1.7393e-01,  1.8424e+00,  ..., -1.8574e+00,\n",
              "           -4.2305e+00, -1.1023e+01]],\n",
              "\n",
              "         [[ 4.0649e-02,  8.2245e-03, -1.7310e-01,  ..., -2.6297e+01,\n",
              "           -1.9141e+01,  1.3852e+01],\n",
              "          [-8.1994e-01, -6.8560e-01, -1.1787e+00,  ..., -2.5609e+01,\n",
              "           -1.9812e+01,  1.3750e+01],\n",
              "          [-8.3198e-01, -2.2960e-01, -1.0998e+00,  ..., -2.5438e+01,\n",
              "           -1.9891e+01,  1.3555e+01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-1.5076e-01,  2.5345e-02, -1.3782e-01,  ..., -1.3164e+01,\n",
              "            6.1367e+00, -3.3145e+00],\n",
              "          [-4.7555e-01,  1.2342e-01, -1.3879e+00,  ..., -1.2812e+01,\n",
              "            4.7656e+00, -3.2637e+00],\n",
              "          [ 1.0824e-01,  4.2289e-01, -1.5217e+00,  ..., -1.1578e+01,\n",
              "            5.0547e+00, -3.8633e+00]],\n",
              "\n",
              "         [[ 4.3762e-02, -3.5004e-02, -1.7383e-01,  ...,  4.1562e+00,\n",
              "            7.8594e+00,  2.8789e+00],\n",
              "          [-4.1180e-01, -5.8583e-01, -1.6998e+00,  ...,  4.8906e+00,\n",
              "            9.0703e+00,  3.8242e+00],\n",
              "          [-2.7888e-01,  1.5917e-01, -2.9193e-01,  ...,  3.5273e+00,\n",
              "            9.4688e+00,  2.7207e+00]],\n",
              "\n",
              "         [[ 3.4241e-02, -1.5823e-02,  9.0576e-02,  ..., -5.8438e+00,\n",
              "           -6.4258e+00, -3.0328e+01],\n",
              "          [-2.5179e-01, -3.6507e-01,  2.2624e+00,  ..., -5.4102e+00,\n",
              "           -5.9062e+00, -2.8922e+01],\n",
              "          [-1.1087e+00, -1.2112e+00,  2.6533e+00,  ..., -6.2773e+00,\n",
              "           -6.9414e+00, -2.9281e+01]]]], device='cuda:0',\n",
              "       grad_fn=<CatBackward0>), tensor([[[[-8.4381e-03, -4.7150e-02, -9.4849e-02,  ..., -1.4824e-02,\n",
              "           -9.9609e-02, -2.0740e-01],\n",
              "          [ 1.0615e+00,  2.7539e-01, -1.3452e-01,  ..., -1.0083e-01,\n",
              "            8.8525e-01,  6.4209e-01],\n",
              "          [ 1.0264e+00,  5.6396e-01,  1.7764e+00,  ..., -1.2217e+00,\n",
              "           -9.7119e-01,  1.5552e-01]],\n",
              "\n",
              "         [[ 1.2732e-01,  1.7517e-01,  3.9001e-02,  ..., -8.3130e-02,\n",
              "            5.4749e-02,  1.0443e-01],\n",
              "          [-2.9053e-01,  1.5059e+00,  1.1328e+00,  ..., -1.0889e-01,\n",
              "            4.5386e-01,  1.1826e+00],\n",
              "          [-2.6807e-01,  7.1680e-01,  7.3633e-01,  ..., -1.0010e-01,\n",
              "           -1.1551e-02,  4.0283e-01]],\n",
              "\n",
              "         [[ 8.1238e-02, -6.9214e-02, -2.9495e-02,  ..., -4.6051e-02,\n",
              "            2.3834e-02,  8.4167e-02],\n",
              "          [ 7.6660e-01,  1.1786e-01, -5.7861e-01,  ..., -2.3413e-01,\n",
              "           -2.9224e-01,  9.1064e-01],\n",
              "          [ 2.2021e-01,  7.6050e-02, -3.7158e-01,  ...,  5.4077e-02,\n",
              "            6.3965e-01, -1.1493e-01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 6.2500e-02, -1.4001e-01, -1.7639e-01,  ...,  5.8075e-02,\n",
              "           -1.8188e-01, -6.8787e-02],\n",
              "          [-2.6392e-01, -4.5996e-01,  3.9087e-01,  ..., -4.0436e-03,\n",
              "           -6.0944e-02, -6.8945e-01],\n",
              "          [-5.4346e-01, -3.9697e-01, -2.0667e-01,  ..., -5.2002e-01,\n",
              "            5.7812e-01, -1.5361e+00]],\n",
              "\n",
              "         [[-2.8900e-02, -2.3425e-01, -3.2166e-02,  ..., -6.2866e-02,\n",
              "            5.1842e-03,  2.8000e-03],\n",
              "          [ 9.7119e-01, -1.0186e+00,  5.6190e-03,  ..., -5.7617e-02,\n",
              "           -5.3613e-01, -7.9883e-01],\n",
              "          [ 1.0410e+00, -1.7395e-01, -1.2002e+00,  ..., -4.2285e-01,\n",
              "           -8.6572e-01, -7.7588e-01]],\n",
              "\n",
              "         [[ 1.8970e-01,  1.0828e-01,  4.2236e-02,  ..., -9.2285e-02,\n",
              "            1.0956e-01, -1.1475e-01],\n",
              "          [-2.4646e-01,  1.4346e+00,  7.1631e-01,  ..., -4.0698e-01,\n",
              "            4.3311e-01,  6.4160e-01],\n",
              "          [-1.0195e+00,  2.9712e-01,  1.9177e-01,  ...,  4.2603e-01,\n",
              "            1.1896e-01, -1.6928e-03]]]], device='cuda:0', dtype=torch.float16,\n",
              "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 7.1106e-03, -1.4453e-01, -2.7039e-02,  ...,  9.5938e+00,\n",
              "           -1.2602e+01, -1.4688e+01],\n",
              "          [-8.6641e-01, -5.7154e-01,  9.9740e-03,  ...,  8.8047e+00,\n",
              "           -1.1844e+01, -1.3602e+01],\n",
              "          [ 5.3445e-02, -1.1097e-01, -1.2180e-01,  ...,  9.1172e+00,\n",
              "           -1.2398e+01, -1.4844e+01]],\n",
              "\n",
              "         [[-8.1421e-02,  6.6345e-02,  2.8061e-02,  ..., -3.1719e+00,\n",
              "           -2.4231e-01, -7.6836e+00],\n",
              "          [ 2.1990e-01,  8.6712e-02, -3.5788e-01,  ..., -4.1094e+00,\n",
              "            3.0542e-01, -7.2266e+00],\n",
              "          [ 7.8866e-01, -1.6024e-01, -1.0282e+00,  ..., -3.7324e+00,\n",
              "           -4.9927e-01, -7.0664e+00]],\n",
              "\n",
              "         [[ 9.8206e-02,  1.7651e-01,  3.0548e-02,  ...,  2.9219e+01,\n",
              "           -2.2484e+01, -8.2578e+00],\n",
              "          [ 6.4655e-01, -2.1766e-01, -3.1310e+00,  ...,  2.8531e+01,\n",
              "           -2.2531e+01, -7.8750e+00],\n",
              "          [ 1.8109e+00, -1.9519e+00, -2.9511e+00,  ...,  2.8984e+01,\n",
              "           -2.2141e+01, -7.8906e+00]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-8.6792e-02,  5.8136e-03,  8.7585e-02,  ...,  1.4250e+01,\n",
              "            1.4133e+01,  6.2695e+00],\n",
              "          [-4.4606e-01,  5.4342e-01,  1.1756e-01,  ...,  1.3914e+01,\n",
              "            1.4320e+01,  5.9531e+00],\n",
              "          [ 7.7255e-01,  1.6596e+00, -4.7069e-01,  ...,  1.4281e+01,\n",
              "            1.3531e+01,  5.9805e+00]],\n",
              "\n",
              "         [[-1.9012e-02,  3.0838e-02,  1.1346e-01,  ..., -5.2852e+00,\n",
              "           -1.4180e+00, -1.0719e+01],\n",
              "          [ 1.5935e-02, -5.4897e-02,  7.6129e-01,  ..., -4.7266e+00,\n",
              "           -2.0781e+00, -1.0133e+01],\n",
              "          [-2.0688e-01,  4.6308e-01,  3.6455e-01,  ..., -5.4961e+00,\n",
              "           -4.3555e+00, -9.7188e+00]],\n",
              "\n",
              "         [[-5.9875e-02, -1.3989e-01,  4.8462e-02,  ...,  8.7891e+00,\n",
              "            1.2430e+01,  6.6797e+00],\n",
              "          [ 4.3948e-02, -5.4037e-01,  3.5959e-01,  ...,  7.1680e+00,\n",
              "            1.1625e+01,  7.4727e+00],\n",
              "          [ 6.9173e-01, -8.1031e-01, -2.5944e-02,  ...,  8.7031e+00,\n",
              "            1.2820e+01,  7.0977e+00]]]], device='cuda:0',\n",
              "       grad_fn=<CatBackward0>), tensor([[[[ 0.0169, -0.0317,  0.0211,  ...,  0.1536,  0.0546,  0.1375],\n",
              "          [-0.2104,  0.7959, -0.2131,  ..., -0.0516, -0.2222, -0.4521],\n",
              "          [ 0.5186,  1.0537, -0.1718,  ..., -0.2554, -0.1826, -0.6226]],\n",
              "\n",
              "         [[ 0.0035,  0.0892, -0.1724,  ...,  0.1027,  0.2461,  0.1537],\n",
              "          [-0.3638,  0.0620, -1.3359,  ...,  1.0000,  1.0537, -0.0314],\n",
              "          [-0.9102,  0.4143, -0.4150,  ...,  1.9385,  0.5996,  1.1045]],\n",
              "\n",
              "         [[ 0.3164, -0.0329,  0.0747,  ..., -0.0934, -0.0192,  0.0267],\n",
              "          [ 0.0029, -0.0153, -0.2107,  ...,  0.1652, -0.6826,  0.5156],\n",
              "          [-0.9741,  0.2844, -0.5020,  ...,  0.7798, -0.3030,  0.4077]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-0.0222, -0.0295,  0.0649,  ...,  0.0093, -0.1075, -0.0724],\n",
              "          [ 0.9824,  0.6089,  0.6387,  ...,  0.1132, -0.5024, -0.0635],\n",
              "          [ 0.9194, -0.2235,  0.4429,  ...,  0.5967,  0.0698,  0.4075]],\n",
              "\n",
              "         [[-0.0029, -0.1527,  0.0636,  ...,  0.0127,  0.0518, -0.0033],\n",
              "          [-0.5767, -0.4019, -1.0889,  ...,  0.2078,  0.4363,  1.4502],\n",
              "          [ 0.0495, -1.3359, -0.2474,  ...,  0.7510,  0.1176,  0.9360]],\n",
              "\n",
              "         [[-0.0244,  0.0346, -0.0185,  ...,  0.0470, -0.0036,  0.0594],\n",
              "          [ 0.0549,  1.2705, -0.3381,  ..., -0.1680, -0.2354,  0.5566],\n",
              "          [ 0.8584,  0.3499, -0.7246,  ...,  0.2856,  0.0249, -0.5425]]]],\n",
              "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[-1.4941e-01, -8.1635e-03,  3.1033e-03,  ...,  1.3898e+01,\n",
              "           -9.6797e+00, -7.1016e+00],\n",
              "          [ 2.3730e-01, -4.7610e-01,  1.1009e+00,  ...,  1.4211e+01,\n",
              "           -9.9609e+00, -7.5586e+00],\n",
              "          [ 2.8418e-01, -6.0781e-01,  8.4216e-01,  ...,  1.3367e+01,\n",
              "           -1.0453e+01, -7.9375e+00]],\n",
              "\n",
              "         [[ 1.4392e-01, -1.0162e-01,  1.2512e-01,  ...,  1.4945e+01,\n",
              "            2.0250e+01,  2.0328e+01],\n",
              "          [ 1.9344e+00,  2.6728e-01,  4.5022e+00,  ...,  1.4883e+01,\n",
              "            1.9859e+01,  2.0656e+01],\n",
              "          [-1.0841e+00, -2.5963e+00,  4.6759e+00,  ...,  1.5094e+01,\n",
              "            1.9281e+01,  2.0938e+01]],\n",
              "\n",
              "         [[-1.6882e-01, -2.4429e-02, -2.3865e-02,  ..., -1.5734e+01,\n",
              "           -1.2391e+01, -1.6438e+01],\n",
              "          [-1.1191e+00, -3.1371e-02, -9.3288e-01,  ..., -1.6266e+01,\n",
              "           -1.2219e+01, -1.6547e+01],\n",
              "          [ 2.2710e+00,  3.5449e-01, -3.5900e+00,  ..., -1.5195e+01,\n",
              "           -1.3078e+01, -1.6328e+01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 1.0254e-01, -1.9800e-01, -2.7710e-01,  ...,  2.2281e+01,\n",
              "           -2.0828e+01,  1.6078e+01],\n",
              "          [ 1.4818e+00, -2.8781e-01,  1.5584e+00,  ...,  2.1625e+01,\n",
              "           -2.0719e+01,  1.6781e+01],\n",
              "          [-7.9683e-01, -8.3715e-01,  3.6014e-01,  ...,  2.2094e+01,\n",
              "           -2.0125e+01,  1.6750e+01]],\n",
              "\n",
              "         [[ 2.2715e+00,  1.4473e+00,  1.0713e+00,  ...,  3.3562e+01,\n",
              "            3.3469e+01, -3.3469e+01],\n",
              "          [ 1.3355e+01,  8.2235e+00,  8.5833e+00,  ...,  3.4281e+01,\n",
              "            3.4156e+01, -3.4375e+01],\n",
              "          [ 1.8556e+01,  4.4532e+00,  1.1690e+01,  ...,  3.4062e+01,\n",
              "            3.4219e+01, -3.3312e+01]],\n",
              "\n",
              "         [[ 7.6904e-02,  7.7332e-02,  2.5464e-01,  ..., -3.3750e+00,\n",
              "           -4.2930e+00, -7.5879e-01],\n",
              "          [ 1.6920e-01,  2.0815e-01,  5.2202e-01,  ..., -2.7676e+00,\n",
              "           -4.7539e+00, -6.1475e-01],\n",
              "          [ 5.2962e-01, -8.5269e-02,  1.1714e+00,  ..., -4.9878e-01,\n",
              "           -4.4414e+00, -2.1265e-01]]]], device='cuda:0',\n",
              "       grad_fn=<CatBackward0>), tensor([[[[-7.0435e-02,  5.4108e-02, -2.7002e-01,  ...,  3.1982e-02,\n",
              "            1.8896e-01,  1.2292e-01],\n",
              "          [ 3.0981e-01,  3.8208e-01, -6.9824e-01,  ..., -5.2539e-01,\n",
              "            4.7900e-01,  8.2458e-02],\n",
              "          [ 2.0825e-01,  1.4092e+00, -5.8545e-01,  ..., -9.3689e-02,\n",
              "            5.9180e-01, -3.1006e-01]],\n",
              "\n",
              "         [[ 4.1565e-02, -1.0309e-03,  4.3152e-02,  ..., -2.1851e-02,\n",
              "            1.5671e-02,  1.6797e-01],\n",
              "          [ 5.4297e-01, -6.3525e-01, -2.1887e-01,  ...,  7.3242e-01,\n",
              "            6.6895e-02,  3.1471e-03],\n",
              "          [ 3.4424e-01,  4.3750e-01, -5.7364e-04,  ...,  4.4482e-01,\n",
              "           -2.5586e-01, -1.2286e-01]],\n",
              "\n",
              "         [[-3.6285e-02,  3.9856e-02,  2.1790e-02,  ...,  2.7515e-01,\n",
              "            5.4565e-02,  1.7271e-03],\n",
              "          [-4.5581e-01,  3.9478e-01, -7.1167e-02,  ..., -5.4053e-01,\n",
              "           -1.1847e-01, -3.1494e-02],\n",
              "          [-3.3643e-01, -1.2122e-01,  6.7432e-01,  ..., -1.4834e+00,\n",
              "           -1.8042e-01, -3.6450e-01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 2.1103e-02, -4.9829e-04, -4.6143e-02,  ..., -2.2781e-02,\n",
              "            4.9011e-02,  9.6680e-02],\n",
              "          [-8.3679e-02,  1.7212e-01, -2.4048e-01,  ..., -4.5288e-01,\n",
              "           -2.1286e-02, -4.5898e-01],\n",
              "          [ 5.9784e-02, -6.5137e-01, -4.2786e-02,  ..., -9.6582e-01,\n",
              "           -6.3049e-02, -3.2642e-01]],\n",
              "\n",
              "         [[ 2.2385e-02, -1.6724e-02,  5.3787e-03,  ...,  2.2903e-02,\n",
              "            6.6956e-02,  8.0061e-04],\n",
              "          [ 1.3647e-01, -1.7053e-01,  2.1460e-01,  ..., -4.7876e-01,\n",
              "            1.9421e-01,  2.4060e-01],\n",
              "          [ 1.1548e-01, -5.5786e-02, -1.1444e-01,  ...,  1.6281e-02,\n",
              "            6.4746e-01,  1.0391e-02]],\n",
              "\n",
              "         [[-1.8188e-01,  1.5186e-01,  4.3335e-02,  ..., -1.2311e-01,\n",
              "           -3.0029e-01, -1.5955e-01],\n",
              "          [ 8.0994e-02,  1.8799e-01, -1.1289e+00,  ..., -2.5635e-01,\n",
              "           -5.1416e-01, -6.6528e-02],\n",
              "          [-3.3667e-01, -1.2178e+00, -5.7324e-01,  ...,  2.5708e-01,\n",
              "           -5.8398e-01, -1.5498e+00]]]], device='cuda:0', dtype=torch.float16,\n",
              "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 9.2087e-03, -3.1143e-02, -1.6113e-01,  ...,  3.6094e+01,\n",
              "            3.6562e+01, -3.5438e+01],\n",
              "          [ 1.2699e+00,  1.5856e+00, -3.0572e+00,  ...,  3.7094e+01,\n",
              "            3.6688e+01, -3.5969e+01],\n",
              "          [ 2.3921e+00, -1.0625e+00, -1.7823e+00,  ...,  3.6219e+01,\n",
              "            3.6469e+01, -3.5812e+01]],\n",
              "\n",
              "         [[ 2.1191e-01, -3.1641e-01, -3.9795e-01,  ...,  3.6719e+01,\n",
              "           -2.2703e+01,  3.4594e+01],\n",
              "          [ 2.1323e+00,  2.4994e-01, -3.8380e-01,  ...,  3.7000e+01,\n",
              "           -2.2188e+01,  3.4156e+01],\n",
              "          [ 1.0759e+00,  2.1143e+00,  2.7951e-01,  ...,  3.7500e+01,\n",
              "           -2.3031e+01,  3.4719e+01]],\n",
              "\n",
              "         [[ 1.1768e-01, -1.3745e-01, -1.5808e-01,  ..., -2.6828e+01,\n",
              "            3.1219e+01,  2.7812e+01],\n",
              "          [ 2.1017e-01, -3.4010e-01,  4.7792e-01,  ..., -2.6531e+01,\n",
              "            3.1344e+01,  2.8391e+01],\n",
              "          [-3.3030e-02, -1.5540e-01,  1.5497e+00,  ..., -2.6094e+01,\n",
              "            3.1312e+01,  2.7016e+01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-2.9659e-03,  6.2256e-02, -9.5825e-02,  ..., -2.0000e+01,\n",
              "            1.6422e+01,  2.1938e+01],\n",
              "          [-5.7265e-01,  2.9532e-01,  2.6854e-01,  ..., -1.9609e+01,\n",
              "            1.7516e+01,  2.1797e+01],\n",
              "          [-7.2938e-01,  1.0463e+00,  2.9088e+00,  ..., -1.9719e+01,\n",
              "            1.6516e+01,  2.1734e+01]],\n",
              "\n",
              "         [[ 6.7688e-02, -2.3022e-01,  1.6125e-01,  ...,  6.9062e+00,\n",
              "            1.8688e+01, -1.1703e+01],\n",
              "          [ 3.5246e-01, -8.5210e-01, -4.9979e-01,  ...,  7.4219e+00,\n",
              "            1.8766e+01, -1.2453e+01],\n",
              "          [-1.5539e-01, -1.4006e+00, -1.3663e+00,  ...,  6.9062e+00,\n",
              "            1.9375e+01, -1.2500e+01]],\n",
              "\n",
              "         [[-4.7333e-02, -4.1046e-02,  6.5820e-01,  ...,  2.2469e+01,\n",
              "            1.6984e+01,  2.0172e+01],\n",
              "          [ 4.1025e-01,  4.6595e-01,  2.6348e+00,  ...,  2.1969e+01,\n",
              "            1.6781e+01,  2.0234e+01],\n",
              "          [-2.8452e-01,  1.2939e-01,  2.1272e+00,  ...,  2.1719e+01,\n",
              "            1.7453e+01,  2.1078e+01]]]], device='cuda:0',\n",
              "       grad_fn=<CatBackward0>), tensor([[[[-0.0798,  0.0859, -0.1469,  ..., -0.1265, -0.1857, -0.0127],\n",
              "          [-0.5859,  0.2805, -0.0648,  ..., -0.4299, -0.5527,  0.9380],\n",
              "          [-0.6729, -0.0748, -0.3501,  ...,  0.2454,  0.3003,  1.3701]],\n",
              "\n",
              "         [[-0.0250,  0.2241, -0.1105,  ..., -0.0458,  0.0090, -0.0064],\n",
              "          [ 0.4092,  0.4390,  0.4443,  ..., -0.8354,  0.1268, -0.1787],\n",
              "          [ 0.3572,  0.3982,  0.8433,  ..., -0.4998, -0.1635, -0.0035]],\n",
              "\n",
              "         [[-0.1184,  0.0550,  0.0201,  ...,  0.2001, -0.1528,  0.0195],\n",
              "          [ 0.2080,  0.1243, -0.3904,  ...,  0.0591,  0.3018, -0.2263],\n",
              "          [ 0.2273, -0.2213, -0.5718,  ...,  0.4575, -0.6611,  0.3914]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-0.1479, -0.0853, -0.1573,  ...,  0.0092, -0.0247,  0.0105],\n",
              "          [ 0.8760,  0.2012,  0.0524,  ...,  0.2029, -0.1803,  0.0876],\n",
              "          [ 0.6294,  0.7344,  0.6655,  ...,  0.1214,  0.9995,  1.3486]],\n",
              "\n",
              "         [[-0.0087, -0.0705,  0.0342,  ...,  0.0384,  0.1458, -0.0648],\n",
              "          [ 0.4387, -0.1895,  0.3914,  ...,  0.1036, -0.3655,  0.3447],\n",
              "          [-0.0790,  0.4619,  0.4009,  ...,  0.7178, -0.4680,  1.3467]],\n",
              "\n",
              "         [[-0.0575, -0.0912,  0.0887,  ...,  0.0790,  0.1707,  0.2478],\n",
              "          [-0.1479, -1.0498, -0.0580,  ...,  0.0778,  0.6621, -0.9082],\n",
              "          [-0.1760, -0.4824,  1.3486,  ...,  1.1045,  1.1572, -0.4355]]]],\n",
              "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[ 6.8298e-02,  9.6863e-02, -6.7932e-02,  ..., -4.6211e+00,\n",
              "            1.9000e+01,  1.3617e+01],\n",
              "          [ 1.9294e-01,  6.6215e-01, -5.2146e-01,  ..., -5.2891e+00,\n",
              "            1.8359e+01,  1.3859e+01],\n",
              "          [ 1.1853e+00,  5.1532e-01, -2.1138e+00,  ..., -2.3945e+00,\n",
              "            1.8141e+01,  1.3148e+01]],\n",
              "\n",
              "         [[-6.5613e-02,  9.2712e-02,  2.1216e-01,  ..., -3.8531e+01,\n",
              "           -3.5469e+01, -3.4875e+01],\n",
              "          [ 4.0771e+00,  4.3657e-01,  4.9251e+00,  ..., -3.8281e+01,\n",
              "           -3.5500e+01, -3.6750e+01],\n",
              "          [ 3.9263e+00,  2.3020e-01,  3.8285e+00,  ..., -3.7781e+01,\n",
              "           -3.5000e+01, -3.6438e+01]],\n",
              "\n",
              "         [[ 7.4036e-02, -3.5620e-01,  7.2510e-01,  ..., -3.4812e+01,\n",
              "           -3.0016e+01, -2.7078e+01],\n",
              "          [-4.6206e-01, -1.0701e+00,  9.6159e-01,  ..., -3.5906e+01,\n",
              "           -2.9625e+01, -2.8156e+01],\n",
              "          [ 2.3841e-02,  1.3266e+00,  1.6264e+00,  ..., -3.6312e+01,\n",
              "           -3.0109e+01, -2.7609e+01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 5.5084e-02,  2.9785e-01, -4.0126e-04,  ...,  3.0734e+01,\n",
              "            4.4297e+00, -2.1969e+01],\n",
              "          [ 6.5086e-01,  1.3108e+00,  1.7117e+00,  ...,  3.1484e+01,\n",
              "            1.4404e+00, -2.1734e+01],\n",
              "          [-1.6960e-01,  1.4831e+00,  2.8676e+00,  ...,  3.2188e+01,\n",
              "            4.5093e-01, -2.1297e+01]],\n",
              "\n",
              "         [[-2.4139e-02,  9.3262e-02, -5.7587e-02,  ..., -1.6094e+01,\n",
              "            1.2688e+01, -1.9953e+01],\n",
              "          [-1.9646e+00,  3.2521e-01, -2.4304e+00,  ..., -1.6234e+01,\n",
              "            1.2445e+01, -1.9875e+01],\n",
              "          [-1.4476e+00, -7.5989e-01, -3.4542e+00,  ..., -1.7391e+01,\n",
              "            1.3438e+01, -1.9562e+01]],\n",
              "\n",
              "         [[ 1.4844e-01, -5.6519e-02, -4.3671e-02,  ...,  2.8156e+01,\n",
              "            2.4969e+01, -2.7500e+01],\n",
              "          [ 9.1808e-01, -1.6897e-01, -1.4622e+00,  ...,  2.8109e+01,\n",
              "            2.5484e+01, -2.7594e+01],\n",
              "          [-3.3883e-02, -6.4924e-01, -7.2861e-01,  ...,  2.8344e+01,\n",
              "            2.6500e+01, -2.7969e+01]]]], device='cuda:0',\n",
              "       grad_fn=<CatBackward0>), tensor([[[[-2.0325e-01, -7.2571e-02,  1.3159e-01,  ...,  2.9205e-02,\n",
              "            2.1683e-02,  1.2619e-02],\n",
              "          [-6.5234e-01, -5.9912e-01,  1.4380e-01,  ..., -3.0298e-01,\n",
              "            2.5732e-01,  3.2788e-01],\n",
              "          [ 4.1687e-02, -2.3901e-01,  8.0994e-02,  ..., -1.3770e-01,\n",
              "           -2.8267e-03, -3.9966e-01]],\n",
              "\n",
              "         [[ 1.6144e-02, -2.7557e-02, -2.2831e-03,  ..., -1.0577e-01,\n",
              "            1.1279e-01, -9.8877e-02],\n",
              "          [-2.2656e-01, -1.2189e-01,  7.1259e-03,  ..., -4.1382e-01,\n",
              "           -3.8574e-01, -4.2676e-01],\n",
              "          [-3.2837e-01,  3.6987e-02, -1.1530e-03,  ..., -3.7671e-01,\n",
              "           -6.1816e-01, -4.6484e-01]],\n",
              "\n",
              "         [[ 1.2415e-01,  6.2027e-03, -4.7058e-02,  ..., -7.8491e-02,\n",
              "           -1.0870e-01,  3.7048e-02],\n",
              "          [ 6.0156e-01,  4.0015e-01,  3.8086e-01,  ..., -8.8745e-02,\n",
              "           -4.7852e-01,  1.7883e-01],\n",
              "          [-1.2976e-01,  5.2734e-01,  3.1030e-01,  ...,  7.6721e-02,\n",
              "           -3.1274e-01,  3.0005e-01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-2.9892e-02,  9.7046e-02,  1.0498e-01,  ...,  4.3976e-02,\n",
              "            1.2915e-01,  1.1060e-01],\n",
              "          [-2.4878e-01, -1.9885e-01,  9.1858e-02,  ..., -5.0293e-01,\n",
              "            4.8999e-01,  2.3694e-01],\n",
              "          [-4.0698e-01,  7.8430e-02,  2.9614e-01,  ..., -4.3433e-01,\n",
              "            1.1115e-01, -1.5576e+00]],\n",
              "\n",
              "         [[ 3.3569e-02, -1.1176e-01, -8.2458e-02,  ..., -5.3009e-02,\n",
              "           -1.8835e-01,  5.2399e-02],\n",
              "          [-5.8203e-01, -6.8457e-01,  2.4390e-01,  ..., -9.8511e-02,\n",
              "           -9.1748e-01,  3.8208e-01],\n",
              "          [-1.4648e-01,  8.9722e-02, -4.5443e-04,  ..., -1.3843e-01,\n",
              "           -6.7200e-02, -2.5757e-01]],\n",
              "\n",
              "         [[ 2.9953e-02,  1.0992e-01, -9.2773e-02,  ..., -1.0666e-02,\n",
              "            9.9548e-02,  6.1401e-02],\n",
              "          [-7.4463e-01,  8.0469e-01, -8.1348e-01,  ...,  3.3936e-01,\n",
              "            5.0244e-01, -8.4290e-02],\n",
              "          [-7.1826e-01,  3.5278e-01, -4.8779e-01,  ...,  1.7505e-01,\n",
              "            3.8208e-02, -3.8257e-01]]]], device='cuda:0', dtype=torch.float16,\n",
              "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 2.9114e-02,  1.9910e-01,  7.7246e-01,  ..., -3.4625e+01,\n",
              "            3.4906e+01,  3.7281e+01],\n",
              "          [ 4.9966e-01, -3.0665e-01, -1.2154e+00,  ..., -3.3250e+01,\n",
              "            3.4625e+01,  3.7812e+01],\n",
              "          [ 1.3882e+00, -2.0577e+00,  1.8870e+00,  ..., -3.3094e+01,\n",
              "            3.3750e+01,  3.7562e+01]],\n",
              "\n",
              "         [[ 1.3203e+00,  1.2051e+00, -1.2930e+00,  ...,  3.7938e+01,\n",
              "           -3.6812e+01, -3.6781e+01],\n",
              "          [-1.8897e+00, -1.3111e+00, -2.4537e+00,  ...,  3.7750e+01,\n",
              "           -3.7219e+01, -3.7469e+01],\n",
              "          [-1.0560e+01,  2.2972e+00, -6.8253e+00,  ...,  3.7938e+01,\n",
              "           -3.6844e+01, -3.7781e+01]],\n",
              "\n",
              "         [[ 1.2680e-02,  1.1047e-01, -1.8042e-01,  ...,  4.1219e+01,\n",
              "            3.9375e+01,  4.0750e+01],\n",
              "          [-2.0351e+00,  2.4810e+00, -1.3634e+00,  ...,  4.0906e+01,\n",
              "            3.8688e+01,  4.0500e+01],\n",
              "          [-1.6785e+00,  6.6483e+00, -3.1171e+00,  ...,  4.0969e+01,\n",
              "            3.8906e+01,  4.0750e+01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 2.3633e-01,  4.0436e-02, -3.5327e-01,  ..., -3.2531e+01,\n",
              "           -3.3375e+01, -2.1891e+01],\n",
              "          [-1.8898e+00, -1.6708e+00, -3.9886e+00,  ..., -3.2281e+01,\n",
              "           -3.3594e+01, -2.2047e+01],\n",
              "          [-6.2288e+00, -5.2466e+00, -5.7415e+00,  ..., -3.1969e+01,\n",
              "           -3.3594e+01, -2.2125e+01]],\n",
              "\n",
              "         [[ 1.0364e-01,  5.8105e-01, -5.4541e-01,  ...,  3.3719e+01,\n",
              "           -3.1344e+01, -3.6125e+01],\n",
              "          [-5.9550e-01,  6.2316e-01, -8.8913e-01,  ...,  3.4594e+01,\n",
              "           -3.1125e+01, -3.6438e+01],\n",
              "          [-1.4353e+00, -9.7836e-01, -1.3167e+00,  ...,  3.3844e+01,\n",
              "           -3.1703e+01, -3.6281e+01]],\n",
              "\n",
              "         [[ 5.9448e-02,  1.4075e-01, -2.1448e-01,  ..., -3.2406e+01,\n",
              "            3.3594e+01,  3.5250e+01],\n",
              "          [-1.8187e+00,  2.6845e+00, -2.3209e+00,  ..., -3.1469e+01,\n",
              "            3.3562e+01,  3.5406e+01],\n",
              "          [ 9.3194e-01,  9.1698e-01,  1.7794e-01,  ..., -3.1438e+01,\n",
              "            3.2406e+01,  3.6344e+01]]]], device='cuda:0',\n",
              "       grad_fn=<CatBackward0>), tensor([[[[ 0.0898,  0.0355,  0.0019,  ...,  0.0264,  0.0807,  0.1274],\n",
              "          [-0.1481,  0.5190,  0.1521,  ...,  0.6763,  0.3708,  0.3313],\n",
              "          [-0.2094,  0.5942, -0.6768,  ..., -0.0341,  0.7095,  0.0603]],\n",
              "\n",
              "         [[-0.1132,  0.0476, -0.0826,  ..., -0.0110, -0.1267, -0.0196],\n",
              "          [-0.4995, -0.0676, -0.1495,  ...,  0.1934,  0.5420,  0.1152],\n",
              "          [-0.3450,  0.1556, -0.0792,  ...,  0.2981,  0.5854,  0.1000]],\n",
              "\n",
              "         [[ 0.0141, -0.1080, -0.0577,  ...,  0.0928, -0.0422, -0.0147],\n",
              "          [-0.0953, -0.1445,  0.2393,  ...,  0.1965,  0.0269, -0.0921],\n",
              "          [-0.1682,  0.5020,  0.2795,  ..., -0.6353,  0.3650,  0.1122]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 0.0726,  0.0828, -0.1123,  ..., -0.0177,  0.0911,  0.1092],\n",
              "          [ 0.1270, -0.3772, -0.4097,  ..., -0.0772, -0.0450,  0.4053],\n",
              "          [-0.5005,  0.2654, -1.3730,  ...,  0.0439, -0.4888,  0.2158]],\n",
              "\n",
              "         [[-0.0899,  0.0703, -0.1056,  ...,  0.0482, -0.1067, -0.0293],\n",
              "          [-0.0266,  0.7119, -0.4194,  ...,  0.6753,  0.0418, -0.2184],\n",
              "          [-0.2209,  0.7534, -0.6465,  ...,  0.3333,  0.4712, -0.8281]],\n",
              "\n",
              "         [[ 0.0861, -0.0723, -0.0474,  ..., -0.0349, -0.0994, -0.0175],\n",
              "          [ 0.7085,  0.0701, -0.3767,  ..., -0.2466, -0.0561,  0.4812],\n",
              "          [ 1.0742,  0.4802, -0.7861,  ..., -0.4314, -0.2419,  0.4648]]]],\n",
              "       device='cuda:0', dtype=torch.float16, grad_fn=<PermuteBackward0>)), (tensor([[[[ 5.8496e-01,  5.2783e-01, -9.3460e-03,  ..., -3.9000e+01,\n",
              "            3.8750e+01,  3.7094e+01],\n",
              "          [-2.7582e+00, -2.1096e+00, -1.2514e+01,  ..., -3.8562e+01,\n",
              "            3.9156e+01,  3.7406e+01],\n",
              "          [-1.7022e+01, -8.3549e+00, -2.3240e+01,  ..., -3.8094e+01,\n",
              "            3.8844e+01,  3.7656e+01]],\n",
              "\n",
              "         [[-2.0554e-02,  9.3945e-01, -1.9702e-01,  ..., -3.6906e+01,\n",
              "           -3.6281e+01, -3.7281e+01],\n",
              "          [-7.8843e+00,  3.8061e+00,  1.5948e+00,  ..., -3.8031e+01,\n",
              "           -3.5844e+01, -3.5281e+01],\n",
              "          [-1.4353e+01,  4.7767e+00,  5.2274e+00,  ..., -3.8156e+01,\n",
              "           -3.7125e+01, -3.6219e+01]],\n",
              "\n",
              "         [[ 3.3281e+00,  2.6978e-01, -1.9580e+00,  ..., -3.7469e+01,\n",
              "            3.7594e+01, -3.5281e+01],\n",
              "          [ 1.6504e+01,  9.3995e+00, -1.2942e+01,  ..., -3.7562e+01,\n",
              "            3.8375e+01, -3.5156e+01],\n",
              "          [ 2.1464e+00,  1.9727e+01, -1.9439e+01,  ..., -3.7594e+01,\n",
              "            3.7719e+01, -3.6562e+01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-6.1377e-01,  1.8770e+00, -1.5596e+00,  ..., -3.6969e+01,\n",
              "            3.7188e+01,  3.6969e+01],\n",
              "          [-7.0680e+00,  9.3587e+00, -1.5057e+00,  ..., -3.6844e+01,\n",
              "            3.8188e+01,  3.7156e+01],\n",
              "          [-1.1815e+00,  1.0855e+01, -5.6100e+00,  ..., -3.6688e+01,\n",
              "            3.7000e+01,  3.8156e+01]],\n",
              "\n",
              "         [[-1.1445e+00, -2.8555e+00,  3.4980e+00,  ..., -3.2406e+01,\n",
              "            3.2375e+01, -3.5250e+01],\n",
              "          [ 7.3835e+00, -1.2554e+01,  6.5976e+00,  ..., -3.3125e+01,\n",
              "            2.9266e+01, -3.4938e+01],\n",
              "          [ 1.8788e+01, -1.3041e+01,  1.3906e+01,  ..., -3.3156e+01,\n",
              "            2.9594e+01, -3.5312e+01]],\n",
              "\n",
              "         [[-1.1143e+00,  2.0703e+00, -1.6172e+00,  ...,  3.3906e+01,\n",
              "            3.5656e+01, -2.9156e+01],\n",
              "          [-3.6210e-01,  8.6655e+00, -4.2762e+00,  ...,  3.3281e+01,\n",
              "            3.5438e+01, -2.8406e+01],\n",
              "          [ 2.6040e+00,  1.1524e+01, -3.9993e+00,  ...,  3.3125e+01,\n",
              "            3.5906e+01, -2.8609e+01]]]], device='cuda:0',\n",
              "       grad_fn=<CatBackward0>), tensor([[[[-6.1963e-01,  6.5857e-02, -7.4951e-01,  ..., -1.3257e-01,\n",
              "            2.5375e-02, -1.1304e-01],\n",
              "          [-9.4287e-01, -1.6833e-01, -7.2803e-01,  ..., -2.6514e-01,\n",
              "            6.0254e-01,  5.7037e-02],\n",
              "          [-1.0781e+00, -8.9539e-02, -1.3213e+00,  ..., -1.5552e-01,\n",
              "           -6.6895e-02,  4.3121e-02]],\n",
              "\n",
              "         [[-2.1225e-02,  1.3049e-01, -3.8477e-01,  ...,  1.0693e-01,\n",
              "           -5.7945e-03, -4.8859e-02],\n",
              "          [ 1.2927e-01,  7.3291e-01,  1.0271e-03,  ...,  2.3425e-01,\n",
              "            1.1792e-01,  1.4258e-01],\n",
              "          [ 4.5996e-01,  4.6436e-01, -6.2109e-01,  ...,  8.7280e-02,\n",
              "           -2.7490e-01,  8.6121e-02]],\n",
              "\n",
              "         [[-1.0049e+00,  2.5482e-02,  1.8286e-01,  ..., -1.7993e-01,\n",
              "            3.8940e-02,  5.9277e-01],\n",
              "          [-1.6436e+00,  6.5247e-02,  4.0503e-01,  ..., -2.9443e-01,\n",
              "            6.1768e-01,  1.1611e+00],\n",
              "          [-1.2725e+00, -6.6064e-01,  6.3916e-01,  ...,  1.3806e-01,\n",
              "            3.6035e-01,  5.1904e-01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 5.8716e-02,  4.7363e-02, -8.2458e-02,  ...,  8.7158e-01,\n",
              "            6.2378e-02, -7.5928e-02],\n",
              "          [-1.7236e-01,  6.2451e-01, -2.7344e-01,  ...,  1.1113e+00,\n",
              "           -3.1348e-01, -2.1851e-01],\n",
              "          [-6.8848e-02,  3.0273e-01, -4.7046e-01,  ...,  1.1621e+00,\n",
              "           -2.1814e-01, -1.4294e-01]],\n",
              "\n",
              "         [[ 2.3651e-02, -1.6711e-01, -1.1969e-01,  ..., -2.6535e-02,\n",
              "           -1.1147e-02, -7.6721e-02],\n",
              "          [-2.4011e-01, -5.8887e-01,  9.1095e-03,  ..., -4.1162e-01,\n",
              "            2.4341e-01,  1.4084e-02],\n",
              "          [-4.3018e-01, -3.8361e-02, -6.3232e-02,  ..., -4.5386e-01,\n",
              "            6.5625e-01, -1.8036e-02]],\n",
              "\n",
              "         [[ 4.0918e-01, -1.0681e-01,  1.5344e-01,  ..., -2.7563e-01,\n",
              "            3.3301e-01, -4.0192e-02],\n",
              "          [ 5.2881e-01, -1.3354e-01,  5.9509e-04,  ..., -5.7373e-01,\n",
              "            3.2910e-01,  3.5229e-01],\n",
              "          [ 1.2168e+00, -1.0040e-01, -1.2842e-01,  ..., -6.3623e-01,\n",
              "            6.3281e-01, -2.5317e-01]]]], device='cuda:0', dtype=torch.float16,\n",
              "       grad_fn=<PermuteBackward0>))), hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
        "q_model(**tokenizer('Testing the changes', return_tensors='pt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAVgAq0uydr6"
      },
      "source": [
        "## Dequantize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "WgWZNFMIarG9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2fd56c5-72e4-489f-d418-583b81f91346"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model is going to be dequantized in torch.float16 - if you want to upcast it to another dtype, make sure to pass the desired dtype when quantizing the model through `bnb_4bit_quant_type` argument of `BitsAndBytesConfig`\n",
            "For some reason the model has not been properly dequantized. You might see unexpected behavior.\n"
          ]
        }
      ],
      "source": [
        "deq_model = q_model.dequantize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX9735JQMVym",
        "outputId": "8d23b0b8-d61d-41d1-e2c0-d5afff981d1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "455.393688\n"
          ]
        }
      ],
      "source": [
        "print(deq_model.get_memory_footprint()/1e6)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_model.hf_quantizer??"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JovRYeD5RZQo",
        "outputId": "cea5fb81-d50e-4b1a-f7e9-69c1e4de8791"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Object `q_model.hf_quantizer` not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xi1CFXq5SCzC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a46901efeb5a4774856e8e8dcf64834b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_205d7c1ed50448658a115f35d5c4846d",
              "IPY_MODEL_424f24aaf797450db4726d23efa82dfd",
              "IPY_MODEL_157367a343de4d508a6f6c2d3cf2f924"
            ],
            "layout": "IPY_MODEL_8dd90572097d4f47b1cf2b2c974db279"
          }
        },
        "205d7c1ed50448658a115f35d5c4846d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5388eb8007d9439285d0aa06910a9ca9",
            "placeholder": "​",
            "style": "IPY_MODEL_9d866e441f3a445faa98b13403e14abb",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "424f24aaf797450db4726d23efa82dfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0844f3ab460047be9ebf385c7887757c",
            "max": 396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d3c3eb3ab8a400e9bd0c73320009ac5",
            "value": 396
          }
        },
        "157367a343de4d508a6f6c2d3cf2f924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af7948b99cad40fe9423c1ffc01994b1",
            "placeholder": "​",
            "style": "IPY_MODEL_bb5b588c39d8402ba1c462c88fcb46b7",
            "value": " 396/396 [00:00&lt;00:00, 33.0kB/s]"
          }
        },
        "8dd90572097d4f47b1cf2b2c974db279": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5388eb8007d9439285d0aa06910a9ca9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d866e441f3a445faa98b13403e14abb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0844f3ab460047be9ebf385c7887757c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d3c3eb3ab8a400e9bd0c73320009ac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af7948b99cad40fe9423c1ffc01994b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb5b588c39d8402ba1c462c88fcb46b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "401bfd6b8de94d9ba8746862e05cfe16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35149e6be34848da8344563275f991ac",
              "IPY_MODEL_09665b5761a1414db126fc3074b2e8ad",
              "IPY_MODEL_e82daf0e099c4d59bfc994bba5e3e105"
            ],
            "layout": "IPY_MODEL_400d6f098b85479698a95d92143fab2c"
          }
        },
        "35149e6be34848da8344563275f991ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dce07f8e405f4d1f9b256a1d97f9e106",
            "placeholder": "​",
            "style": "IPY_MODEL_b6bb277130eb4472906fa5424621b4f5",
            "value": "tokenizer.json: 100%"
          }
        },
        "09665b5761a1414db126fc3074b2e8ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f512ce7b1905423c889577420ba0a9db",
            "max": 2113710,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e6854b5235f48d8a73ede7e5017bb01",
            "value": 2113710
          }
        },
        "e82daf0e099c4d59bfc994bba5e3e105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a1ce4bb87bd436f8dd8ac3bd7f416ab",
            "placeholder": "​",
            "style": "IPY_MODEL_b7a056295f464e34a0d8e99832a71181",
            "value": " 2.11M/2.11M [00:00&lt;00:00, 10.8MB/s]"
          }
        },
        "400d6f098b85479698a95d92143fab2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dce07f8e405f4d1f9b256a1d97f9e106": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6bb277130eb4472906fa5424621b4f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f512ce7b1905423c889577420ba0a9db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e6854b5235f48d8a73ede7e5017bb01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a1ce4bb87bd436f8dd8ac3bd7f416ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7a056295f464e34a0d8e99832a71181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9cff4bff2c24a518117ce5e01d9a805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_308f8fa1f7ee4f1c9f4e99f1eb6806f4",
              "IPY_MODEL_8dc2721b61c34eabaffd74224db4d638",
              "IPY_MODEL_65f6bb6a0fd74832ba3f7a7cdc7426f2"
            ],
            "layout": "IPY_MODEL_c0949eacf6684db9b77a88f467f8f2ae"
          }
        },
        "308f8fa1f7ee4f1c9f4e99f1eb6806f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9262e4ad868d49da8f4822a98e1ec7db",
            "placeholder": "​",
            "style": "IPY_MODEL_e6ca34efbd0d4a2d9caed79299e99402",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "8dc2721b61c34eabaffd74224db4d638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35c2d5274be64c0da9c0fbf9c0374eca",
            "max": 99,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2ee9ddbc7dc4345a95781c610bb4368",
            "value": 99
          }
        },
        "65f6bb6a0fd74832ba3f7a7cdc7426f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2596cd591e548f98bb4fa9530e533a9",
            "placeholder": "​",
            "style": "IPY_MODEL_567a36b547de4a9ea025ad9248be7cb6",
            "value": " 99.0/99.0 [00:00&lt;00:00, 8.57kB/s]"
          }
        },
        "c0949eacf6684db9b77a88f467f8f2ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9262e4ad868d49da8f4822a98e1ec7db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6ca34efbd0d4a2d9caed79299e99402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35c2d5274be64c0da9c0fbf9c0374eca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2ee9ddbc7dc4345a95781c610bb4368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2596cd591e548f98bb4fa9530e533a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "567a36b547de4a9ea025ad9248be7cb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}