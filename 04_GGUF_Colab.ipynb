{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NID123-CH/LLM-Codes/blob/main/04_GGUF_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aXbsBLV-_Ei"
      },
      "source": [
        "# GGUF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORtXEUAW2QC7",
        "outputId": "e27f2bfa-c78c-463d-adcc-0dad4df38666"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting peft\n",
            "  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.24.7)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
            "Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.13.2-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes, peft\n",
            "Successfully installed bitsandbytes-0.44.1 peft-0.13.2\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate bitsandbytes peft"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac0Ld6j2-_En"
      },
      "source": [
        "## Install GGUF-PY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dvFCAjP1YzY",
        "outputId": "33fa4578-2e6e-4fed-dd71-b54c872ea3fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llama.cpp'...\n",
            "remote: Enumerating objects: 15623, done.\u001b[K\n",
            "remote: Counting objects: 100% (4576/4576), done.\u001b[K\n",
            "remote: Compressing objects: 100% (171/171), done.\u001b[K\n",
            "remote: Total 15623 (delta 4485), reused 4406 (delta 4405), pack-reused 11047 (from 1)\u001b[K\n",
            "Receiving objects: 100% (15623/15623), 21.40 MiB | 9.66 MiB/s, done.\n",
            "Resolving deltas: 100% (11109/11109), done.\n",
            "Note: switching to '3f167476b11efa7ab08f6cacdeb8cab0935c1249'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "Processing /content/llama.cpp/gguf-py\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from gguf==0.9.0) (1.26.4)\n",
            "Building wheels for collected packages: gguf\n",
            "  Building wheel for gguf (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gguf: filename=gguf-0.9.0-py3-none-any.whl size=30136 sha256=0ddb0288ba63a9fda09228a7948da94df9e7e4e13177875b3d52aeb7c7b94938\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/42/13/ff5427daa7a8a54a9bbcfafc10a0cd0cb13eae7952fb878270\n",
            "Successfully built gguf\n",
            "Installing collected packages: gguf\n",
            "Successfully installed gguf-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!git clone -b b2760 --single-branch https://github.com/ggerganov/llama.cpp.git\n",
        "!cd llama.cpp/gguf-py && pip install ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "487K5ZUZ-_Er"
      },
      "source": [
        "## Load Base Model and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580,
          "referenced_widgets": [
            "1a1e4c29ae2b474dbf8237f85cb35b73",
            "3bed4fed6948457981f14ca01d121f6c",
            "df0f5fd8debb40bca962b7c49c83f472",
            "acb0cf6e36e14e4ab144492f03473693",
            "e61d40cbbda84523aa72c2e0b4de9f3e",
            "e7a10efd91bf4d8ebcef20404fc467d4",
            "d2255e978c5842f0a03ded6f92bf287f",
            "5beb8fea92a842298b01264792988ef4",
            "b844d6ceb5924b0392387e71abc0f12d",
            "10aadd7fa2874c4d9de184360233adc3",
            "191f3840c33848808af95e69e106b512",
            "afc86549f7004bacb85491b60fc9b06b",
            "82610ae59ccf4ba4aaf1d16f779ce6cd",
            "93370cabcd124d7a9d8069f4306b6faf",
            "9849017be0e142278fdc826afaa8f9c7",
            "3cf2b3bbba3d424ca4eaf6cbe8317917",
            "0b18e83387aa4711afeedb552b45a80d",
            "12a7c7b4c46747e69954119e97ef65bc",
            "32df4440f82c43f7816315ada79b1348",
            "66f299d22e464d90abd8905b74253a50",
            "31752869b2ff43038091fba2e4a2f189",
            "b368558fbd81468aaf546266f708f6bd",
            "af1f0e0c8c124d489fa0dcf6c8dae60a",
            "f8f06bc7937442eb8dfd214837efaad6",
            "e017c10c0f004bc694c5376545be87e4",
            "5f1e1a3f58fd4612b2f5032f986d8e3d",
            "ec9bcfa0ff064670bb1cb87c21377aa1",
            "b3d9c03902584c85bb0105049f30934a",
            "7e0f3c6c3c5e41ab8cade3cbc5423ce0",
            "4b1a40c938ff47ed933599cfc4b2a7d4",
            "d81b992d329f45c8b6851415c95e7ac4",
            "19480d32a5f441f4971598cee11f1493",
            "d9b832bc7710409aa574809aa2801bce",
            "6e738977567041609e08c44a63ed4963",
            "d8209772cfb64967aa112915f47c7af4",
            "c1c30aed034a419dae442250a153cda1",
            "5e7ee4baf3b14b53816505f131882f5f",
            "dc893d16445f40f8821bf55a1d640949",
            "69509b0d07de4ab68ee4f34c3b41dd21",
            "80d84fd5ff414a6e92818f9a9e3442ae",
            "0c178bd343cb41a7924164c9fed14caf",
            "6391ac8408b94380970dbde06bfbcdf2",
            "af0cd4157eb24827a915fec3d8b32f46",
            "6194c1dd183543b082badfade6c502d4",
            "d78e61d1b2a6479e850d190acd8aabdf",
            "31f33edfc866406eb19911780b3e8773",
            "97636dc8b3284c0ca5d68b5e823cf160",
            "5556fd9e8c18481492d209853ef4feac",
            "b631082e89c748929bc12a86ec155ff9",
            "2c044cd86c6b41aba3e46e01aa761b20",
            "777c6d80beac41dfab953242d3eb6a29",
            "4132181f94dd4339a5393b19339ebe7c",
            "6e9e3d35ca8249638f4ff30e89e52b43",
            "cbb8e7d5ac9b4406b7a9114c28ac3a43",
            "7a2b70b322d04b57bfe0cc0c0b6303fd",
            "b01f74a93a9840fe87a7084a27fc75c1",
            "25b92984b3a949b482f0f6dbcbac013d",
            "1f5eb142283949a8b5a5cb4c010ed0c2",
            "e079e7012ab5480eb613ba4f99f180d0",
            "1b63dc9d621d4251a1e1f4639aa48c18",
            "628ea22f4c0c4ed59de61dc16108a10a",
            "d5ecbfc49efb4d37bcd02b83caed1db8",
            "1e3750b35bec42e2a7fad992014cc1a8",
            "73a3b70f4b804855ab36917ba7c24bd6",
            "8fb6f28a422c403d854fc6d750aed038",
            "56a4a76a1ffa43e69dc52f54351c4ee0",
            "f35c62c9c9e6414586fc6dd0358d8a50",
            "b7c71cece89849948fc8f18d14a7eb73",
            "35edbf04c34a480eb665394e6b6ed764",
            "54aeba9431304df28a530ef2270ce47b",
            "5ed5f158fb7f4a0383369f87773e934d",
            "596c3239393d4a48955875270ceaeb9c",
            "918c7aeb1c4e4f9abd875442b4142156",
            "362f78f1c05b4a39907411d3a460dfef",
            "f42a154b44aa4812bf7eb06ddf5dd6c3",
            "771fb316380147f2be1ea2d4f12eb45a",
            "83c0724170764457b39357b6ee29d6d8",
            "11d6bd32e2114393a67224ae5fdd7db4",
            "650041ffdd0e43b481958906e5011bb6",
            "90076a5bf95c436cbe1a774f1a832ec4",
            "55e0515b8d0c40a19020b6096e5f6094",
            "2b250fd4e37046bead660688f839be6e",
            "5269d8e9d8b8474ca97f94ae46bcf277",
            "fb7606a1f7704b5a82d73d5225a392d8",
            "b66ffe170f85414299c49103323bf99a",
            "8682b7ed3a8f4a6d840df4ed76e2a390",
            "8b77596bed4f4bc38dc80b03f629ec4a",
            "d20c493117c44d8a807c279e0e466804",
            "53f3e7b0b8f8413eb1976dd1ac57e345",
            "68c6a2e7b9ca45928a6d139d8d848636",
            "c44d2bffe6ca4d37822ca88e35030883",
            "48c0e2f2d5834eb6afdd42c0f5664a97",
            "351df7e8344f4ecf9e79bb361bfb394c",
            "65923751e78a4837bd8e6f89bfc81ff5",
            "861cce46bc8d484284c471451106ff5a",
            "4b31afd992f5441fbf609906f5d2d28a",
            "ff377c7455244da3be56a968882eb898",
            "fb72b776ba7b4d668315bcd9e5168144",
            "5150fad18fee40e1a70841971bcc6b5c",
            "f3622fcca2704b34b1ffbd3fb77810d4",
            "4704727c51924aa2a1caa4951d7647e4",
            "b57dc6f9dd874fe5994935f818a415ee",
            "3821edefa9b547b9986348dcb25576cb",
            "7bd3627e47ee4d9fb75f807385e55ebb",
            "f17e86f493194a818e46acbff695ce74",
            "7724f481fa4c4f039686103157144172",
            "1d0e7abe605440a58ac3bcbdb29b9d18",
            "165cb2cef5364bafa35eb74a90f78d32",
            "307f42379165477786e29a9a82593a13",
            "468e3eb48351404abec26b499d215acd",
            "2f3547b9a8d947e4b5e35a48b0e2bd61",
            "ce00506fb3674cdc899234151ac45dc4",
            "065ddc44413f4546abdc54096951a657",
            "c544445ea5ef4ba1b5411704249e415c",
            "c8a8718680ce463ca9a1b921c8aba866",
            "4fdbe87a833d4e928be8f0762be99027",
            "74a63060648143558f848c3712525899",
            "8e8fcb1f5f0b4b059b770fab954d37eb",
            "45968a4045b04566910f772ca0662664",
            "b557fb83dbce4e539f830d897fe79cbb",
            "aa7ea7c46fd34756a83a813eaba3f621",
            "e735fcececa64867930ca30bf9d9d703",
            "d939472d2b8a48d59c41cf070813c940",
            "c2dcb87123a9445cb86ad58cd85f7250",
            "b38805d675e840c5868478618274232f",
            "d7730feb260e4b3e9f281ef48e840265",
            "392da393a021459c9e1101d11542b184",
            "af61150c7ace4de0a1edac470f63a62a",
            "882d36d7864549c9925d4a82620b3dbb",
            "cb2df06d4f964dd4a3808ce62c4f8ce4",
            "4db54774874e45168741b179d06d09bb",
            "0b9156fede034b59a5e5328e44c2bb3e",
            "0698800dd3bb47819351063ae76e979f",
            "5d523da4c754408cadbb57e8d93d814b",
            "e835a040ee8f44469859c7e24598de19",
            "ab2dadf5170e4524af913a2764acd7c5",
            "c7115c64d89746f5aa5ea6d9d341c566",
            "2cf3e428ca1d4232aa61e262bc981be3",
            "ac824d086c4b41ff87941b2d920e8b48",
            "9b18391837d241c3a770e05f403a6075",
            "14f05fb9cf524232808f1c5f284dbf44",
            "b7361e11048245e5962f8643967f269d",
            "6c0234060a2240729218f21b4722da94"
          ]
        },
        "id": "_P4FkUwU1r8V",
        "outputId": "ad08910d-474e-46f4-8b58-bd4fbc49efb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a1e4c29ae2b474dbf8237f85cb35b73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/35.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afc86549f7004bacb85491b60fc9b06b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af1f0e0c8c124d489fa0dcf6c8dae60a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e738977567041609e08c44a63ed4963"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d78e61d1b2a6479e850d190acd8aabdf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b01f74a93a9840fe87a7084a27fc75c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f35c62c9c9e6414586fc6dd0358d8a50"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11d6bd32e2114393a67224ae5fdd7db4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53f3e7b0b8f8413eb1976dd1ac57e345"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3622fcca2704b34b1ffbd3fb77810d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f3547b9a8d947e4b5e35a48b0e2bd61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e735fcececa64867930ca30bf9d9d703"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0698800dd3bb47819351063ae76e979f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "name = 'microsoft/phi-2'\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(name, trust_remote_code=True, device_map={\"\": 0})\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    name,\n",
        "    use_fast=False,\n",
        ")\n",
        "tokenizer.add_special_tokens({'pad_token': '<|pad|>'})\n",
        "tokenizer.add_special_tokens({'additional_special_tokens': ['##[YODA]##>']})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imCqrCsS-_Et"
      },
      "source": [
        "### Loads Trained Adapter and Merges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mFNuE8BcnbF",
        "outputId": "da4afbaa-d1d8-4668-e447-2f850f0e2924"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1kWPIHny94ZDSQffyRiS15yaUScQVe1Ji\n",
            "From (redirected): https://drive.google.com/uc?id=1kWPIHny94ZDSQffyRiS15yaUScQVe1Ji&confirm=t&uuid=6c98c653-cf3b-4c31-8b60-2d93fa80fb65\n",
            "To: /content/yoda_adapter.zip\n",
            "100% 535M/535M [00:12<00:00, 43.4MB/s]\n",
            "Archive:  yoda_adapter.zip\n",
            "  inflating: yoda_adapter/adapter_config.json  \n",
            "  inflating: yoda_adapter/adapter_model.safetensors  \n",
            "  inflating: yoda_adapter/README.md  \n",
            "  inflating: yoda_adapter/training_args.bin  \n"
          ]
        }
      ],
      "source": [
        "!gdown 1kWPIHny94ZDSQffyRiS15yaUScQVe1Ji\n",
        "!unzip -d yoda_adapter yoda_adapter.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "z0lmV_6xclzi"
      },
      "outputs": [],
      "source": [
        "from peft import PeftModel\n",
        "\n",
        "fine_tuned_model = PeftModel.from_pretrained(model, './yoda_adapter')\n",
        "merged_model = fine_tuned_model.merge_and_unload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTEOPhvTbkv7"
      },
      "source": [
        "### Save Merged Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2FdYA4c1ttD",
        "outputId": "678d436b-ae72-482d-d7ba-78d82d1c25ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model/tokenizer_config.json',\n",
              " './model/special_tokens_map.json',\n",
              " './model/vocab.json',\n",
              " './model/merges.txt',\n",
              " './model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "!rm -rf ./model && mkdir model\n",
        "merged_model.save_pretrained('./model')\n",
        "tokenizer.save_pretrained('./model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UVy80laT99m",
        "outputId": "be4235fd-a752-40a2-a43c-a7c6a977bfe3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import gc\n",
        "del fine_tuned_model\n",
        "del merged_model\n",
        "del model\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-o6ke80-_Ey"
      },
      "source": [
        "## Conversion to GGUF Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jP7RJ7rQ1-Vu"
      },
      "outputs": [],
      "source": [
        "#!curl -L -o convert.py https://github.com/ggerganov/llama.cpp/raw/master/convert.py\n",
        "#!curl -L -o convert-hf-to-gguf.py https://github.com/ggerganov/llama.cpp/raw/master/convert-hf-to-gguf.py\n",
        "\n",
        "# commit 3f167476b11efa7ab08f6cacdeb8cab0935c1249\n",
        "#!curl -L -o convert.py https://raw.githubusercontent.com/ggerganov/llama.cpp/3f167476b11efa7ab08f6cacdeb8cab0935c1249/convert.py\n",
        "#!curl -L -o convert-hf-to-gguf.py https://raw.githubusercontent.com/ggerganov/llama.cpp/3f167476b11efa7ab08f6cacdeb8cab0935c1249/convert-hf-to-gguf.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnXaCHta2AOe",
        "outputId": "21a7f8b6-133a-4615-9e31-0f2d2b65ece7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model: model\n",
            "gguf: This GGUF file is for Little Endian only\n",
            "Set model parameters\n",
            "Set model tokenizer\n",
            "gguf: Adding 50000 merge(s).\n",
            "gguf: Setting special token type bos to 50256\n",
            "gguf: Setting special token type eos to 50256\n",
            "gguf: Setting add_bos_token to False\n",
            "Exporting model to 'model/ggml-model-f16.gguf'\n",
            "gguf: loading model part 'model-00001-of-00003.safetensors'\n",
            "token_embd.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.0.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.0.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.0.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.0.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.0.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.0.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.0.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.0.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.0.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.0.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.0.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.0.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.0.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.0.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.1.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.1.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.1.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.1.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.1.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.1.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.1.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.1.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.1.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.1.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.1.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.1.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.1.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.1.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.10.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.10.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.10.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.10.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.10.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.10.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.10.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.10.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.10.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.10.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.10.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.10.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.10.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.10.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.11.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.11.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.11.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.11.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.11.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.11.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.11.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.11.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.11.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.11.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.11.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.11.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.11.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.11.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.12.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.12.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.12.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.12.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.12.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.12.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.12.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.12.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.12.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.12.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.12.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.12.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.12.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.12.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.13.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.13.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.13.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.13.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.13.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.13.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.13.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.13.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.13.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.13.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.13.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.13.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.13.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.13.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.14.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.14.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.14.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.14.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.2.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.2.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.2.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.2.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.2.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.2.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.2.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.2.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.2.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.2.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.2.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.2.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.2.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.2.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.3.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.3.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.3.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.3.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.3.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.3.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.3.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.3.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.3.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.3.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.3.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.3.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.3.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.3.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.4.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.4.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.4.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.4.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.4.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.4.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.4.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.4.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.4.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.4.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.4.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.4.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.4.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.4.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.5.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.5.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.5.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.5.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.5.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.5.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.5.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.5.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.5.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.5.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.5.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.5.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.5.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.5.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.6.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.6.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.6.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.6.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.6.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.6.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.6.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.6.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.6.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.6.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.6.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.6.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.6.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.6.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.7.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.7.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.7.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.7.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.7.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.7.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.7.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.7.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.7.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.7.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.7.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.7.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.7.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.7.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.8.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.8.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.8.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.8.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.8.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.8.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.8.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.8.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.8.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.8.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.8.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.8.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.8.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.8.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.9.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.9.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.9.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.9.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.9.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.9.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.9.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.9.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.9.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.9.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.9.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.9.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.9.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.9.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "gguf: loading model part 'model-00002-of-00003.safetensors'\n",
            "blk.14.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.14.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.14.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.14.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.14.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.14.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.14.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.14.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.14.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.14.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.15.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.15.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.15.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.15.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.15.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.15.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.15.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.15.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.15.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.15.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.15.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.15.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.15.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.15.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.16.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.16.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.16.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.16.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.16.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.16.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.16.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.16.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.16.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.16.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.16.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.16.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.16.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.16.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.17.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.17.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.17.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.17.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.17.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.17.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.17.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.17.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.17.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.17.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.17.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.17.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.17.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.17.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.18.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.18.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.18.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.18.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.18.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.18.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.18.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.18.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.18.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.18.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.18.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.18.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.18.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.18.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.19.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.19.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.19.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.19.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.19.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.19.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.19.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.19.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.19.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.19.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.19.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.19.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.19.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.19.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.20.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.20.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.20.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.20.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.20.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.20.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.20.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.20.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.20.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.20.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.20.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.20.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.20.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.20.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.21.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.21.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.21.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.21.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.21.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.21.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.21.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.21.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.21.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.21.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.21.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.21.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.21.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.21.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.22.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.22.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.22.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.22.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.22.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.22.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.22.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.22.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.22.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.22.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.22.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.22.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.22.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.22.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.23.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.23.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.23.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.23.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.23.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.23.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.23.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.23.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.23.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.23.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.23.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.23.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.23.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.23.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.24.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.24.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.24.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.24.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.24.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.24.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.24.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.24.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.24.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.24.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.24.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.24.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.24.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.24.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.25.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.25.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.25.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.25.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.25.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.25.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.25.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.25.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.25.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.25.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.25.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.25.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.25.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.25.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.26.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.26.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.26.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.26.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.26.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.26.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.26.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.26.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.26.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.26.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.26.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.26.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.26.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.26.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.27.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.27.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.27.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.27.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.27.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.27.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.27.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.27.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.27.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.27.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.27.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.27.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.27.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.27.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.28.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.28.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.28.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.28.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.28.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.28.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.28.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.28.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.28.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.28.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.28.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.28.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.28.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.28.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.29.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.29.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.29.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.29.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.29.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.29.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.29.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.29.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.29.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.29.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.29.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.29.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.29.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.29.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "gguf: loading model part 'model-00003-of-00003.safetensors'\n",
            "output.bias, n_dims = 1, torch.float32 --> float32\n",
            "output.weight, n_dims = 2, torch.float32 --> float16\n",
            "output_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "output_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.30.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.30.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.30.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.30.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.30.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.30.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.30.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.30.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.30.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.30.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.30.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.30.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.30.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.30.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.31.attn_norm.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.31.attn_norm.weight, n_dims = 1, torch.float32 --> float32\n",
            "blk.31.ffn_up.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.31.ffn_up.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.31.ffn_down.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.31.ffn_down.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.31.attn_output.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.31.attn_output.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.31.attn_k.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.31.attn_k.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.31.attn_q.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.31.attn_q.weight, n_dims = 2, torch.float32 --> float16\n",
            "blk.31.attn_v.bias, n_dims = 1, torch.float32 --> float32\n",
            "blk.31.attn_v.weight, n_dims = 2, torch.float32 --> float16\n",
            "Model successfully exported to 'model/ggml-model-f16.gguf'\n"
          ]
        }
      ],
      "source": [
        "!python ./llama.cpp/convert-hf-to-gguf.py ./model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Opsv23Du-_E0"
      },
      "source": [
        "## Quantization\n",
        "\n",
        "### Install llama.cpp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Cf74LCgc3qLW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "21bc1af7-9f6c-417e-d781-d7615e1f8a88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I ccache not found. Consider installing it for faster compilation.\n",
            "I llama.cpp build info: \n",
            "I UNAME_S:   Linux\n",
            "I UNAME_P:   x86_64\n",
            "I UNAME_M:   x86_64\n",
            "I CFLAGS:    -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion \n",
            "I CXXFLAGS:  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE \n",
            "I NVCCFLAGS: -std=c++11 -O3 \n",
            "I LDFLAGS:    \n",
            "I CC:        cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "I CXX:       c++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "\n",
            "rm -vrf *.o tests/*.o *.so *.a *.dll benchmark-matmult lookup-create lookup-merge lookup-stats common/build-info.cpp *.dot *.gcno tests/*.gcno *.gcda tests/*.gcda *.gcov tests/*.gcov lcov-report gcovr-report main quantize quantize-stats perplexity imatrix embedding vdot q8dot train-text-from-scratch convert-llama2c-to-ggml simple batched batched-bench save-load-state server gguf gguf-split eval-callback llama-bench libllava.a llava-cli baby-llama beam-search retrieval speculative infill tokenize benchmark-matmult parallel finetune export-lora lookahead lookup passkey gritlm tests/test-c.o tests/test-llama-grammar tests/test-grammar-parser tests/test-double-float tests/test-grad0 tests/test-opt tests/test-quantize-fns tests/test-quantize-perf tests/test-sampling tests/test-tokenizer-0-llama tests/test-tokenizer-0-falcon tests/test-tokenizer-1-llama tests/test-tokenizer-1-bpe tests/test-rope tests/test-backend-ops tests/test-model-load-cancel tests/test-autorelease tests/test-json-schema-to-grammar tests/test-grammar-integration\n",
            "rm -vrf ggml-cuda/*.o\n",
            "find examples pocs -type f -name \"*.o\" -delete\n",
            "I ccache not found. Consider installing it for faster compilation.\n",
            "I llama.cpp build info: \n",
            "I UNAME_S:   Linux\n",
            "I UNAME_P:   x86_64\n",
            "I UNAME_M:   x86_64\n",
            "I CFLAGS:    -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion \n",
            "I CXXFLAGS:  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE \n",
            "I NVCCFLAGS: -std=c++11 -O3 \n",
            "I LDFLAGS:    \n",
            "I CC:        cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "I CXX:       c++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "\n",
            "cc  -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion    -c ggml.c -o ggml.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c llama.cpp -o llama.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c common/common.cpp -o common.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c common/sampling.cpp -o sampling.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c common/grammar-parser.cpp -o grammar-parser.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c common/build-info.cpp -o build-info.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c common/json-schema-to-grammar.cpp -o json-schema-to-grammar.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c common/console.cpp -o console.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c sgemm.cpp -o sgemm.o\n",
            "cc  -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion    -c ggml-alloc.c -o ggml-alloc.o\n",
            "cc  -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion    -c ggml-backend.c -o ggml-backend.o\n",
            "cc -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion     -c ggml-quants.c -o ggml-quants.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c unicode.cpp -o unicode.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c unicode-data.cpp -o unicode-data.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/main/main.cpp -o examples/main/main.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o console.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/main/main.o -o main  \n",
            "\n",
            "====  Run ./main -h for help.  ====\n",
            "\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/quantize/quantize.cpp -o examples/quantize/quantize.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/quantize/quantize.o -o quantize  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/quantize-stats/quantize-stats.cpp -o examples/quantize-stats/quantize-stats.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  build-info.o ggml.o llama.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/quantize-stats/quantize-stats.o -o quantize-stats  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/perplexity/perplexity.cpp -o examples/perplexity/perplexity.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/perplexity/perplexity.o -o perplexity  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/imatrix/imatrix.cpp -o examples/imatrix/imatrix.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/imatrix/imatrix.o -o imatrix  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/embedding/embedding.cpp -o examples/embedding/embedding.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/embedding/embedding.o -o embedding  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c pocs/vdot/vdot.cpp -o pocs/vdot/vdot.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o pocs/vdot/vdot.o -o vdot  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c pocs/vdot/q8dot.cpp -o pocs/vdot/q8dot.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o pocs/vdot/q8dot.o -o q8dot  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c common/train.cpp -o train.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/train-text-from-scratch/train-text-from-scratch.cpp -o examples/train-text-from-scratch/train-text-from-scratch.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o train.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/train-text-from-scratch/train-text-from-scratch.o -o train-text-from-scratch  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/convert-llama2c-to-ggml/convert-llama2c-to-ggml.cpp -o examples/convert-llama2c-to-ggml/convert-llama2c-to-ggml.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/convert-llama2c-to-ggml/convert-llama2c-to-ggml.o -o convert-llama2c-to-ggml  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/simple/simple.cpp -o examples/simple/simple.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/simple/simple.o -o simple  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/batched/batched.cpp -o examples/batched/batched.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/batched/batched.o -o batched  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/batched-bench/batched-bench.cpp -o examples/batched-bench/batched-bench.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  build-info.o ggml.o llama.o common.o sampling.o grammar-parser.o json-schema-to-grammar.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/batched-bench/batched-bench.o -o batched-bench  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/save-load-state/save-load-state.cpp -o examples/save-load-state/save-load-state.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/save-load-state/save-load-state.o -o save-load-state  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/server/server.cpp -o examples/server/server.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o -Iexamples/server examples/server/server.o -o server   \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/gguf/gguf.cpp -o examples/gguf/gguf.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/gguf/gguf.o -o gguf  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/gguf-split/gguf-split.cpp -o examples/gguf-split/gguf-split.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/gguf-split/gguf-split.o -o gguf-split  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/eval-callback/eval-callback.cpp -o examples/eval-callback/eval-callback.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/eval-callback/eval-callback.o -o eval-callback  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/llama-bench/llama-bench.cpp -o examples/llama-bench/llama-bench.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/llama-bench/llama-bench.o -o llama-bench  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -static -fPIC -c examples/llava/llava.cpp -o libllava.a -Wno-cast-qual\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/llava/llava-cli.cpp -o examples/llava/llava-cli.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/llava/clip.cpp  -o examples/llava/clip.o -Wno-cast-qual\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/llava/llava.cpp -o examples/llava/llava.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/llava/llava-cli.o examples/llava/clip.o examples/llava/llava.o -o llava-cli  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/baby-llama/baby-llama.cpp -o examples/baby-llama/baby-llama.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o train.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/baby-llama/baby-llama.o -o baby-llama  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/beam-search/beam-search.cpp -o examples/beam-search/beam-search.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/beam-search/beam-search.o -o beam-search  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/retrieval/retrieval.cpp -o examples/retrieval/retrieval.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/retrieval/retrieval.o -o retrieval  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/speculative/speculative.cpp -o examples/speculative/speculative.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/speculative/speculative.o -o speculative  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/infill/infill.cpp -o examples/infill/infill.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o console.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/infill/infill.o -o infill  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/tokenize/tokenize.cpp -o examples/tokenize/tokenize.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/tokenize/tokenize.o -o tokenize  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/benchmark/benchmark-matmult.cpp -o examples/benchmark/benchmark-matmult.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  build-info.o ggml.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/benchmark/benchmark-matmult.o -o benchmark-matmult  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/parallel/parallel.cpp -o examples/parallel/parallel.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/parallel/parallel.o -o parallel  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/finetune/finetune.cpp -o examples/finetune/finetune.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o train.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/finetune/finetune.o -o finetune  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/export-lora/export-lora.cpp -o examples/export-lora/export-lora.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/export-lora/export-lora.o -o export-lora  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/lookahead/lookahead.cpp -o examples/lookahead/lookahead.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/lookahead/lookahead.o -o lookahead  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c common/ngram-cache.cpp -o ngram-cache.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/lookup/lookup.cpp -o examples/lookup/lookup.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o ngram-cache.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/lookup/lookup.o -o lookup  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/lookup/lookup-create.cpp -o examples/lookup/lookup-create.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o ngram-cache.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/lookup/lookup-create.o -o lookup-create  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/lookup/lookup-merge.cpp -o examples/lookup/lookup-merge.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o ngram-cache.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/lookup/lookup-merge.o -o lookup-merge  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/lookup/lookup-stats.cpp -o examples/lookup/lookup-stats.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o ngram-cache.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/lookup/lookup-stats.o -o lookup-stats  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/passkey/passkey.cpp -o examples/passkey/passkey.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/passkey/passkey.o -o passkey  \n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -c examples/gritlm/gritlm.cpp -o examples/gritlm/gritlm.o\n",
            "c++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o json-schema-to-grammar.o sgemm.o ggml-alloc.o ggml-backend.o ggml-quants.o unicode.o unicode-data.o examples/gritlm/gritlm.o -o gritlm  \n",
            "cc -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_LLAMAFILE  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion  -c tests/test-c.c -o tests/test-c.o\n",
            "Collecting numpy~=1.24.4 (from -r llama.cpp/./requirements/requirements-convert.txt (line 1))\n",
            "  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting sentencepiece~=0.1.98 (from -r llama.cpp/./requirements/requirements-convert.txt (line 2))\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.35.2 in /usr/local/lib/python3.10/dist-packages (from -r llama.cpp/./requirements/requirements-convert.txt (line 3)) (4.44.2)\n",
            "Requirement already satisfied: gguf>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from -r llama.cpp/./requirements/requirements-convert.txt (line 4)) (0.9.0)\n",
            "Collecting protobuf<5.0.0,>=4.21.0 (from -r llama.cpp/./requirements/requirements-convert.txt (line 5))\n",
            "  Downloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting torch~=2.1.1 (from -r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting einops~=0.7.0 (from -r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 3))\n",
            "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (0.24.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.1.0 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (1.3.0)\n",
            "Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece, triton, protobuf, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, einops, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.2.0\n",
            "    Uninstalling sentencepiece-0.2.0:\n",
            "      Successfully uninstalled sentencepiece-0.2.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: einops\n",
            "    Found existing installation: einops 0.8.0\n",
            "    Uninstalling einops-0.8.0:\n",
            "      Successfully uninstalled einops-0.8.0\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.5.0.50\n",
            "    Uninstalling nvidia-cudnn-cu12-9.5.0.50:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.5.0.50\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.0+cu121\n",
            "    Uninstalling torch-2.5.0+cu121:\n",
            "      Successfully uninstalled torch-2.5.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.5 which is incompatible.\n",
            "torchaudio 2.5.0+cu121 requires torch==2.5.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchvision 0.20.0+cu121 requires torch==2.5.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed einops-0.7.0 numpy-1.24.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvtx-cu12-12.1.105 protobuf-4.25.5 sentencepiece-0.1.99 torch-2.1.2 triton-2.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "sentencepiece",
                  "torch",
                  "torchgen"
                ]
              },
              "id": "18bef078b40841c48b480c2f823516fb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!cd llama.cpp && make clean && make\n",
        "!pip install -r llama.cpp/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GptmwIbL-_E1"
      },
      "source": [
        "### Quantize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8v_aXi95xcS",
        "outputId": "0147b987-e7b8-4cfb-d7cf-d46692d7e57d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "main: build = 2760 (3f16747)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing './model/ggml-model-f16.gguf' to './model/ggml-model-q4_0.gguf' as Q4_0\n",
            "llama_model_loader: loaded meta data with 19 key-value pairs and 453 tensors from ./model/ggml-model-f16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = phi2\n",
            "llama_model_loader: - kv   1:                               general.name str              = Phi2\n",
            "llama_model_loader: - kv   2:                        phi2.context_length u32              = 2048\n",
            "llama_model_loader: - kv   3:                      phi2.embedding_length u32              = 2560\n",
            "llama_model_loader: - kv   4:                   phi2.feed_forward_length u32              = 10240\n",
            "llama_model_loader: - kv   5:                           phi2.block_count u32              = 32\n",
            "llama_model_loader: - kv   6:                  phi2.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   7:               phi2.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   8:          phi2.attention.layer_norm_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv   9:                  phi2.rope.dimension_count u32              = 32\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  11:               tokenizer.ggml.add_bos_token bool             = false\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,51200]   = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,51200]   = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.merges arr[str,50000]   = [\"Ġ t\", \"Ġ a\", \"h e\", \"i n\", \"r e\",...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 50256\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 50256\n",
            "llama_model_loader: - kv  18:               tokenizer.ggml.add_bos_token bool             = false\n",
            "llama_model_loader: - type  f32:  259 tensors\n",
            "llama_model_loader: - type  f16:  194 tensors\n",
            "[   1/ 453]                    token_embd.weight - [ 2560, 51200,     1,     1], type =    f16, converting to q4_0 .. size =   250.00 MiB ->    70.31 MiB\n",
            "[   2/ 453]                 blk.0.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[   3/ 453]               blk.0.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[   4/ 453]                    blk.0.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[   5/ 453]                  blk.0.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[   6/ 453]                  blk.0.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[   7/ 453]                blk.0.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[   8/ 453]               blk.0.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[   9/ 453]             blk.0.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  10/ 453]                    blk.0.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  11/ 453]                  blk.0.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  12/ 453]                    blk.0.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  13/ 453]                  blk.0.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  14/ 453]                    blk.0.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  15/ 453]                  blk.0.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  16/ 453]                 blk.1.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  17/ 453]               blk.1.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  18/ 453]                    blk.1.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[  19/ 453]                  blk.1.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  20/ 453]                  blk.1.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  21/ 453]                blk.1.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  22/ 453]               blk.1.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  23/ 453]             blk.1.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  24/ 453]                    blk.1.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  25/ 453]                  blk.1.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  26/ 453]                    blk.1.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  27/ 453]                  blk.1.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  28/ 453]                    blk.1.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  29/ 453]                  blk.1.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  30/ 453]                blk.10.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  31/ 453]              blk.10.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  32/ 453]                   blk.10.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[  33/ 453]                 blk.10.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  34/ 453]                 blk.10.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  35/ 453]               blk.10.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  36/ 453]              blk.10.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  37/ 453]            blk.10.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  38/ 453]                   blk.10.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  39/ 453]                 blk.10.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  40/ 453]                   blk.10.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  41/ 453]                 blk.10.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  42/ 453]                   blk.10.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  43/ 453]                 blk.10.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  44/ 453]                blk.11.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  45/ 453]              blk.11.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  46/ 453]                   blk.11.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[  47/ 453]                 blk.11.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  48/ 453]                 blk.11.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  49/ 453]               blk.11.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  50/ 453]              blk.11.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  51/ 453]            blk.11.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  52/ 453]                   blk.11.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  53/ 453]                 blk.11.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  54/ 453]                   blk.11.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  55/ 453]                 blk.11.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  56/ 453]                   blk.11.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  57/ 453]                 blk.11.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  58/ 453]                blk.12.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  59/ 453]              blk.12.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  60/ 453]                   blk.12.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[  61/ 453]                 blk.12.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  62/ 453]                 blk.12.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  63/ 453]               blk.12.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  64/ 453]              blk.12.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  65/ 453]            blk.12.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  66/ 453]                   blk.12.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  67/ 453]                 blk.12.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  68/ 453]                   blk.12.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  69/ 453]                 blk.12.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  70/ 453]                   blk.12.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  71/ 453]                 blk.12.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  72/ 453]                blk.13.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  73/ 453]              blk.13.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  74/ 453]                   blk.13.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[  75/ 453]                 blk.13.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  76/ 453]                 blk.13.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  77/ 453]               blk.13.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  78/ 453]              blk.13.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  79/ 453]            blk.13.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  80/ 453]                   blk.13.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  81/ 453]                 blk.13.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  82/ 453]                   blk.13.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  83/ 453]                 blk.13.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  84/ 453]                   blk.13.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  85/ 453]                 blk.13.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  86/ 453]                   blk.14.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  87/ 453]                 blk.14.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  88/ 453]                   blk.14.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  89/ 453]                 blk.14.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  90/ 453]                 blk.2.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  91/ 453]               blk.2.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  92/ 453]                    blk.2.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[  93/ 453]                  blk.2.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  94/ 453]                  blk.2.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  95/ 453]                blk.2.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  96/ 453]               blk.2.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  97/ 453]             blk.2.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[  98/ 453]                    blk.2.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  99/ 453]                  blk.2.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 100/ 453]                    blk.2.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 101/ 453]                  blk.2.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 102/ 453]                    blk.2.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 103/ 453]                  blk.2.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 104/ 453]                 blk.3.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 105/ 453]               blk.3.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 106/ 453]                    blk.3.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 107/ 453]                  blk.3.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 108/ 453]                  blk.3.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 109/ 453]                blk.3.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 110/ 453]               blk.3.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 111/ 453]             blk.3.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 112/ 453]                    blk.3.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 113/ 453]                  blk.3.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 114/ 453]                    blk.3.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 115/ 453]                  blk.3.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 116/ 453]                    blk.3.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 117/ 453]                  blk.3.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 118/ 453]                 blk.4.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 119/ 453]               blk.4.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 120/ 453]                    blk.4.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 121/ 453]                  blk.4.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 122/ 453]                  blk.4.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 123/ 453]                blk.4.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 124/ 453]               blk.4.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 125/ 453]             blk.4.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 126/ 453]                    blk.4.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 127/ 453]                  blk.4.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 128/ 453]                    blk.4.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 129/ 453]                  blk.4.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 130/ 453]                    blk.4.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 131/ 453]                  blk.4.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 132/ 453]                 blk.5.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 133/ 453]               blk.5.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 134/ 453]                    blk.5.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 135/ 453]                  blk.5.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 136/ 453]                  blk.5.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 137/ 453]                blk.5.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 138/ 453]               blk.5.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 139/ 453]             blk.5.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 140/ 453]                    blk.5.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 141/ 453]                  blk.5.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 142/ 453]                    blk.5.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 143/ 453]                  blk.5.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 144/ 453]                    blk.5.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 145/ 453]                  blk.5.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 146/ 453]                 blk.6.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 147/ 453]               blk.6.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 148/ 453]                    blk.6.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 149/ 453]                  blk.6.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 150/ 453]                  blk.6.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 151/ 453]                blk.6.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 152/ 453]               blk.6.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 153/ 453]             blk.6.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 154/ 453]                    blk.6.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 155/ 453]                  blk.6.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 156/ 453]                    blk.6.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 157/ 453]                  blk.6.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 158/ 453]                    blk.6.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 159/ 453]                  blk.6.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 160/ 453]                 blk.7.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 161/ 453]               blk.7.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 162/ 453]                    blk.7.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 163/ 453]                  blk.7.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 164/ 453]                  blk.7.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 165/ 453]                blk.7.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 166/ 453]               blk.7.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 167/ 453]             blk.7.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 168/ 453]                    blk.7.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 169/ 453]                  blk.7.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 170/ 453]                    blk.7.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 171/ 453]                  blk.7.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 172/ 453]                    blk.7.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 173/ 453]                  blk.7.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 174/ 453]                 blk.8.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 175/ 453]               blk.8.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 176/ 453]                    blk.8.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 177/ 453]                  blk.8.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 178/ 453]                  blk.8.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 179/ 453]                blk.8.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 180/ 453]               blk.8.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 181/ 453]             blk.8.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 182/ 453]                    blk.8.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 183/ 453]                  blk.8.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 184/ 453]                    blk.8.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 185/ 453]                  blk.8.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 186/ 453]                    blk.8.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 187/ 453]                  blk.8.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 188/ 453]                 blk.9.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 189/ 453]               blk.9.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 190/ 453]                    blk.9.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 191/ 453]                  blk.9.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 192/ 453]                  blk.9.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 193/ 453]                blk.9.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 194/ 453]               blk.9.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 195/ 453]             blk.9.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 196/ 453]                    blk.9.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 197/ 453]                  blk.9.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 198/ 453]                    blk.9.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 199/ 453]                  blk.9.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 200/ 453]                    blk.9.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 201/ 453]                  blk.9.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 202/ 453]                blk.14.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 203/ 453]              blk.14.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 204/ 453]                   blk.14.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 205/ 453]                 blk.14.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 206/ 453]                 blk.14.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 207/ 453]               blk.14.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 208/ 453]              blk.14.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 209/ 453]            blk.14.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 210/ 453]                   blk.14.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 211/ 453]                 blk.14.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 212/ 453]                blk.15.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 213/ 453]              blk.15.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 214/ 453]                   blk.15.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 215/ 453]                 blk.15.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 216/ 453]                 blk.15.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 217/ 453]               blk.15.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 218/ 453]              blk.15.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 219/ 453]            blk.15.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 220/ 453]                   blk.15.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 221/ 453]                 blk.15.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 222/ 453]                   blk.15.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 223/ 453]                 blk.15.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 224/ 453]                   blk.15.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 225/ 453]                 blk.15.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 226/ 453]                blk.16.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 227/ 453]              blk.16.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 228/ 453]                   blk.16.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 229/ 453]                 blk.16.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 230/ 453]                 blk.16.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 231/ 453]               blk.16.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 232/ 453]              blk.16.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 233/ 453]            blk.16.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 234/ 453]                   blk.16.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 235/ 453]                 blk.16.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 236/ 453]                   blk.16.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 237/ 453]                 blk.16.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 238/ 453]                   blk.16.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 239/ 453]                 blk.16.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 240/ 453]                blk.17.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 241/ 453]              blk.17.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 242/ 453]                   blk.17.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 243/ 453]                 blk.17.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 244/ 453]                 blk.17.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 245/ 453]               blk.17.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 246/ 453]              blk.17.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 247/ 453]            blk.17.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 248/ 453]                   blk.17.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 249/ 453]                 blk.17.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 250/ 453]                   blk.17.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 251/ 453]                 blk.17.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 252/ 453]                   blk.17.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 253/ 453]                 blk.17.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 254/ 453]                blk.18.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 255/ 453]              blk.18.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 256/ 453]                   blk.18.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 257/ 453]                 blk.18.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 258/ 453]                 blk.18.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 259/ 453]               blk.18.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 260/ 453]              blk.18.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 261/ 453]            blk.18.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 262/ 453]                   blk.18.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 263/ 453]                 blk.18.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 264/ 453]                   blk.18.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 265/ 453]                 blk.18.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 266/ 453]                   blk.18.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 267/ 453]                 blk.18.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 268/ 453]                blk.19.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 269/ 453]              blk.19.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 270/ 453]                   blk.19.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 271/ 453]                 blk.19.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 272/ 453]                 blk.19.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 273/ 453]               blk.19.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 274/ 453]              blk.19.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 275/ 453]            blk.19.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 276/ 453]                   blk.19.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 277/ 453]                 blk.19.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 278/ 453]                   blk.19.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 279/ 453]                 blk.19.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 280/ 453]                   blk.19.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 281/ 453]                 blk.19.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 282/ 453]                blk.20.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 283/ 453]              blk.20.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 284/ 453]                   blk.20.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 285/ 453]                 blk.20.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 286/ 453]                 blk.20.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 287/ 453]               blk.20.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 288/ 453]              blk.20.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 289/ 453]            blk.20.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 290/ 453]                   blk.20.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 291/ 453]                 blk.20.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 292/ 453]                   blk.20.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 293/ 453]                 blk.20.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 294/ 453]                   blk.20.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 295/ 453]                 blk.20.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 296/ 453]                blk.21.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 297/ 453]              blk.21.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 298/ 453]                   blk.21.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 299/ 453]                 blk.21.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 300/ 453]                 blk.21.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 301/ 453]               blk.21.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 302/ 453]              blk.21.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 303/ 453]            blk.21.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 304/ 453]                   blk.21.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 305/ 453]                 blk.21.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 306/ 453]                   blk.21.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 307/ 453]                 blk.21.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 308/ 453]                   blk.21.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 309/ 453]                 blk.21.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 310/ 453]                blk.22.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 311/ 453]              blk.22.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 312/ 453]                   blk.22.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 313/ 453]                 blk.22.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 314/ 453]                 blk.22.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 315/ 453]               blk.22.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 316/ 453]              blk.22.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 317/ 453]            blk.22.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 318/ 453]                   blk.22.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 319/ 453]                 blk.22.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 320/ 453]                   blk.22.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 321/ 453]                 blk.22.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 322/ 453]                   blk.22.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 323/ 453]                 blk.22.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 324/ 453]                blk.23.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 325/ 453]              blk.23.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 326/ 453]                   blk.23.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 327/ 453]                 blk.23.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 328/ 453]                 blk.23.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 329/ 453]               blk.23.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 330/ 453]              blk.23.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 331/ 453]            blk.23.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 332/ 453]                   blk.23.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 333/ 453]                 blk.23.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 334/ 453]                   blk.23.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 335/ 453]                 blk.23.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 336/ 453]                   blk.23.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 337/ 453]                 blk.23.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 338/ 453]                blk.24.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 339/ 453]              blk.24.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 340/ 453]                   blk.24.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 341/ 453]                 blk.24.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 342/ 453]                 blk.24.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 343/ 453]               blk.24.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 344/ 453]              blk.24.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 345/ 453]            blk.24.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 346/ 453]                   blk.24.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 347/ 453]                 blk.24.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 348/ 453]                   blk.24.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 349/ 453]                 blk.24.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 350/ 453]                   blk.24.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 351/ 453]                 blk.24.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 352/ 453]                blk.25.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 353/ 453]              blk.25.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 354/ 453]                   blk.25.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 355/ 453]                 blk.25.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 356/ 453]                 blk.25.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 357/ 453]               blk.25.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 358/ 453]              blk.25.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 359/ 453]            blk.25.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 360/ 453]                   blk.25.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 361/ 453]                 blk.25.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 362/ 453]                   blk.25.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 363/ 453]                 blk.25.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 364/ 453]                   blk.25.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 365/ 453]                 blk.25.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 366/ 453]                blk.26.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 367/ 453]              blk.26.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 368/ 453]                   blk.26.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 369/ 453]                 blk.26.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 370/ 453]                 blk.26.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 371/ 453]               blk.26.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 372/ 453]              blk.26.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 373/ 453]            blk.26.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 374/ 453]                   blk.26.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 375/ 453]                 blk.26.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 376/ 453]                   blk.26.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 377/ 453]                 blk.26.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 378/ 453]                   blk.26.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 379/ 453]                 blk.26.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 380/ 453]                blk.27.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 381/ 453]              blk.27.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 382/ 453]                   blk.27.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 383/ 453]                 blk.27.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 384/ 453]                 blk.27.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 385/ 453]               blk.27.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 386/ 453]              blk.27.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 387/ 453]            blk.27.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 388/ 453]                   blk.27.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 389/ 453]                 blk.27.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 390/ 453]                   blk.27.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 391/ 453]                 blk.27.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 392/ 453]                   blk.27.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 393/ 453]                 blk.27.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 394/ 453]                blk.28.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 395/ 453]              blk.28.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 396/ 453]                   blk.28.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 397/ 453]                 blk.28.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 398/ 453]                 blk.28.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 399/ 453]               blk.28.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 400/ 453]              blk.28.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 401/ 453]            blk.28.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 402/ 453]                   blk.28.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 403/ 453]                 blk.28.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 404/ 453]                   blk.28.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 405/ 453]                 blk.28.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 406/ 453]                   blk.28.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 407/ 453]                 blk.28.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 408/ 453]                blk.29.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 409/ 453]              blk.29.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 410/ 453]                   blk.29.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 411/ 453]                 blk.29.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 412/ 453]                 blk.29.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 413/ 453]               blk.29.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 414/ 453]              blk.29.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 415/ 453]            blk.29.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 416/ 453]                   blk.29.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 417/ 453]                 blk.29.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 418/ 453]                   blk.29.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 419/ 453]                 blk.29.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 420/ 453]                   blk.29.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 421/ 453]                 blk.29.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 422/ 453]                          output.bias - [51200,     1,     1,     1], type =    f32, size =    0.195 MB\n",
            "[ 423/ 453]                        output.weight - [ 2560, 51200,     1,     1], type =    f16, converting to q6_K .. size =   250.00 MiB ->   102.54 MiB\n",
            "[ 424/ 453]                     output_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 425/ 453]                   output_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 426/ 453]                blk.30.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 427/ 453]              blk.30.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 428/ 453]                   blk.30.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 429/ 453]                 blk.30.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 430/ 453]                 blk.30.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 431/ 453]               blk.30.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 432/ 453]              blk.30.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 433/ 453]            blk.30.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 434/ 453]                   blk.30.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 435/ 453]                 blk.30.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 436/ 453]                   blk.30.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 437/ 453]                 blk.30.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 438/ 453]                   blk.30.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 439/ 453]                 blk.30.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 440/ 453]                blk.31.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 441/ 453]              blk.31.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 442/ 453]                   blk.31.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 443/ 453]                 blk.31.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 444/ 453]                 blk.31.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 445/ 453]               blk.31.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 446/ 453]              blk.31.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 447/ 453]            blk.31.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 448/ 453]                   blk.31.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 449/ 453]                 blk.31.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 450/ 453]                   blk.31.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 451/ 453]                 blk.31.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "[ 452/ 453]                   blk.31.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 453/ 453]                 blk.31.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, converting to q4_0 .. size =    12.50 MiB ->     3.52 MiB\n",
            "llama_model_quantize_internal: model size  =  5303.65 MB\n",
            "llama_model_quantize_internal: quant size  =  1526.50 MB\n",
            "\n",
            "main: quantize time = 39363.40 ms\n",
            "main:    total time = 39363.40 ms\n"
          ]
        }
      ],
      "source": [
        "!./llama.cpp/quantize ./model/ggml-model-f16.gguf ./model/ggml-model-q4_0.gguf q4_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X33pI5-NV0zm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a1e4c29ae2b474dbf8237f85cb35b73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3bed4fed6948457981f14ca01d121f6c",
              "IPY_MODEL_df0f5fd8debb40bca962b7c49c83f472",
              "IPY_MODEL_acb0cf6e36e14e4ab144492f03473693"
            ],
            "layout": "IPY_MODEL_e61d40cbbda84523aa72c2e0b4de9f3e"
          }
        },
        "3bed4fed6948457981f14ca01d121f6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7a10efd91bf4d8ebcef20404fc467d4",
            "placeholder": "​",
            "style": "IPY_MODEL_d2255e978c5842f0a03ded6f92bf287f",
            "value": "config.json: 100%"
          }
        },
        "df0f5fd8debb40bca962b7c49c83f472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5beb8fea92a842298b01264792988ef4",
            "max": 735,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b844d6ceb5924b0392387e71abc0f12d",
            "value": 735
          }
        },
        "acb0cf6e36e14e4ab144492f03473693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10aadd7fa2874c4d9de184360233adc3",
            "placeholder": "​",
            "style": "IPY_MODEL_191f3840c33848808af95e69e106b512",
            "value": " 735/735 [00:00&lt;00:00, 56.7kB/s]"
          }
        },
        "e61d40cbbda84523aa72c2e0b4de9f3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7a10efd91bf4d8ebcef20404fc467d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2255e978c5842f0a03ded6f92bf287f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5beb8fea92a842298b01264792988ef4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b844d6ceb5924b0392387e71abc0f12d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10aadd7fa2874c4d9de184360233adc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "191f3840c33848808af95e69e106b512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afc86549f7004bacb85491b60fc9b06b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82610ae59ccf4ba4aaf1d16f779ce6cd",
              "IPY_MODEL_93370cabcd124d7a9d8069f4306b6faf",
              "IPY_MODEL_9849017be0e142278fdc826afaa8f9c7"
            ],
            "layout": "IPY_MODEL_3cf2b3bbba3d424ca4eaf6cbe8317917"
          }
        },
        "82610ae59ccf4ba4aaf1d16f779ce6cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b18e83387aa4711afeedb552b45a80d",
            "placeholder": "​",
            "style": "IPY_MODEL_12a7c7b4c46747e69954119e97ef65bc",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "93370cabcd124d7a9d8069f4306b6faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32df4440f82c43f7816315ada79b1348",
            "max": 35716,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66f299d22e464d90abd8905b74253a50",
            "value": 35716
          }
        },
        "9849017be0e142278fdc826afaa8f9c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31752869b2ff43038091fba2e4a2f189",
            "placeholder": "​",
            "style": "IPY_MODEL_b368558fbd81468aaf546266f708f6bd",
            "value": " 35.7k/35.7k [00:00&lt;00:00, 2.73MB/s]"
          }
        },
        "3cf2b3bbba3d424ca4eaf6cbe8317917": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b18e83387aa4711afeedb552b45a80d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12a7c7b4c46747e69954119e97ef65bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32df4440f82c43f7816315ada79b1348": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66f299d22e464d90abd8905b74253a50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31752869b2ff43038091fba2e4a2f189": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b368558fbd81468aaf546266f708f6bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af1f0e0c8c124d489fa0dcf6c8dae60a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8f06bc7937442eb8dfd214837efaad6",
              "IPY_MODEL_e017c10c0f004bc694c5376545be87e4",
              "IPY_MODEL_5f1e1a3f58fd4612b2f5032f986d8e3d"
            ],
            "layout": "IPY_MODEL_ec9bcfa0ff064670bb1cb87c21377aa1"
          }
        },
        "f8f06bc7937442eb8dfd214837efaad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3d9c03902584c85bb0105049f30934a",
            "placeholder": "​",
            "style": "IPY_MODEL_7e0f3c6c3c5e41ab8cade3cbc5423ce0",
            "value": "Downloading shards: 100%"
          }
        },
        "e017c10c0f004bc694c5376545be87e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b1a40c938ff47ed933599cfc4b2a7d4",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d81b992d329f45c8b6851415c95e7ac4",
            "value": 2
          }
        },
        "5f1e1a3f58fd4612b2f5032f986d8e3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19480d32a5f441f4971598cee11f1493",
            "placeholder": "​",
            "style": "IPY_MODEL_d9b832bc7710409aa574809aa2801bce",
            "value": " 2/2 [02:13&lt;00:00, 57.34s/it]"
          }
        },
        "ec9bcfa0ff064670bb1cb87c21377aa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3d9c03902584c85bb0105049f30934a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e0f3c6c3c5e41ab8cade3cbc5423ce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b1a40c938ff47ed933599cfc4b2a7d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d81b992d329f45c8b6851415c95e7ac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19480d32a5f441f4971598cee11f1493": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9b832bc7710409aa574809aa2801bce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e738977567041609e08c44a63ed4963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8209772cfb64967aa112915f47c7af4",
              "IPY_MODEL_c1c30aed034a419dae442250a153cda1",
              "IPY_MODEL_5e7ee4baf3b14b53816505f131882f5f"
            ],
            "layout": "IPY_MODEL_dc893d16445f40f8821bf55a1d640949"
          }
        },
        "d8209772cfb64967aa112915f47c7af4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69509b0d07de4ab68ee4f34c3b41dd21",
            "placeholder": "​",
            "style": "IPY_MODEL_80d84fd5ff414a6e92818f9a9e3442ae",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "c1c30aed034a419dae442250a153cda1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c178bd343cb41a7924164c9fed14caf",
            "max": 4995584424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6391ac8408b94380970dbde06bfbcdf2",
            "value": 4995584424
          }
        },
        "5e7ee4baf3b14b53816505f131882f5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af0cd4157eb24827a915fec3d8b32f46",
            "placeholder": "​",
            "style": "IPY_MODEL_6194c1dd183543b082badfade6c502d4",
            "value": " 5.00G/5.00G [01:58&lt;00:00, 38.0MB/s]"
          }
        },
        "dc893d16445f40f8821bf55a1d640949": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69509b0d07de4ab68ee4f34c3b41dd21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80d84fd5ff414a6e92818f9a9e3442ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c178bd343cb41a7924164c9fed14caf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6391ac8408b94380970dbde06bfbcdf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af0cd4157eb24827a915fec3d8b32f46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6194c1dd183543b082badfade6c502d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d78e61d1b2a6479e850d190acd8aabdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31f33edfc866406eb19911780b3e8773",
              "IPY_MODEL_97636dc8b3284c0ca5d68b5e823cf160",
              "IPY_MODEL_5556fd9e8c18481492d209853ef4feac"
            ],
            "layout": "IPY_MODEL_b631082e89c748929bc12a86ec155ff9"
          }
        },
        "31f33edfc866406eb19911780b3e8773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c044cd86c6b41aba3e46e01aa761b20",
            "placeholder": "​",
            "style": "IPY_MODEL_777c6d80beac41dfab953242d3eb6a29",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "97636dc8b3284c0ca5d68b5e823cf160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4132181f94dd4339a5393b19339ebe7c",
            "max": 563832976,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e9e3d35ca8249638f4ff30e89e52b43",
            "value": 563832976
          }
        },
        "5556fd9e8c18481492d209853ef4feac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbb8e7d5ac9b4406b7a9114c28ac3a43",
            "placeholder": "​",
            "style": "IPY_MODEL_7a2b70b322d04b57bfe0cc0c0b6303fd",
            "value": " 564M/564M [00:13&lt;00:00, 42.0MB/s]"
          }
        },
        "b631082e89c748929bc12a86ec155ff9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c044cd86c6b41aba3e46e01aa761b20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "777c6d80beac41dfab953242d3eb6a29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4132181f94dd4339a5393b19339ebe7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e9e3d35ca8249638f4ff30e89e52b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cbb8e7d5ac9b4406b7a9114c28ac3a43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a2b70b322d04b57bfe0cc0c0b6303fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b01f74a93a9840fe87a7084a27fc75c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25b92984b3a949b482f0f6dbcbac013d",
              "IPY_MODEL_1f5eb142283949a8b5a5cb4c010ed0c2",
              "IPY_MODEL_e079e7012ab5480eb613ba4f99f180d0"
            ],
            "layout": "IPY_MODEL_1b63dc9d621d4251a1e1f4639aa48c18"
          }
        },
        "25b92984b3a949b482f0f6dbcbac013d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_628ea22f4c0c4ed59de61dc16108a10a",
            "placeholder": "​",
            "style": "IPY_MODEL_d5ecbfc49efb4d37bcd02b83caed1db8",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "1f5eb142283949a8b5a5cb4c010ed0c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e3750b35bec42e2a7fad992014cc1a8",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73a3b70f4b804855ab36917ba7c24bd6",
            "value": 2
          }
        },
        "e079e7012ab5480eb613ba4f99f180d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fb6f28a422c403d854fc6d750aed038",
            "placeholder": "​",
            "style": "IPY_MODEL_56a4a76a1ffa43e69dc52f54351c4ee0",
            "value": " 2/2 [00:05&lt;00:00,  2.18s/it]"
          }
        },
        "1b63dc9d621d4251a1e1f4639aa48c18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "628ea22f4c0c4ed59de61dc16108a10a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5ecbfc49efb4d37bcd02b83caed1db8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e3750b35bec42e2a7fad992014cc1a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73a3b70f4b804855ab36917ba7c24bd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8fb6f28a422c403d854fc6d750aed038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56a4a76a1ffa43e69dc52f54351c4ee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f35c62c9c9e6414586fc6dd0358d8a50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7c71cece89849948fc8f18d14a7eb73",
              "IPY_MODEL_35edbf04c34a480eb665394e6b6ed764",
              "IPY_MODEL_54aeba9431304df28a530ef2270ce47b"
            ],
            "layout": "IPY_MODEL_5ed5f158fb7f4a0383369f87773e934d"
          }
        },
        "b7c71cece89849948fc8f18d14a7eb73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_596c3239393d4a48955875270ceaeb9c",
            "placeholder": "​",
            "style": "IPY_MODEL_918c7aeb1c4e4f9abd875442b4142156",
            "value": "generation_config.json: 100%"
          }
        },
        "35edbf04c34a480eb665394e6b6ed764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_362f78f1c05b4a39907411d3a460dfef",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f42a154b44aa4812bf7eb06ddf5dd6c3",
            "value": 124
          }
        },
        "54aeba9431304df28a530ef2270ce47b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_771fb316380147f2be1ea2d4f12eb45a",
            "placeholder": "​",
            "style": "IPY_MODEL_83c0724170764457b39357b6ee29d6d8",
            "value": " 124/124 [00:00&lt;00:00, 11.2kB/s]"
          }
        },
        "5ed5f158fb7f4a0383369f87773e934d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "596c3239393d4a48955875270ceaeb9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "918c7aeb1c4e4f9abd875442b4142156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "362f78f1c05b4a39907411d3a460dfef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f42a154b44aa4812bf7eb06ddf5dd6c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "771fb316380147f2be1ea2d4f12eb45a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83c0724170764457b39357b6ee29d6d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11d6bd32e2114393a67224ae5fdd7db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_650041ffdd0e43b481958906e5011bb6",
              "IPY_MODEL_90076a5bf95c436cbe1a774f1a832ec4",
              "IPY_MODEL_55e0515b8d0c40a19020b6096e5f6094"
            ],
            "layout": "IPY_MODEL_2b250fd4e37046bead660688f839be6e"
          }
        },
        "650041ffdd0e43b481958906e5011bb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5269d8e9d8b8474ca97f94ae46bcf277",
            "placeholder": "​",
            "style": "IPY_MODEL_fb7606a1f7704b5a82d73d5225a392d8",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "90076a5bf95c436cbe1a774f1a832ec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b66ffe170f85414299c49103323bf99a",
            "max": 7339,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8682b7ed3a8f4a6d840df4ed76e2a390",
            "value": 7339
          }
        },
        "55e0515b8d0c40a19020b6096e5f6094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b77596bed4f4bc38dc80b03f629ec4a",
            "placeholder": "​",
            "style": "IPY_MODEL_d20c493117c44d8a807c279e0e466804",
            "value": " 7.34k/7.34k [00:00&lt;00:00, 585kB/s]"
          }
        },
        "2b250fd4e37046bead660688f839be6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5269d8e9d8b8474ca97f94ae46bcf277": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb7606a1f7704b5a82d73d5225a392d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b66ffe170f85414299c49103323bf99a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8682b7ed3a8f4a6d840df4ed76e2a390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b77596bed4f4bc38dc80b03f629ec4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d20c493117c44d8a807c279e0e466804": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53f3e7b0b8f8413eb1976dd1ac57e345": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68c6a2e7b9ca45928a6d139d8d848636",
              "IPY_MODEL_c44d2bffe6ca4d37822ca88e35030883",
              "IPY_MODEL_48c0e2f2d5834eb6afdd42c0f5664a97"
            ],
            "layout": "IPY_MODEL_351df7e8344f4ecf9e79bb361bfb394c"
          }
        },
        "68c6a2e7b9ca45928a6d139d8d848636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65923751e78a4837bd8e6f89bfc81ff5",
            "placeholder": "​",
            "style": "IPY_MODEL_861cce46bc8d484284c471451106ff5a",
            "value": "vocab.json: 100%"
          }
        },
        "c44d2bffe6ca4d37822ca88e35030883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b31afd992f5441fbf609906f5d2d28a",
            "max": 798156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff377c7455244da3be56a968882eb898",
            "value": 798156
          }
        },
        "48c0e2f2d5834eb6afdd42c0f5664a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb72b776ba7b4d668315bcd9e5168144",
            "placeholder": "​",
            "style": "IPY_MODEL_5150fad18fee40e1a70841971bcc6b5c",
            "value": " 798k/798k [00:00&lt;00:00, 948kB/s]"
          }
        },
        "351df7e8344f4ecf9e79bb361bfb394c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65923751e78a4837bd8e6f89bfc81ff5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "861cce46bc8d484284c471451106ff5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b31afd992f5441fbf609906f5d2d28a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff377c7455244da3be56a968882eb898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb72b776ba7b4d668315bcd9e5168144": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5150fad18fee40e1a70841971bcc6b5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3622fcca2704b34b1ffbd3fb77810d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4704727c51924aa2a1caa4951d7647e4",
              "IPY_MODEL_b57dc6f9dd874fe5994935f818a415ee",
              "IPY_MODEL_3821edefa9b547b9986348dcb25576cb"
            ],
            "layout": "IPY_MODEL_7bd3627e47ee4d9fb75f807385e55ebb"
          }
        },
        "4704727c51924aa2a1caa4951d7647e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f17e86f493194a818e46acbff695ce74",
            "placeholder": "​",
            "style": "IPY_MODEL_7724f481fa4c4f039686103157144172",
            "value": "merges.txt: 100%"
          }
        },
        "b57dc6f9dd874fe5994935f818a415ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d0e7abe605440a58ac3bcbdb29b9d18",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_165cb2cef5364bafa35eb74a90f78d32",
            "value": 456318
          }
        },
        "3821edefa9b547b9986348dcb25576cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_307f42379165477786e29a9a82593a13",
            "placeholder": "​",
            "style": "IPY_MODEL_468e3eb48351404abec26b499d215acd",
            "value": " 456k/456k [00:00&lt;00:00, 718kB/s]"
          }
        },
        "7bd3627e47ee4d9fb75f807385e55ebb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f17e86f493194a818e46acbff695ce74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7724f481fa4c4f039686103157144172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d0e7abe605440a58ac3bcbdb29b9d18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "165cb2cef5364bafa35eb74a90f78d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "307f42379165477786e29a9a82593a13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "468e3eb48351404abec26b499d215acd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f3547b9a8d947e4b5e35a48b0e2bd61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce00506fb3674cdc899234151ac45dc4",
              "IPY_MODEL_065ddc44413f4546abdc54096951a657",
              "IPY_MODEL_c544445ea5ef4ba1b5411704249e415c"
            ],
            "layout": "IPY_MODEL_c8a8718680ce463ca9a1b921c8aba866"
          }
        },
        "ce00506fb3674cdc899234151ac45dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fdbe87a833d4e928be8f0762be99027",
            "placeholder": "​",
            "style": "IPY_MODEL_74a63060648143558f848c3712525899",
            "value": "added_tokens.json: 100%"
          }
        },
        "065ddc44413f4546abdc54096951a657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e8fcb1f5f0b4b059b770fab954d37eb",
            "max": 1080,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45968a4045b04566910f772ca0662664",
            "value": 1080
          }
        },
        "c544445ea5ef4ba1b5411704249e415c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b557fb83dbce4e539f830d897fe79cbb",
            "placeholder": "​",
            "style": "IPY_MODEL_aa7ea7c46fd34756a83a813eaba3f621",
            "value": " 1.08k/1.08k [00:00&lt;00:00, 94.7kB/s]"
          }
        },
        "c8a8718680ce463ca9a1b921c8aba866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fdbe87a833d4e928be8f0762be99027": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74a63060648143558f848c3712525899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e8fcb1f5f0b4b059b770fab954d37eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45968a4045b04566910f772ca0662664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b557fb83dbce4e539f830d897fe79cbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa7ea7c46fd34756a83a813eaba3f621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e735fcececa64867930ca30bf9d9d703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d939472d2b8a48d59c41cf070813c940",
              "IPY_MODEL_c2dcb87123a9445cb86ad58cd85f7250",
              "IPY_MODEL_b38805d675e840c5868478618274232f"
            ],
            "layout": "IPY_MODEL_d7730feb260e4b3e9f281ef48e840265"
          }
        },
        "d939472d2b8a48d59c41cf070813c940": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_392da393a021459c9e1101d11542b184",
            "placeholder": "​",
            "style": "IPY_MODEL_af61150c7ace4de0a1edac470f63a62a",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "c2dcb87123a9445cb86ad58cd85f7250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_882d36d7864549c9925d4a82620b3dbb",
            "max": 99,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb2df06d4f964dd4a3808ce62c4f8ce4",
            "value": 99
          }
        },
        "b38805d675e840c5868478618274232f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4db54774874e45168741b179d06d09bb",
            "placeholder": "​",
            "style": "IPY_MODEL_0b9156fede034b59a5e5328e44c2bb3e",
            "value": " 99.0/99.0 [00:00&lt;00:00, 8.51kB/s]"
          }
        },
        "d7730feb260e4b3e9f281ef48e840265": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "392da393a021459c9e1101d11542b184": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af61150c7ace4de0a1edac470f63a62a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "882d36d7864549c9925d4a82620b3dbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb2df06d4f964dd4a3808ce62c4f8ce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4db54774874e45168741b179d06d09bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b9156fede034b59a5e5328e44c2bb3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0698800dd3bb47819351063ae76e979f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d523da4c754408cadbb57e8d93d814b",
              "IPY_MODEL_e835a040ee8f44469859c7e24598de19",
              "IPY_MODEL_ab2dadf5170e4524af913a2764acd7c5"
            ],
            "layout": "IPY_MODEL_c7115c64d89746f5aa5ea6d9d341c566"
          }
        },
        "5d523da4c754408cadbb57e8d93d814b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cf3e428ca1d4232aa61e262bc981be3",
            "placeholder": "​",
            "style": "IPY_MODEL_ac824d086c4b41ff87941b2d920e8b48",
            "value": "tokenizer.json: 100%"
          }
        },
        "e835a040ee8f44469859c7e24598de19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b18391837d241c3a770e05f403a6075",
            "max": 2114924,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14f05fb9cf524232808f1c5f284dbf44",
            "value": 2114924
          }
        },
        "ab2dadf5170e4524af913a2764acd7c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7361e11048245e5962f8643967f269d",
            "placeholder": "​",
            "style": "IPY_MODEL_6c0234060a2240729218f21b4722da94",
            "value": " 2.11M/2.11M [00:00&lt;00:00, 5.01MB/s]"
          }
        },
        "c7115c64d89746f5aa5ea6d9d341c566": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cf3e428ca1d4232aa61e262bc981be3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac824d086c4b41ff87941b2d920e8b48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b18391837d241c3a770e05f403a6075": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14f05fb9cf524232808f1c5f284dbf44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7361e11048245e5962f8643967f269d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c0234060a2240729218f21b4722da94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}